id,abstract_text
151F5ECE-FE41-4B22-8EF5-8F5325099B0F,"As species diverge, they accumulate nucleotide substitutions in their genomes at a rate approximately constant in time. Thus, substitutions serve as timepieces to infer species divergences. By incorporating information from the fossil record, the inferred speciation timings can be calibrated to geological time. This method, known as molecular-clock dating, has broad applications in evolutionary biology, such as studying the timing of spread of viral pandemics, ancient rates of diversification in animals and plants, the relationship of species evolution with past climate or extinction events, human evolution, or the origin of agriculture and animal domestication. Indeed, evolutionary timetrees provide much richer information about species histories than trees without temporal information, thus allowing the formulation and testing of hypotheses on evolutionary timescales.

Currently, Bayesian methods are the-state-of-the-art in molecular-clock dating as they allow flexible modelling of evolutionary processes and integration of fossil uncertainties in the analysis. Progresses in Bayesian clock-dating include stochastic models of rate variation among lineages (so-called relaxed clock models), modelling of trait evolution in extant and extinct taxa, and development of &quot;soft-bounds&quot; and flexible fossil calibration densities. While these advances have made the Bayesian method attractive for clock-dating, Bayesian computation relies on MCMC sampling which requires computationally expensive stochastic simulation, precluding the Bayesian method for analysis of large-scale datasets. This is unfortunate since large scale molecular datasets are now commonplace: several high-throughput genome sequencing projects have now been announced or are in progress and we expect a flood of genome-scale data for several thousand species (e.g. the 10K animal genomes and the UK's 66K eukaryotic genomes projects). This deluge of genome data has been accompanied by an explosive increase in the number of morphological datasets based on a computational revolution in comparative anatomy - the widespread deployment of X-Ray Tomography and photogrammetry resulting in vast databases of trait data: MorphoBank and Phenome10K now store over 64,200 surface scans for over 7,000 species. Computational tools capable of exploiting these newly generated datasets are now urgently required. For example, with current methods, inference of a 66K-species timetree would require at least 55 years of computing time (extrapolating from some of our previous analyses). Evidently, the efficiency of analytic methods has not kept apace with the volume of data available and increasingly required to tackle large scale questions in evolutionary biology. 

In this project we will overcome two major challenges in Bayesian clock dating of species divergences: (i) the mixing and computational limitations of MCMC algorithms in analyses of large datasets, and (ii) the limitations of current trait models of evolution in timetree inference. We will design novel MCMC algorithms to improve the mixing efficiency making use of new ideas about MCMC algorithm design and improve the computational efficiency through code improvement and parallelization. We will incorporate advanced trait models to infer timetrees of extant and fossil species. In particular, we will adapt trait models to analyse large genomic trait datasets such as RNA-seq expression data. The newly developed algorithms will be implemented in our MCMCtree software, and applied to several large-scale empirical datasets with densely sampled extant and fossil species. The data analyses will provide important motivations for method development and serve to showcase our new software by addressing fundamental questions in evolutionary biology. Our proposal addresses the BBSRC's strategic priorities of &quot;data driven biology&quot; and &quot;system approaches to the biosciences&quot;."
98B16D86-1FF0-47C6-B8C5-195676D280C3,"Cellular plasticity, the ability to undergo molecular and physical changes, is a key adaptive mechanism that enables organisms to develop, regenerate and respond to stress. In cancer, however, it is one of the major underlying causes for resistance to therapy. This process allows cells to transition to distinct states and thereby gain the ability to evade immune responses, to accumulate new mutations which could enable resistance to antiproliferative drugs, colonise other organs or help metastatic tumour cells to adapt to new environments. All of these can lead to tumour progression and/or recurrence. Plasticity manifests in many forms, but one of particular clinical relevance is cellular dormancy. Dormant cells enter a reversible cell cycle arrest named quiescence which enables them to resist to high levels of stress such as those encountered during tumour development or treatment, e.g. chemotherapy targeting cycling cells. There is increasing evidence indicating that tumours contain subpopulations of slow-cycling or entirely quiescent cells which can evade therapy.

Dormancy results from a complex equilibrium between DNA damage and cell growth processes, involving master regulators like the p53 and Rb proteins, to enable the cells to cope with increasing genomic instability and levels of stress. These processes are crucial during early tumour development and manifest as a consequence of various mutagenic insults accumulated in the genome. Yet, the specific mutational processes inducing cells into a dormant phenotype are completely unexplored. Moreover, the extent to which dormancy levels vary within a single tumour or between multiple affected individuals is unknown. Addressing these knowledge gaps could lead to a paradigm shift into cancer treatment management.

A cancer with particular relevance for the phenomenon of dormancy is oesophageal adenocarcinoma, an aggressive disease with consistently poor outcomes from both chemotherapy and immunotherapy and a 5-year survival rate of only 15%. We have shown that chemotherapy does not change the mutational make-up of this cancer significantly, suggesting that something beyond the genome must be driving resistance to this therapy. Literature evidence and our own analyses indicate that dormancy could play a role. I propose to investigate the mechanisms leading to dormancy in this cancer and their potential therapeutic relevance. Beyond oesophageal cancer, various other tumour types show evidence of this phenomenon. Brain tumours, particularly gliomas, show consistently high rates of dormancy which confers stem-like characteristics and resistance to standard therapeutic strategies. Sarcomas are highly metastatic, often due to latent micrometastases enabled by dormant cells. Understanding the emergence and clinical impact of dormancy in various cancer tissues could help rationalise tailored therapies for cancer patients.

Statistical methods such as matrix decomposition have recently enabled us to identify the distinctive genomic footprints of various mutagens (such as smoking or UV light) from DNA sequencing data. These inform us on how specific cancers developed and can be linked to gene expression programmes active in dormancy and their manifestation in the tissue. In this regard, I will employ and develop cutting edge statistics, data integration and artificial intelligence methods on bulk, single cell and imaging datasets from oesophageal, brain and bone cancers to elucidate the genomic drivers, spatial heterogeneity and therapeutic relevance of dormancy in tumours.

The aim of this proposal is to provide an integrated view of how dormancy arises as a result of various mutational processes in cancer and how this impacts the broader cellular architecture of the tumour. I will employ this knowledge to redesign how cancer treatment is allocated by predicting the risk of resistance to therapies where dormancy may play a role."
CC625D6D-1856-4EA6-8D50-0B03D59C746E,"Phylogenetic methods using genomic data have been used with great success to construct and study the evolutionary relationships between extant mammal species. However, due to methodological constraints, morphological data has so far been underutilised and this has become a limiting factor when trying to estimate patterns of divergence and extinction in the evolutionary history of this group. The proposed project aims to use recent advances in Bayesian statistical methods to reconstruct a species-level mammal phylogeny by combining morphology (from extant and extinct species) and genomic data (from extant species) and use the reconstructed phylogeny to unravel patterns of mammal evolution through time. Morphological data will come mainly from CT scan data obtained from previous work and online databases, which will also be supplemented with new scans from museum specimens taken over the course of the project. Genomic data will be obtained from online databases. The advantage of the proposed methodology is that fossil species will be used as dated tips in the phylogenetic reconstruction, which, together with extensive phylogenomic sampling from extant mammals, would provide more information about early mammalian evolution compared to previous studies. This reconstructed phylogeny can then be used to estimate rates of evolution and divergence times in order to place key evolutionary events in their geological/environmental context, allowing us to address a number of important questions, such as the relationship of mammal diversification and extinction to palaeoclimate or to understand the genetic basis of morphological innovation in this group. This could in turn provide useful inferences for the current climate crisis and how it may affect patterns of diversity and evolution in modern mammals and other vertebrates."
1B494B79-2B3A-4712-B906-EB716B41C7CB,"The ability to genetically engineer insects of medical and agricultural importance has opened the possibility of deliberately introducing genetic traits into insect populations as a way to alter their ability to either reproduce, to cause crop damage or to vector pathogens that cause disease. However, one thing is identifying the genetic trait that one would like to introduce into a modified insect; it is another thing completely to get that introduced trait to spread into a population. The reason this is difficult is that the added genetic trait usually does not improve the evolutionary fitness of those insects that harbour it, meaning that its representation in the population is unlikely to increase generation upon generation. In fact in some cases the genetic trait is designed to have a strong negative fitness effect on the population. In either of these scenarios this means that huge numbers, usually tens of millions and far in excess of the numbers in the local target population, need to be released in order to have an appreciable effect on the population. This is expensive and logistically challenging. Moreover, the effect lasts only as long as one can continue to release such numbers. Recent innovations in genetic control, such as 'gene drive', get round this problem by ensuring that there is a biased inheritance of the modification each generation, meaning that its frequency in the population can increase relatively rapidly. 

These types of approaches hold much promise because they are self-sustaining - only a few insects need to be released to have a long term effect - and they are species-specific because the traits are passed on by mating between insects of the same species. Many of these gene drive designs use genome editing tools such as CRISPR as their 'molecular motor' that works to bias the inheritance of the gene drive element among the sperm or eggs that an insect makes and contributes to the next generation. Making small changes to the duration and/or timing of the CRISPR element in the gene drive can drastically affect its performance in how likely it is to be inherited - limiting its expression only to the germline cells where it needs to be active can cause huge improvements in the fitness of insects carrying the drive element and therefore can increase its likelihood of penetrating a target population. Similarly, many gene drives contain also a genetic 'cargo', designed to produce some intended effect in insects carrying it - for example, activation of innate immune system against a pathogen or the production of proteins that interfere with parasite replication - and expression of these effects in insects, or tissues therein, not infected by the pathogen can be very costly. In both cases then, an ability to fine tune expression within the insect, in both time and space, can have a large effect in improving the efficacy. 

What we are proposing here is to: 1) dissect the process of sperm and egg formation in the ovary and testis, to the single cell level, and extract information on the DNA sequence of the genetic switches in the genome that control expression in the relevant cells necessary to ensure biased inheritance of the gene drive. We will then test these new switches to see if they improve the gene drive performance; 2) We will provide an additional level of exquisite specificity to the expression of the gene drive and/or its cargo by ensuring that each is only active in response to signals - such as RNA from the pathogen - that faithfully signal that expression should occur in that cell type. These RNA-based 'riboswitches' are very novel and proof of their ability to work in this system would have far reaching importance, not just in insect control but in improving the utility and specificity of genome editing in a range of applications including healthcare applications such as in vivo genome editing and CRISPR-based diagnostic assays."
8BBBCEAC-F4C4-4F56-A723-F1E3C3974AB2,"Large quantities of data are gathered in many domains of life, including the medical, financial, retail, industrial and social media domains. This data must be analysed such that its properties can be extracted and the underlying system understood. It is necessary to distinguish between the quantity of data, which may be large, and the information contained in the data, which may allow it to be represented, with acceptable accuracy, by a simple model. This simple model captures fundamental properties of the system, such that it can be used for the determination of the response of the system on new (unseen) data. An example of a simple model is a low degree polynomial, but this proposal considers a sparse model, which is another example of a simple model. A sparse model of a system is a model in which the dominant input variables (predictors) that determine the output, rather than all the input variables, are identified. Genomics provides an example of a sparse model because there are about 30,000 genes in the human body, but not all genes are associated directly with cancer. It is therefore desirable to identify the genes that are most directly associated with cancer, such that treatment is focused on the dominant contributory factors, rather than factors whose role in the cause of cancer is minor. 

Sparsity of the solution x of the linear algebraic equation Ax=b is imposed by regularisation in the 1-norm (the lasso). This is different from regularisation in the 2-norm (Tikhonov regularisation), which imposes stability on x. The lasso is not understood as well as Tikhonov regularisation because of the absence of a 1-norm matrix decomposition, but fundamental properties of a regularised solution of Ax=b are independent of the norm in which the regularisation is imposed. For example, a regularised solution in both norms must be stable and the error between it and the exact solution must be small. This proposal considers these properties of a regularised solution when regularisation by the lasso is used.

Computations on sparse models are, in general, simpler and faster than computations on exact dense models, which is advantageous, and important theoretical issues that must be addressed are considered in this proposal. A sparse model is an approximation of an exact dense model and there is therefore an error associated with a sparse model. A good sparse model is a model in which this error is small, and this sparse model is accepted because this small error is balanced by the greater physical insight allowed by a sparse model. Furthermore, a sparse model must be computationally reliable such that results derived from it are numerically stable, and thus a good sparse model must have a small error and be stable. It cannot, however, be assumed that all inputs yield an approximate input-output relationship that is sparse, stable and has a small error. It is therefore necessary to establish the class of inputs for which these properties are, and are not, satisfied. It follows that there are many issues to be considered before a sparse model can be used with confidence of its correctness. This proposal addresses these issues and it will include theoretical results and computational experiments. 
 
The benefits of the proposed research extend to the many areas in which a sparse model is used to model an input-output relationship. These applications include the medical, financial, retail, industrial and social media domains (as stated above). Apart from the computational advantages of a sparse model (stated above), the desirability of a sparse model follows from its simplicity, and it is therefore easier to obtain a physical understanding of the input-output relationship of the system."
6F4E70DB-BD56-4C96-95FF-090E9E7640AE,"The use of high throughput data measured through the use of microarrays has started a new era in clinical diagnostics and prognosis. Microarrays, which are currently used to measure DNA content and DNA methylation, enable the measurement of tens of thousands of variables in a single experiment. Generally, the situation may then be described as having a large set of covariates that can be used to predict survival outcome.
Typically such genomic data are high dimensional and consequently variable selection procedures such as Lasso and elastic nets are commonly used. However, these traditional variable selection procedures do not account for known, hierarchical relationships between data types. To take into account the differences between data types, it is proposed to explore different variable selection methods.
There is a need to understand the relationships between genomic data and clinical data and observations in clinical studies. Such data will typically comprise patient outcome, including, for example, response, tumour size and growth kinetics, progression-free survival and overall survival. In addition, data will also be available for adverse events, including duration and severity. Relating genomic data to the various forms of patient data on efficacy and safety is of importance in order to understand more about patient selection for individual therapies and potentially prognostics for the outcome. 

AstraZeneca (AZ) has collected different types of genomic data in a number of clinical studies for several drugs in development for the treatment of cancer. The genomic data collected include copy number variation, somatic mutation, methylation, mRNA, miRNA and protein expression data. The clinical studies, which include Phase, 1, Phase 2 and Phase 3 studies comprise patients with various tumour types including ovarian cancer, non-small cell lung cancer and other solid malignancies.

AZ have also identified suitable clinical studies or real-world evidence (RWE) databases in haematological and/or non-small cell lung cancer indications, which involve the collection of genomic data, and extract appropriate genomic data, together with longitudinal efficacy and safety data, all of which can be used in this project.

In this context, RWE is generally understood to mean the information derived from electronic health records (EHR), which are used to centralise data across sites of healthcare and allow for population-level modelling and pharma-covigilance. It has been argued that research and randomised clinical trials at the site of care can generate results with superior external validity compared to conventional clinical trials, and facilitate the participation of a number of patients that, otherwise, would not benefit from the treatment. Difficulties in building prognostic models from genomics and real-world data (RWD) include interpretability of large datasets and inference of treatment effects.

Aims

The project, in collaboration with AZ, comprises the study of non-small cell lung cancer (NSCLC) data to develop prognostic tools, predictive models and reproduction of biomolecular pathways. The aims are summarised as follows:
- Define predictive tools for time-to-event combining clinical data, which will include RWD and multicentre data, together with high-throughput genomic and transcriptomic data.
- Analyse and test the biological plausibility for each gene pathway and biomarker described in the prognostic model.
- Examine the predictive performance in RWD datasets and evaluate the feasibility of the prognostic tests with particular interest in improving false discovery rates from current techniques.
- Analyse and undertake improvements in the protocols of clinical trials or observational cohorts from a disease discovery, data analysis, results-oriented viewpoint.
The clinical usefulness of each prognostic model will be assessed in terms of its ability to predict clinical outcome in RWD"
86DE7044-A6CD-434E-B702-31D734121E64,"After one species splits into two, their genes and genomes will evolve independently. If the rate of evolution is constant over time, the genetic differences between species will accumulate at a fixed pace, proportional to the time of species separation. Thus molecules can serve as a clock, keeping time of species separation by the accumulated changes. If fossil records or geological events can be used to assign an absolute geological time to a species divergence event on the evolutionary tree, one can convert all calculated genetic distances into absolute geological times. This rationale for molecular clock dating has recently been extended to deal with variable evolutionary rate over time in the so-called relaxed-clock models. For fast-evolving viral DNA, the different sampling times of the viral sequences allows us to similarly calibrate the molecular and to obtain estimates of the absolute divergence times and evolutionary rates. In this project, we will develop statistical models of trait evolution, which will be used to analyse morphological trait data for both living and extinct species to generate fossil calibrations, which are crucially important to molecular dating analysis. Such models of trait evolution will also allow us to study the correlation between viral molecular sequence evolution and viral genotypes such as antigenic drift. We will apply the new methods to analyse real datasets to date major divergence events in the tree of life, such as the divergences of the human and the apes, the primates, the animals, and the flowering plants."
ADD7864F-1C1C-469E-8989-D4095AF9D9F3,"Admissions to National Health Service (NHS) hospitals in England have increased by 28% over the last decade and nearly half of all adults admitted are &gt;=65 years old. Some older adults age robustly but others develop frailty, a condition characterised by reduced ability to withstand stressors such as illness. In addition, approximately a third of adult inpatients have one or more chronic health conditions, and many patients are prescribed multiple long term medications, so called 'polypharmacy'. We aim to understand how older adults use emergency hospital services and journey through the hospital from admission to discharge. We will also explore factors, particularly related to prescription medications, associated with poor hospital outcomes such as inpatient death. The World Health Organisation declared 'Medication without harm' its 3rd global patient safety challenge in 2017 and a report commissioned by the Department of Health Policy Research Programme estimated medication errors cost the NHS &pound;98.5 million per year. Whilst medication related harm is widely recognised, more information is needed about which drugs confer the highest risk in which patients to inform safer prescribing practices. 

We will use data from 80 000 inpatient episodes of older adults (&gt;/=65 years old) admitted as an emergency to one tertiary NHS hospital (Addenbrooke's Hospital, Cambridge) over four years. Data is available for large scale retrospective analysis after an electronic patient record system was introduced in 2014. Information describing all aspects of admission from patient characteristics such as age group to information pertaining to bedside observations, prescription medications and blood tests are available. These data will have many repeated measurements over the admission duration, for example blood pressure measurements taken several times each day, leading to a very large and complex dataset. Therefore, anonymised patient records will be transferred to the European Bioinformatics Institute (EBI; Wellcome Genome Campus, Hinxton, Cambridge). EBI is a leading research institution focused on developing cutting-edge technologies to process and manage 'big' data. 

We will employ machine learning (ML), a type of artificial intelligence capable of visualising patterns within complex data, to explore the thousands of patient examples in our dataset. We will firstly define how many different types of hospital admission describe the majority of admissions in older adults and characterise these inpatient trajectories. For example, admission episodes may be characterised by their length (short versus prolonged) or hospital operational factors such as number of ward moves. Secondly, we will use ML to study how different prescribed medications, or combinations of medications, represent a pattern that is consistently associated with inpatient death. We can use known associations, such as the use of blood thinning medications and higher likelihood of death from bleeding, to educate the ML process. ML can then identify other prescribing patterns associated with inpatient death and explore whether certain patient characteristics or types of admission make patients more vulnerable. This will build a comprehensive picture of patient, treatment and hospital factors that impact on the eventual hospital outcome. Inpatient death is our primary outcome but other outcomes such as new admission to a care home following discharge can be considered. Finally, ML can simulate how the hospital outcome might change if a hypothetical alternative treatment plan was employed. For example, medications can be substituted with an alternative treatment to see how this would change the likelihood of death occurring. 

This research will describe use of acute hospital services by older adults and identify potentially inappropriate medications for further study. The Northeast-Newcastle &amp; North Tyneside research ethics service committee approved the study."
4DF50C04-B4EA-49DA-A650-A9AF5411C3E9,"Proteins are biological molecules that are the machinery of life involved in numerous biological processes such as the breakdown of food to provide energy and the defence of a cell against disease. Proteins adopt complex three-dimensional (3D) structures and the location of the atoms can be revealed experimentally. Knowledge of the 3D structure of a protein and its function often provides major insight into biological processes. In addition, this knowledge is of substantial benefit to the design of novel drugs. As a result of advances in biological research, particularly the sequencing of the genomes of humans, other animals and many bacteria, the scientific community is now determining or predicting the 3D structures for many proteins whose functions are not yet known. In addition computational methods can predict the possible structure of a protein from its chemical formula (its sequence). This project is to develop a computer-based approach to take a protein of experimentally-determined or predicted structure and suggest its function. Protein function is determined by the spatial position of critical residues and the environment of these residues. We will use a computer algorithm to learn the rules from known examples of protein structures and their functions. In particular the machine learning approach will be a combination of logic reasoning and quantitative predictions from a support vector machine using a novel method known as Support Vector Inductive Logic Programming (SVILP). SVILP has the benefits that logic rules are powerful in describing spatial relationships and can be readily understood. However logic rules are yes or no and for quantitative prediction (e.g. confidence or rank) we then feed the logic rules into a support vector machine. In this grant we will enhance this novel SVILP methodology. There will be two major results from the grant. First we will have developed an enhanced method to assign function to protein structure and develop a web server for use by the community. Second we will have developed an enhanced robust version of SVILP with its power benchmarked on a challenging application and in a form suitable for uptake by the community to apply our method to a wide range of problems."
E135D5F6-A017-460B-AB08-7B841DE8A834,"Background
--
Science is discovering the exciting world of genes, how they interact, how they differ from person to person and the process by which they ultimately form the templates for proteins, the building block of life. But genes are more complicated than we thought. It seems that genes can be transformed: somewhere between the DNA code for a gene and the final protein, genes can be 'spliced' to make different types of proteins and to form other molecules that interact with the gene system. 

In a healthy cell, this splicing is useful! It allows us to store the code for different proteins in a single gene. But splicing has been implicated in disease, in particular, Motor Neurone Disease (MND), a debilitating and poorly understood disease. Recently, researchers have found a small part of the genetic code (which we call C9ORF72) which may be a tiny clue in understanding MND, and it seems to have a huge effect on splicing. 

New technology is allowing us to uncover the world of genes. Technology developed to sequence the human genome allows us to measure the genes in a cell, right at the point where splicing happens: we call this RNA-Seq. But this sequencing generates LOTS of data, and the amount is increasing. In fact, it's increasing faster than computers are improving. If we want to analyse the data to uncover the world of splicing and the effect it has in MND, we need to create new computational tools which allow us to deal with the data using limited computing resources. 

The Problem
--
RNA-Seq presents us with millions of short sequences which represent the genes after splicing has occured. It's a bit like being presented with a huge bag of jigsaw pieces from thousands of different puzzles: how do the pieces fit together? How many types of picture are there? Which pictures occur most often? There is a lot of uncertainty in the problem, and so we use probabilities to express how the pieces might fit together, and thus how genes have been spliced. 

In recent work, I've examined how to make probabilistic algorithms like this one more efficient, now I will look at how to make use of this type of method in RNA-Seq data. My research will create such tools usings methods based on approximate Bayesian inference. I'll devise algorithms which can deal with these increasing quantities of data, and allow scientists to make statistical inferences from RNA-Seq data about splicing in disease. 

Transferring knowledge
--
To develop such tools, I'll draw inspiration from the related field of natural language processing. With the explosion of the web, data scientists have created methods for organising and categorising our data. One particular statistical method, called a &quot;topic model&quot;, closely resembles the analysis of RNA-Seq. With so much focus on the web, there have been lots of developments in topic models that we can borrow to make our algorithms for RNA-Seq faster and better. I'll investigate how we can transfer these ideas to RNA-Seq analysis. 

There are lots of statistical models that we might want to adapt to study disease through RNA-Seq. For example, we might want to build a time-series model of gene progression, or we might want to find groups of genes which follow the same pattern or trend. To get the maximum efficiency from the data, I'll build these models right in to the reverse-jigsaw problem described above. 

Investigating disease
--
My colleagues are in the process of collecting RNA-Seq data on MND. But the nature of the data will present unforeseen statistical challenges. For example, we might have unknown groupings in patients from whom we have data. I'll use the investigations into MND to inspire statistical models built around the RNA-Seq algorithms that I develop. These methods will be inspired by problems in MND research, but will lead to algorithms that can be used by the wider scientific community in experiments which involve RNA-Seq."
C50ADD8F-B99C-431A-AC9C-2B76CF0CCF0B,"With the rapid increase in our ability to make various measurements about biology at the genomic, epi-genetic, gene expression and population levels, there is widespread acknowledgement within the biological community that mathematical and computational modelling is a necessary tool to be able to understand how molecular interaction and genetically encoded information translates into biological function, and how to translate such understanding to help in the treatment of complex diseases. Of particular interest is the measurement of gene expression at the different levels of transcriptome and proteome, how this mapping is regulated and what kind of information encoded in the DNA sequence are determinants of it. We have been building a strong collaboration between ECS and the School of Medicine in this domain and so far have: (i) an outlier detection algorithm (published in Bioinformatics) for detection of post-translationally regulated proteins, which later formed the subject of a successful KTP bid; (ii) a publication that builds on the above (in the Journal of Immunology) looking at new data that is mapped to micro RNAs regulating protein levels; (iii) A manuscript on the subject of translation regulation (submission to Nucleic Acids Research imminent) and (iv) a grant submission this round to BBSRC (currently under review). This project will be in this rich domain, focusing on two areas we have hitherto not addressed: (i) the role of splicing and its regulation; and (ii) extracting information from the sequence level with focus on regulatory elements in the non-coding regions of the genome. We expect a combination of measured and sequence-derived features to be beneficial in making accurate inferences and will be developing advanced representations learned from deep learning techniques to achieve this."
BCA103B9-1A38-466B-9F42-7AD718620C68,"Context: This proposal builds on our work which identified differences in function between polar and non-polar microbes at the genomic level, through constructing metagenome assembled genomes (MAGs) from large-scale metagenomic sequencing from Mocks lab (Duncan, 2020). Within this data, we have recently identified varying components within photosynthetic metabolic pathways correlated with satellite observations of chlorophyll concentration, suggesting a direct link between gene function and ocean regions. 


Objective 1: The student will functionally annotate extensive public omics datasets including those in (Sunagawa, 2015) and (Zhang, 2020) as well as from the ongoing polar MOSAiC cruise when it becomes available. All data will be annotated in a format comparable to Tara Oceans data using the EBI MGnify pipeline or similar tools. In this way the student will gain experience with bioinformatics tools, and handling large sequencing datasets. She will then perform a bioinformatics comparison of gene functions identified in the Arctic and Antarctic communities, as well as comparing this to the gene functions of MAGs already available from the same data.

Objective 2: The student will apply non-negative matrix factorisation and related machine learning approaches on the annotated data to identify groups of cooccurring functions characterising variation between surface ocean regions. NMF has been used to investigate functional patterns in metagenomics data in marine contexts (Jiang, 2012). To investigate the biological and metabolic processes underlying the groupings, the student will apply clustering and visualisation methods like network representations to identify key functions within groups which characterise their variation. Associations between groups and environmental metadata including satellite data will then be explored. This will provide experience in applying unsupervised machine learning approaches to mixed data sets, and working with experts to identify environmental insights from the results.

Objective 3: Based on associations identified between the reduced dimension models and environmental metadata, the student will develop models to predict gene functions from environmental conditions. Models have been successfully used to predict taxonomic structure (Bracher, 2017) as well as community gene function in phytoplankton using taxonomy as an intermediate step (Larsen, 2015). We aim to predict gene function without reference to taxonomy. The student will approach this using Bayesian networks, in particular learning the network structure from the metagenomic data. This will enable them to infer gene functions from the independent environmental variables. 

Security vs challenge: As this project builds on strong foundations for all 3 objectives, there is little evidence that this work will not be successful. Yet, the challenge is to develop skills in bioinformatics and machine learning to identify environmentally meaningful results. With the acquired skill set, there is potential to identify synergies through working in a highly integrative and multidisciplinary environment."
3AE91E2F-0E8D-497A-B4FE-041AA0DA8D27,"Rationale: Hypertrophic cardiomyopathy (HCM), the most common cardiac disease in humans and cats, occurs spontaneously in 15% of domestic cats and may cause heart failure, cardioembolic complication or sudden death. HCM is heritable in many cat breeds, and two causative mutations in the MYBPC3 gene have been identified in Maine coon and Ragdoll cats using a candidate gene approach based on human studies. Further genetic studies could not only provide the means to control the disease, via genetic testing and selective breeding programmes, but they could also help identify new therapeutic targets. However, over the past decade the candidate gene approach has failed to identify further mutations. Genome-wide genotyping technologies might offer a useful alternative.

This project is aimed at investigating the genetic architecture and the underlying molecular mechanism of HCM susceptibility in cats. Our hypothesis is that HCM is a complex disease of polygenic inheritance controlled by several variants in both protein-coding genes and regulatory elements. 

The objectives of this project are: 
(1) Map and evaluate genomic regions affecting HCM susceptibility in cats.
(2) Identify gene expression signatures for HCM in cats.
(3) Integrate results and identify genetic markers and biomarkers for prediction of HCM susceptibility.

Experimental Design and Methods: We will conduct a genome-wide association (GWA) analysis to detect loci affecting HCM susceptibility using 200 meticulously phenotyped cats from 2 pedigree breeds, Birman and British shorthair, chosen on the basis of their diversity regarding disease onset, clinical expression and prognosis. We will analyse the disease as a binary trait (case vs. control) and using continuous variables based on echocardiographic measurements and histopathological findings.The study will include GWA, regional heritability mapping and selective sweep analyses across and within the two cat breeds (obj.1). In addition, the gene expression profile associated with disease will be assessed using RNA-sequencing in 20 myocardial samples collected from cases and controls (elderly, to avoid false-negatives, and sex matched) from the two cat breeds, followed by differential expression and pathway enrichment analysis (obj.2). Systems biology, artificial intelligence, and machine learning approaches will be used to integrate the results of the genomic/ transcriptomic analyses and shed light on the underlying HCM mechanism (obj.3). Main results will be validated using qRTPCR and Western Blot. Thus, the student will be trained in cutting-edge molecular, genetic and bioinformatic technologies as well as advanced echocardiography and histopathology."
2633F3FA-78DF-41B1-B3F4-E0323CAFF335,"Genes that cause abnormal growth of cells and development of cancer are called oncogenes. While oncogenes often arise from mutation of cellular genes, several types of viruses that can cause cancer, such as human papillomavirus (HPV), bring viral oncogenes into the cells they infect. Oncogenes can induce 'replication stress' (called oncogene-induced replication stress or Oi-RS), which is characterised by the frequent stalling or slowing of DNA replication when chromosomes are copied. This causes more mutations in the chromosomes, which is called genomic instability. 

While replication stress is common in established cancers, it has been discovered that it might also occur in pre-cancerous and early cancer tissues, leading to the hypothesis that Oi-RS is an initial driver of cancer but there is currently no direct evidence for this from existing experimental models of cancer development. Moreover, it is not known how early replication stress causes a healthy cell to become cancerous. Discovery of the initiating mechanisms leading to genomic instability and cancer would provide a vital step forward in understanding what causes cells to become cancerous and will be instrumental in improving early detection and treatment of cancer. We propose to use oncogenic HPV infection of human skin cells, the natural target cell of HPV, as a human tissue model system to analyse the precise steps from Oi-RS and genomic instability to cancer initiation. 

HPV causes &gt;600,000 cancers per year worldwide that are characterised by high levels of genomic instability. Infection with high-risk types of HPV is a very useful model for Oi-RS and genomic instability during early cancer development, because viral oncogenes rapidly cause replication stress and genomic instability. To date however, no team has yet combined expertise to establish the precise pathways from HPV infection, replication stress and genomic instability, through to cancer formation in relevant human skin models. 

Our team comprises a tumour virologist, two cell biologists and a computational scientist. Together, we cross multiple biology disciplines from molecules to human tissue models and will bring diverse methods and technologies to investigate Oi-RS in a model of HPV infection. Our expertise ranges from molecular biochemistry and cell biology to computational biology and the application of artificial intelligence. Importantly, the individual partners all have a fundamental interest in how replication stress and genome instability contribute to cancer development. This project will for the first time bring together distinct backgrounds and disciplines to unravel the molecular events between Oi-RS, genomic instability, and cancer development. We will integrate single cell- and single molecule sequencing technology and machine learning-based detection of replication stress to interrogate the steps from early establishment of HPV in skin cells to the development of invasive cancer cells."
4B52414E-A134-40FB-9CEC-AFF336E623C6,"Prostate cancer is a heterogeneous disease, displaying a multitude of genetic alterations, histological patterns and clinical outcomes. This heterogeneity has confounded our ability to identify subtypes or signatures of aggressive disease, and as such clinical decision making in prostate cancer is still informed only through histopathological grading and biochemical markers. Analysis of data obtained through DNA sequencing and other 'omics technologies has revealed patterns that could be used to inform diagnosis, prognosis and treatment, but these are difficult to define in a clear and consistent way. Recently, several countries have joined together to form the Pan Prostate Cancer Group (PPCG), pooling resources and harmonising bioinformatics pipelines so their data can be analysed together. This data set consists of samples from approximately 2000 men and includes data from whole genome sequencing, RNA sequencing, methylation arrays, histopathological features, and clinical variables.
The data is now of such a scale where machine learning methods could potentially provide deep insights by identifying underlying patterns in the data, but there are a number of requirements that are difficult to fulfil with conventional methods. In particular:
1) Integration of data from multiple sources across several countries, which may have different biases and scales
2) Ability to deal with large amounts of missing data as not all data sources are available for all patients

3) Retaining interpretable links to the underlying biology so clinicians and patients can understand the rationale behind any computational output

4) Identification of patterns that are linked to aggressive disease or reflect disrupted biological processes that could be targeted therapeutically

We therefore propose the development of novel machine learning approaches that can fulfil these requirements and these will be applied to the PPCG data set. Our methodology will be focused on the extraction of latent features that encapsulate relationships both within and between data from different sources and present them in an interpretable form. We will then evaluate the applicability of feature scoring methods in our approaches and develop methods to circumvent any shortcomings. The patient data can be represented in the form of these latent features and this will be used as the basis for further analysis.

As we experience diminishing returns from data sets on the scale that can be generated by individual groups, we will inevitably experience a rise in pooled data sets like that from the PPGC. These provide greater sample numbers but also increase the breadth of available data types, which could contain information leading to deep insights. However, the processing and analysis of this data also presents unique challenges. In this project we will design methods that address these challenges and open up this data for analysis. As we focus on interpretability, any findings should be amenable for translation to clinical use. We will create our methodology with the expectation that it should be will applicable to data from other cancer types. This project falls within the EPSRC Artificial Intelligence and Robotics research area and will run in conjunction with projects funded by Prostate Cancer Research, Cancer Research UK and Prostate Cancer UK."
6C80B2CF-A5DE-4EF8-9E72-D4987B88DF77,"Pharmaceutical companies would be unable to function without high levels of automation, and the demands for high-throughput screening of potential drug candidates has been driving advances in automation technology. However, while this industry has embraced the use of automation for tasks that are simple to automate, especially at companies with enough long-term human resources and economic power to acquire costly highly specialized equipment, the automation of R&amp;D is still very challenging.
Recent developments in automation technology have dramatically lowered the costs, and improved the flexibility and accessibility of the platforms, e.g., low-cost open-source liquid handling robots. The free open-source hardware and software community has played a prominent role democratizing automation. This has been achieved by the development and sharing of tools freely available for the community for further study, customization and commercialization at lower cost. The best example of this for automation is the Opentrons' platform OT-2 [https://opentrons.com/ot-2/], which is an affordable and scalable open-source lab automation system that can automate up to hundreds of assays and workflows.
By leveraging the recent advances in low automation, it is now possible to combine AI and automation to allow an &quot;intelligent&quot; automated platform to create and test its own novel hypothesis based on the data gathered by the iterative design cycle. Currently, DNA Biofoundries (i.e., the Edinburgh Genome Foundry) rely in human input for the creation and evaluation of each of the biodesign steps. Increasingly, however, biofoundries and automation facilities will tend employ AI at each step in the iterative cycle. The main difference with a traditional biofoundry is that in those cases, an AI algorithm will be implemented to generate its own scientific hypotheses, which will then be tested experimentally using the automated platform, resulting in the generation of new scientific knowledge.
These developments combined with further developments in data sharing methods and standardization may allow researchers to truly revolutionize the way biomedical labs operate.
Our hypothesis is that it is now possible to build a system that automates R&amp;D by exploiting low-cost automation, massive high quality data sets, and artificial intelligence (e.g., machine learning techniques based on deep neural networks). Specifically, this thesis will (1) combine bio-automation with machine learning such that data is processed in real time for hypothesis generation (as the algorithm iterates over the input space), and (2) enhance open-source robots with new functionalities such as the ability to &quot;see&quot; sample output with a video camera and pick bacterial colonies based on features of interest such as color intensity. The results will lead to more efficient systems for drug discovery and production.
Aim: Improve the speed, efficiency and cost of automated biofoundries to develop microbial cell factories for pharmaceutical production leveraging on low cost automation and AI."
C2D1BCB3-3E1A-4519-A69E-C68127E38F8C,"Endemic disease such as lameness that may lead to paralysis and death in broiler chickens presents considerable welfare problems, it leads to significant antimicrobial usage and results in substantive economic losses for the broiler industry both within the United Kingdom and worldwide. Enterococcus cecorum, an emerging pathogen, has become associated with infections in affected poultry flocks in the British Broiler Industry. However, little is known about how this commensal has evolved to become a pathogen due to E. cecorum genomics being in its infancy. The environmental reservoir(s) that it occupies which results in apparently sporadic disease occurrence within poultry flocks is also unknown, and no close monitoring is being performed of animal behaviour to determine if any subtle changes occur during the early stages of infection before disease progression and gross physical changes that are associated with lameness becomes apparent. Therefore, in this transformational proof-of concept proposal we aim to fill current knowledge gaps by bringing together a unique and highly skilled project team from diverse backgrounds, gathered through the BBSRC Endemics Livestock Disease Initiative workshops for Priming Partnerships. Through our multi-disciplinary partnership, we will endeavour to lay foundations in the first year of research that will help improve the health and welfare of broiler chickens, so lameness and paralysis due to E. cecorum infection can be detected early, which will also help reduce antimicrobial usage during treatment and more successful treatment outcomes will help prevent large economic losses for farmers and the broiler industry.
In this ambitious multi-pronged study, there will be three main components: pathogens genomics; transmission/persistence; and animal behaviour monitoring. Isolate genomics will help advance our understanding of E. cecorum pathogens. By performing detailed molecular characterisation, we will identify any genetic elements that have been acquired via transfer of mobile genes from other bacteria, particularly those living in the same environmental niche, resulting in increased virulence and a propensity of this bacterium, once a commensal, to cause endemic disease in poultry. Linkage of genes that cause resistance to antimicrobials, with key virulence determinants present in pathogenic variants, will help identify markers associated with pathogenic isolates that can be used for rapid detection on farms in future, using pen-side tests. In addition, groups of isolates found to be enriched with particular virulence elements that are from the same genetic lineages, will enable detection of E. cecorum types or clones associated with diseased birds in Great Britain. For identification of environmental reservoirs that enable transmission and persistence on farm, our plan is to perform in-depth sampling of surfaces, litter and water in positive houses and a negative control, at different periods of the production cycle, from five farms. An E. cecorum specific PCR will help identify presence, which will be verified in a subset by culture. Survival experiments will help distinguish how well E. cecorum survives in water, concrete and plastic that are common in poultry houses and part of our sampling protocol, especially upon exposure to biocides. Video sensors and associated analytical tools are an excellent way for monitoring animal behaviour closely, including detecting any subtle changes. By installing sensors on a subset of the farms and houses where environmental sampling will be performed, we will be able to use artificial intelligence to monitor flock performance and identify deviations from parameters such as climatic conditions, bird growth and water consumption. Deviations in infected flocks, will be verified by veterinary inspections and any correlation between early changes in behaviour and infection will be incorporated into future algorithms to help detect disease early."
7050D18A-C31B-4CB2-A95E-FF21A220F217,"The rapid development of Next Generation Sequencing (NGS) technologies has dramatically increased the ability to sequence genes and genomes over the last decade, leading to the potential of more enriched, deeper understanding of microbial communities within a range of bioscience areas. Today, the most difficult and rate limiting step is not the generation of 'omics data, but the interpretation of it, and the investigation and analysis of these large and diverse data has become a major bottleneck. Furthermore, the ability to link relationships and patterns across multiple 'omics datasets (such as metagenomics and metatranscriptomics) can support a deeper understanding of biological functions. Analysis methods that support gaining of such insight can greatly facilitate decision making as well as support generation of novel hypotheses.

This project will develop novel methods for interactive visualization and explorative analysis of temporal 'omics data of multiple types, working with scientists in the School of Natural and Environmental Sciences that research the emergent technology of plant growth promoting Bacteria (PGPB) as biofertilisers, biopesticides or biostimulants. The data to be used in the project will have been generated through analysis of crops and substrates under controlled conditions. This will include metagenomics and metatranscriptomics data from soil samples, sampled at multiple time points to generate data that can be used to monitor temporal dynamics of rhizosphere microbial communities. 

Such data pose multiple challenges from data analysis perspective. Firstly, analysis across two types of 'omics data needs to be carried out to support understanding of the biological system present. These data are high dimensional, and the need to analyse across datasets adds to the challenge while also opening potential for gaining deeper insights into the biological system. Secondly, the data is temporal and insight into time based patterns will be key to identifying biomarkers for presence and effect of PGPBs. While visualization and exploration of multivariate temporal data has been a major focus in the data visualization community, no satisfactory solution has yet been developed that support temporal analysis across multiple datasets with such high dimensionality as 'omics data. Thirdly, sampled 'omics data is commonly associated with meta data of importance, and statistical analysis is normally required to confirm the reliability of findings and data patterns. These needs to be incorporated into the analysis to make full use of the potential of the data and support reliable analysis. 

Visual representations to represent overall patterns in the high dimensional datasets will be designed, as well as interactive methods for examining finer details and data subset selection methods. Visualization methods will be integrated with semi-automated data mining and machine learning approaches to provide interactive analysis and pattern identification, aiding quick identification of patterns of potential interest. Methods and algorithms for identification of patterns across multiple datasets will be developed, and may for instance include correlation-, cluster- and sub-cluster analysis across the datasets. 

The project will focus on visualization methods to highlight and link identified relationships across multiple datasets, as well as overview representation of the main patterns and relationships across multiple datasets. These will be extended to temporal data, producing representations of changes over time, supporting exploration to track plant environment interactions and aiding the generation of novel hypotheses around PGPBs and plant growth.

Developed tools will be generalised and made them openly available to microbiologists and bioinformaticians, to increase the impact of the work within areas such as bioscience and health informatics."
FCFEF620-5D64-4255-BA2B-155241488C8A,"Microbes like bacteria and fungi inhabit diverse environments, including soil, water, and human body sites, such as the mouth, skin and intestine. Ubiquitous in nature, they also show adaptation to extreme environments, such as acid mine drainage or hydrothermal vents. We have appreciated the potential of microbes for a long time - they are important for food and beverage manufacturing (e.g. cheese and beer), and are key players in bioremediation, as demonstrated by their pivotal role in breaking down complex oils following the Deep Horizon oil spill in the Gulf of Mexico. The field of metagenomics offers an exciting opportunity to examine these microbial communities and gain insights into various aspects of their existence, i.e. their interaction with humans and plants, their potential as disease reservoirs, and as sources of novel enzymes with bioremediation or plastic recycling abilities.

Metagenomics studies microbial communities by sampling the environments directly, extracting and sequencing their genetic material (DNA), and applying computational methods to elucidate microbial composition and function. This sampling approach helps to characterise unculturable or as yet uncultured microbes in the laboratory. Metagenomics experimental data are typically large (10-100s of GBs per sequencing run; 100s of runs per project), complex (comprising 100-1000s of different microbes) and variable due to the nature of the underlying experiments and (sub-)sampling of the dynamic populations.

Despite knowledge about fluxes within a microbial community (e.g. time of year or day), metagenomic datasets typically contain poor descriptions (termed metadata) relating to the sample origin or methods used to obtain the DNA and process the sequence data. To help interpret data across experiments and derive meaningful biological conclusions, it is crucial to know whether a difference between two metagenomics datasets is due to differences in underlying experimental techniques or the biological qualities of the sample. The lack of metadata has impeded our attempts to apply machine learning (ML) techniques to interpret new incoming data, and therefore our capacity to find novel biological applications.

To circumvent these issues, our proposal aims to employ different ML methodologies to enrich the currently available metadata and start elucidating new knowledge embedded in the sequence data. The text mining approach will focus on identifying research articles on metagenomics experiments to unearth and extract detailed descriptions which will be used to enrich the metadata associated with the corresponding DNA sequences and generate new or improved classification systems. This dictionary of descriptor terms will also serve as the template for developing methods to discover previously unidentified metagenomics papers. We will train algorithms on this enriched metadata to progressively learn what criteria might be applied to incoming data with inadequate descriptions in order to determine sample origin, processing, as well as decipher which experimental biases affect the results, when comparing similar samples.

ML approaches will also be used for the discovery of new biological functions. Bacteria encode gene cassettes that are responsible for producing compounds of pharmaceutical and agricultural value. Functional descriptions for the genes constituting these cassettes are incomplete, while many cassettes still await discovery. By combining the ML and text mining approaches, we intend to better describe these cassettes and also focus on the detection of novel groups.

Data underpinning this work will originate from key EMBL-EBI databases, namely EBI Metagenomics and Europe PMC, as well as other resources (e.g. MIBiG). Developments aimed at herein will help resolve complexities underlying experimental data, enriching the metadata in the process and also laying the foundation for a new generation of reliable predictive models."
3255AE88-022D-4B04-A352-205C39EE63A2,"Background: Reactive oxygen species (ROS) cause cell damage that is a major contributor to a number of age-related conditions including neurodegenerative disorders and cardiovascular diseases. However, over the last 10 years, our view of how to limit this damage has been revolutionised. This follows the discovery that low levels of ROS have important, positive, signalling functions, that include initiating protective responses that maintain cell viability/organismal health. Despite, the increasing evidence that localised ROS increases can be beneficial, the mechanisms by which these ROS signals are transduced to protect against ageing/age-associated loss of tissue function remain poorly understood. This project involves a multidisciplinary supervisorial team, enabling the student to combine a range of genetic, biochemical and computational approaches to provide answers to this fundamental question. 
Project: The supervisors have successfully used a combination of high throughput genetic screening and proteomic approaches to identify several candidate ROS-regulated kinases. This project will use standard and cutting-edge molecular biological and biochemical techniques (including genome editing, RNAi, immunoblotting and confocal microscopy) to investigate, whether ROS-induced oxidation of cysteines in these kinases mediates the positive effects of ROS in cell (mammalian), and animal (Caenorhabditis elegans) models. By elucidating new signalling mechanisms that mediated effects of ROS, this project will provide an essential step towards the goal of therapeutically enhancing ROS-induced protective responses to counteract the effects of ageing. The industrial placement, supervised by Dr Conlon, will enable network pharmacology to be used as a prelude to translating these discoveries.
This project falls squarely under the BBSRC challenge area 'Lifelong Health' - understanding the biological mechanisms of healthspan, with the long-term objective of maintaining and enhancing the quality of mental and physical health throughout the life-course."
3A445875-D758-4D09-AEE7-029A0235C097,"Bacterial phytopathogens are hard to control and therefore pose a high risk to crop production and the wider natural environment. In order to mitigate that risk, we propose multidisciplinary research into the tempo at which and the mechanism by which bacteria adapt to hosts. Our findings will support new developments in disease management and control strategies.
 
The host range of a pathogen encompasses all the species it can successfully infect and colonise. It is hypothesised that plant species outside this range mount an effective non-host resistance response, preventing colonisation. Plant pathologists traditionally define some pathogens as having a wide host range (generalists) whilst others are limited to one or a few hosts (specialists), although a continuum between these two life strategies probably exists. Our work focuses on the ubiquitous bacterial species complex Pseudomonas syringae (Ps), lineages of which are pathogens of over 300 different plant species. At least eight lineages of Ps are known to cause bacterial canker of cherry trees including the recognised pathogens Ps pv. morsprunorum and Ps pv. syringae.
 
From our preliminary work, sampling from the leaf and shoot surface across cherry orchards around the UK, we have shown that there are large regional variations in Ps populations. We have found that, in addition to the known pathogens, many additional lineages of Pseudomonas (which have the potential to be pathogenic) are present on non-diseased cherry leaves and such strains are extremely widespread across orchards and regions. These epiphytic (surface) populations of pseudomonads may either be donors or repositories of bacterial genes predicted to have a key role in host adaptation to Prunus. We have shown that there is significant variation in resistance to canker within cherry cultivars and also between genotypes of wild cherry. What we do not know is whether or not the epiphytic populations of Ps are similar or variable between cultivated and wild cherry hosts, or if there is a flow of bacterial strains between wild and cultivated cherry.
 
In this multidisciplinary research proposal, we will extend our initial experiments to study the ecological niches occupied by Ps. Using repeated sampling and genome sequencing of isolates from cultivated crops and surrounding plant species, we will determine if epiphytic Ps populations, some of which contain known pathogens, are stable over time and space. In controlled field experiments we will also ask whether agronomic interventions, such as nitrogen rates and polytunnel covering of crops also play a role in shaping bacterial populations. 
 
Our previous work has shown that key genes have been transferred between Pseudomonas lineages by phages and plasmids. In order to explore the molecular factors that may affect virulence and lead to new disease outbreaks, we will carry out tests to determine whether epiphytic lineages have 'pathogenic potential' and study the mechanisms of host range expansion through a range of directed evolution experiments. Our analysis will include controlled assessment of gene exchange between bacteria through phage infection. 
 
Finally, we will explore whether machine learning approaches can predict the host range of a Pseudomonas isolate with any degree of certainty from its genome sequence alone- a feat that is currently impossible with our current knowledge base, without direct pathogenicity testing upon a host. These predictions will be tested and validated using existing datasets but also on new datasets gathered as part of this work."
B47F911A-4B80-40B6-BD1F-3002F3532D2E,"There are proteins that are well characterized with regard to their three dimensional structure. In particular it is known that parts of them act as &quot;functional&quot; units, e.g. active and binding sites or functional domains. However, within proteins, regions of intrinsically disorder occur and these are characterized by a lack of a well-defined three-dimensional structure. Although these disordered regions do not show a particular higher conformational state, they are known to be functionally important, such as through their involvement in protein-protein interactions or DNA/RNA binding. In a recent work we have shown that there is ongoing positive selection that contributes substantially to the evolution of human long intrinsically disordered protein regions. Furthermore, these protein regions are enriched in posttranslational modification sites as well as regions and motifs (annotated sequence stretches of biological importance), but surprisingly disease mutations tend to occur much less frequently in disordered regions (Uversky et al., 2014), with the exception of mutations associated with musculoskeletal diseases. 

This timely project aims to understand why disease mutations tend to be less frequent in disordered protein regions. The focus of this project will lie on the exceptional group of mutations involved in musculoskeletal diseases that are enriched in disordered protein regions by comparing them to those involved in other disease groups. Fundamental will be a novel genomic comparative approach currently developed in the Gossmann lab targeted at the identification of the evolutionary properties of disease-associated sites. Furthermore, in collaboration with Daniel Rigden from the University of Liverpool, we will conduct molecular dynamic simulations to investigate three dimensional features of disease associated mutations on protein flexibility and protein-ligand interactions. Furthermore we will exploit machine learning approaches to predict protein disorder on the single site residue effects. Experimental evidence and the underlying mechanistics of disease candidate sites can then functionally be tested in a fly model in collaboration with the Mirre Simons lab at the University of Sheffield. This will ultimately gain insights into whether disease mutations are genuinely less likely to occur in disordered protein regions or whether our lacking understanding of disease properties associated with disordered protein regions has led to an under-annotation in the respective databases. 

For this highly innovative, collaborative and interdisciplinary PhD the respective candidate should have a strong background in biology, molecular biology and genetics as well basic programming knowledge or at least a strong interest in computational approaches to investigate fundamental biological problems. A background in bioinformatics is of advantage, however all necessary approaches will be taught during the duration of the PhD. This project will take advantage of multiple biological &quot;big&quot; data sets, such as the 1000-Genome project, Uniprot, large-scale mammalian phylogenies and their respective whole genome information, as well as PDB and several secondary databases."
9A8784C8-87E1-4AD0-9A0B-7EF6B8554349,"This project will build upon preliminary work conducted by Argentine and UK partners which has already identified the presence of AMR in beef feedlots and generated the first large-scale dataset of beef farm antibiotic usage data (334 farms) anywhere in the world. It will also build upon a small existing grant of &pound;7,700 from UK ODA seed fund to help UoL academics develop a 'UK-Argentine Beef Antibiotic Research Network' which will be used to collect and analysis samples to optimize qPCR gene selection for environmental AMR quantification in beef farms, planned for Jan-June 2019. This preliminary work provides a very robust starting point for this project.

The project will use veterinary and epidemiology expertise and experience in quantifying antibiotic usage and agri-health economics expertise in mapping food value chains to build a theoretical antibiotic surveillance framework. This framework will be assessed against the available sources of information in other LMIC's to test its transferability especially in less well developed livestock systems including Kenya and Ethiopia, through existing projects which the UK the collaborators are engaged in (HORN project). 
The system would integrate all the available information on antibiotic prescribing and antibiotic usage along with the farm management practices across the whole range of beef farming systems in Argentina. We will then categorize antibiotic use at farm level recruiting between 200 - 1000 farms from an existing representative network of 4500 farms (organized via SENASA) into different management system types (eg. breeding, growing, feedlot finishing) and correlate the management practices used in these farms with their patterns of antibiotic usage by using the surveillance framework. The environmental AMR population load and diversity will be assessed in a stratified random sub-sample of (n = 50) of the farms according to management system type and AMU level &amp; usage practices. Multi-level modelling, cluster and principal component analysis will be used to quantify the agreement between the classification of farms based upon the AMU surveillance framework and the microbiological results to validate the efficacy of this means of risk assessment.

Deeper molecular analysis will be conducted on samples from farms with evidence of the most significant AMR diversity and load relating to High Priority Critically important antibiotics. This will include whole genome metagenomics and culture based antibiotic phenotype sensitivity to understand the population structure of the resistance profile of the most significant AMR environments. 
This phase of the project will allow us to use risk factor analysis to identify critical control points in the mode of antibiotic use in beef farms. This will be achieved by linking the molecular epidemiology data to detailed quantitative and qualitative interviews with farmers to understand the drivers of antibiotic use.

The final phase of the project will co-develop practical AMR reduction interventions and policy advice of regulatory authorities. All the interventions recommended will be based up the risk factor analysis and their economic impact tested by cost - effectiveness analysis to identify in a clear a reproducible manner the most appropriate control measures for each farm management system. The qualitative interviews conducted with each farmer in the study will inform decision making on barriers to adoption of individual measures and feed into the co-development of policy advice to the beef industry. The collaboration provides the exciting opportunity to compare and contrast approaches in the UK and Argentina to maximizing farmer adoption of new practices and advice. 

The project would employ two post-doctoral researchers (PDRAs) directly through the UoL. Whilst these two PDRA's will be employed by UoL they will be supervised jointly by UK and Argentine partner senior academics."
BD9690CD-621D-4E7E-BC1E-2771C516A286,"Evidence-led policymaking for COVID-19 control relies on accurate understanding the epidemiology of SARS-CoV-2 infections by correlating diagnostics, molecular fingerprinting and patient metadata (intrinsic (e.g. age), and extrinsic (e.g. travel history)). Efforts to correlate these data in Uganda are stalling, despite available local expertise, because laboratories designated for diagnosing and tracking COVID-19 are under-resourced, and widespread mistrust of diagnostic workflows. Current policy is therefore shaped by data from industrialised countries, which may be misleading due to significant differences in the population demographics and underlying health status.

Laboratory facilities in northern Uganda are lacking: i) reagents and experience of reliable workflows for processing of COVID-19 diagnostics; ii) whole genome sequencing equipment and consumables for providing robust epidemiological information. We will address these needs by bringing together UK-based academics and industrial partners with Ugandan biologists and policymakers to rapidly build local capacity for 
SARS-CoV-2 diagnostics and real-time epidemiology. Specifically: 

Transfer knowledge of SARS-CoV-2 diagnostic workflows from leading UK testing centres (NHS, Lighthouse Labs) to Uganda. 

Establish Nanopore sequencing and bioinformatics in northern Uganda, supported by Salford/Liverpool/COG-UK partners, and facilitate their long-term adoption by Ugandan laboratories (UVRI, Makerere University).

Combine WGS with new survey-based patient metadata to provide real-time SARS-CoV-2 genomics, including strains circulating around refugee settlements, to support the Ugandan Ministry of Health and Prime Minister's Office to promptly mitigate local and national COVID-19 spread.

Bring together industry and logistics partners with Ugandan policymakers, to identify and address bottlenecks in the equipment and consumable supply chain, to support cost-effective, future Ugandan bioscience."
33AAC290-0F4D-4638-89AA-FC9B3BBF8936,"Studentship strategic priority area:Basic and Clinical Research
Keywords:DNA replication stress, ovarian, glioblastoma, therapy, biomarker

Background
Faithful duplication of the genome is essential to cell division and requires complex regulation and assembly of nucleotides and replication factors to be completed efficiently. Disruption of these processes causes DNA replication stress (RS) manifest as slowing/stalling of replication forks and generation of DNA double strand breaks (DSBs) associated with activation of the DNA damage response (DDR). RS is a primary driver of genomic instability in cancer and an appealing therapeutic target due to aberrant tumour cell DDR and the absence of RS in normal cells. Both glioblastoma (GBM) and high grade serous tubo-ovarian carcinoma (HGSC) demonstrate genomic instability and activation of DDR, with underlying RS implicated in this phenotype. Recent advances in DDR targeted therapy include approval of PARP inhibitors in platinum sensitive relapsed HGSC, ongoing phase I/II trials of olaparib with radiotherapy and/or temozolomide in GBM, and proposed trials of combined ATR and PARP inhibition (CAiPi) in GBM and HGSC. Robust biomarkers allowing patient selection through identification of tumours exhibiting elevated RS and aberrant RS responses will be key to the clinical success of these approaches. This project will identify predictive biomarkers for RS targeted therapy in GBM and HGSC for validation in forthcoming clinical trials.

Aims
1) To characterise RS levels/responses to Pi, Ai and CAiPi in panels of HGSC and primary GBM cell lines 
Ai, Pi and CAiPi responses will be correlated with levels of RS using DNA fibre assays, DDR protein immunofluorescence, existing RNA sequencing data and mechanistic insights from identification of proteins on nascent DNA (iPOND).

2) To investigate genomic determinants of response to CAiPi
Existing whole genome sequencing data of GBM cell lines will be analysed to investigate genomic and structural abnormalities associated with differential responses (Collaboration; D McArt, Belfast UK). Breaks labelling in situ and sequencing (BLISS) will investigate the influence of genomic sites of CAiPi generated DSBs on response. 

3) To validate candidate biomarkers in vivo and in existing clinical datasets
Candidate biomarkers will be validated utilising intracranial xenografts from GBM cell lines exhibiting differential sensitivities to Ai, Pi and CAiPi. Prevalence of candidate IHC biomarkers will be quantified in existing clinical datasets for HGSC (SCOTROC 1, 4) and GBM (OPARATIC, PARADIGM, PARADIGM-2) and recurrent GBM datasets.

Training Outcomes
This project provides excellent exposure to basic and complex techniques including primary cell culture, immunofluorescence, Western blotting, BLISS, iPOND and in vivo models. The student will become proficient in analysing data from whole genome/RNA sequencing and develop expertise in statistical analyses necessary for pre-clinical development of biomarkers for novel therapies. 

The project has strong commitment from Astra Zeneca as an industry partner who will provide invaluable experience and insight in a non-academic setting and the opportunity to work with commercially minded scientists on applied research.The studentship meets several MRC DTP strategic priorities in quantitative skills and whole organism physiology. The student will gain skills in bioinformatics analysis of genomic and transcriptomic data, basic and translational laboratory research and in vivo studies.

Conclusion
This project will identify biomarkers of response to DNA replication stress targeted therapies in HGSC and GBM by utilising genomic and transcriptomic characterization of HGSC and GBM cell line panels, with validation in in vivo tumour models and clinical trial datasets with corresponding outcome data. This will provide a precision approach for optimal utilization of DDR targeting therapies in the clinic."
D2D93BC9-8505-49B7-BA53-DE02E16E2BBC,"The list of organisms with completed genome sequence is continuously growing and this has led to the identification of thousands of genes whose function is still unknown. These genes could potentially be involved in important biological cell functions and could represent important targets for diagnostic and pharmacogenomics studies and be of industrial and agronomical importance. A major undertaking for biology is therefore that of identifying the function of these uncharacterized genes on a genomic scale. The challenge for bioinformatics is then to devise algorithmic methods that, given a gene, can predict a hypothesis for its function that can then be validated by wet-lab assays. Luckily, new experimental techniques have become available, producing data which offer clues about protein function and can therefore be employed for function prediction, e.g. protein interaction data, gene expression data. Some experimental and computational data have a natural representation as networks (e.g. protein interaction data), others are inherently 'one-dimensional' (e.g. sequence patterns). Three facts have recently become clear: while each data type contains important information that can help in determining the function of a protein, no single data type by itself suffices; large-scale functional inference greatly improves by integrating evidence from different sources; for those data types which can be represented as networks, the best results are obtained by algorithms that take advantage of the networks' topologies. So far, methods that make functional inferences on networks are very limited in the type of data they can integrate, while methods that can integrate a greater variety of data do not take advantage of the networks' topologies. I intend to investigate a general method that can integrate essentially any data type currently available taking into account its intrinsic structure: it takes advantage of the graph topology for network data, and it can integrate this evidence together with one-dimensional information. I shall develop graph-theoretical methods that use the diffusion of information over graphs to generate functional evidence from network data. This evidence is then combined with other one-dimensional information using machine learning techniques. The strength of the methodology lies in its ability to use diverse sets of noisy data, and to combine them to obtain sound statistical inferences; the weak signals contained in each dataset is enhanced by integrating the data. The methodology will be first developed on Yeast, and I shall then transfer this approach to higher organisms such as C. elegans, D. melanogaster, A. thaliana, and H. sapiens. For all these organisms the performance of the algorithms will then be evaluated 'in silico' by means of test sets; that is I shall verify the accuracy of the methods at predicting the function for genes whose annotation is known. The approach will then be tested 'in vivo' on a sub-network of genes that form signalling pathways (MAPK signalling) and function to transmit information from receptors to gene expression. MAPK pathway components are highly diversified in the model plant, Arabidopsis thaliana, with 123 components. For many of these we do not know how they connect up and what their biological functions are. These will be predicted by the algorithms and then functionally tested by silencing their expression using RNA interference and in mutant lines. I shall also design and implement stand-alone and web-based software tools incorporating the algorithms developed. The applications will enable the biologist to easily apply the algorithms through a user-friendly interface; to visualize the relevant biological networks thus making the inference process transparent and providing an explanation for the functional annotation predicted by the system. A web tool will also be created. All these tools will be made freely available to the scientific community."
3F7A73C3-D96E-4E17-AAD2-B5D26D4CD1C8,"Existing classification systems do not adequately describe the diversity of human disease, nor do they account for common mechanisms across diseases. Since underlying mechanism often predicts therapeutic efficacy, a mechanism-based taxonomy of disease is required to unlock therapeutic progress. A data-science approach provides the framework to address this unmet need by integrating diverse patient data from genotype to disease outcomes. Heart failure (HF) is a complex clinical syndrome for which rising prevalence stands in contrast to a lack of effective therapeutic options. This project seeks to reclassify HF patients according to underlying causal mechanisms through analysis of harmonised patient data from HDR London, UK Biobank and the HERMES Consortium (a major global collaboration in HF genomics founded by the applicant) using emerging genome bioinformatics and unsupervised learning methods. The overall aim is to identify and validate molecular pathways as candidate targets for novel therapeutic intervention and to provide an exemplar within HDR UK for novel approaches to the study of complex disease. 

Objective 1. Define the contribution of common genetic variation to risk of HF and clinically established sub-phenotypes. 
A genome-wide association meta-analysis (GWAMA) of &gt;32,000 HF cases from 25 studies has been completed by the HERMES Consortium, yielding variants at a number of loci. To investigate sub-significant association signals, I will perform an extended analysis with &gt;60,000 HF cases (HERMES, HDR London and UK Biobank) and investigate HF subgroups defined by comorbidity (atrial fibrillation, coronary heart disease) and left ventricular phenotypes by stratified analysis. The results of these analyses may enable the identification of novel causal genes and will form the starting point for investigating clinical and genetic heterogeneity (Objective 2). In addition, they will provide the HF outcome dataset for target validation Mendelian randomisation analyses (Objective 3). 

Objective 2. Identify and characterise new HF sub-phenotypes using clinical, EHR and genomic data.
Preliminary analyses indicate that HF risk variants exhibit allelic heterogeneity among HF subtypes defined by comorbid disease status. The observed clinical and genetic complexity suggest an opportunity to define a new, data-driven taxonomy. As well as studying established HF subtypes, I will use unsupervised learning methods (machine learning) to uncover new HF disease clusters based on phenotypic similarity. To explore genetic heterogeneity of HF subgroups, I will test for differences in HF-associated allele frequencies from Objective 1 using locally available, individual participant level data. To validate these findings, I have established a collaboration with investigators from Harvard/ MIT and Boston University. Using these approaches, I will seek to define a data-driven taxonomy of HF subtypes and to provide insights into mechanisms through genomic analysis.

Objective 3. Discover and validate therapeutic targets for heart failure subgroups through genetic causal inference analysis. 
Genetic variants that alter the abundance or function of gene transcripts or their cognate protein can serve as instruments to explore the causal role of a protein in a disease outcome using Mendelian randomisation analysis. The genetic determinants of a many circulating proteins are known and can be used to investigate potential therapeutic targets in HF and/or HF subtypes (from Objective 2). I will prioritise proteins for study based on the presence of prior observational associations or other evidence of a causal role in disease. For proteins with evidence of a causal role, I will seek to characterise the mediators of effect by exploring the association of the genetic tool variants with related imaging and EHR phenotypes, to inform the conduct of clinical trials."
F83813D2-1A0F-488F-A193-C66557840E81,"Enhanced Biological Phosphorus Removal (EBPR) is a variation of the activated sludge technology that in addition to removal of organic matter using a microbial consortium, enacts phosphorus removal from the influent wastewater to prevent eutrophication of the receiving body. Like activated sludge, wastewater treatment plants employing EBPR are known to suffer from poor performance attributed to population imbalances of the functional microorganisms. An understanding of the root causes behind the deteriorated performance, and of the reliable corrective measures have thus far proven themselves elusive.
Advances in culture-independent microbiological techniques and metagenomics have stimulated work towards the in situ characterisation of microbial communities in these systems in terms of their diversity, relative abundance of the representative individual phyla, as well as their respective functional ecology. Complementing this work are laboratory-scale studies utilising highly enriched bacterial cultures, as well as surveys of full-scale facilities which correlate the relative abundance of perceived core members of the microbial community of interest in tandem with physiochemical analyses to their respective function. In its current form however, the nature of the available information remains fragmented and, owing to the isolation in which it was produced, inconclusive - not to mention that with regards to understanding the reported instability of the technology, contradictory.

In light of this, the overall aim of this PhD project is to develop and deploy statistical models with which to evaluate and unite elements of the (1a) composition of the microbial community, (2a) their respective ecological function and inter-phyla interactions and (3a) process design and operation.
The component objectives of this project thus include but are not limited to: (1b) collecting and framing the existing pool of information into a unified working database; (2b) constructing a network model with which to represent, link and evaluate the assembled data; and (3b) investigating and assessing relevant statistical tools such as a self-learning Bayesian statistical models in order to make use of the available evidence to infer the nature of the relationships among different groups within EBPR microbial consortia, their relation to the process configuration and operational parameters and environmental conditions.

The ambition of this project is to improve the holistic understanding of the microbial consortia relevant to EBPR. In particular, the potential impact of this project will (1c) enable the formulation of concrete strategies to cultivate the right communities that would ensure consistently satisfactory performance, and therefore compliance, of wastewater treatment facilities employing this technology, (2c) provide the framework for design optimisation of future EBPR processes and (3c) provide the tools to enable systematic identification of knowledge deficiencies, thereby providing a roadmap of key areas of future research.

In a broader sense, the proposed tools to be developed in this project could find application in the exploitation of any biological system, answering questions such as: (1d) which are the key parameters to monitor in full-scale treatment and/or production facilities to ensure efficient performance, (2d) what is the (smallest) required sample size of this pool of data, (3d) how can one make use of the data already available, or (4d) how to define crowd-sourcing strategies for better informed decision making.

This project will connect the field of water engineering to that of statistics &amp; applied probability, two among the key growth areas as indicated by the EPSRC thematic research portfolio."
97A5EEC4-8242-4AF1-95F0-FE9B59061C7C,"Studentship strategic priority area:Mathematics, statistics and computation
Keywords: Data science, bioinformatics, metagenomics, microbiome, virome

The advent of high-throughput sequencing (HTS) has led to an increasing deluge of metagenomic sequence data being deposited in online archives. HTS has enabled the routine detection of known pathogenic viruses, the discovery of novel human viruses and human-resident phages, and the characterisation of the human virome, which is essential for our understanding of the role the microbiome plays in health and disease. However, a significant proportion of sequence data cannot be classified as it displays no detectable homology to any known sequence, and such sequence data is typically discounted from further analyses. The aim of this PhD project is to develop a complete computational framework for the data mining of online archives for 'dark' sequence data, combined with the assembly, storage, clustering, and initial classification of such dark sequences. The project will answer fundamental questions related to the extent and diversity of dark sequences, classify these sequences into related groups, and predict their biological function and origin. There are 3 broad stages: (1) The development of data mining pipelines to automatically retrieve meta and sequence data from the short read archive. (2) The adaptation of existing metagenomic assembly pipelines towards sequences of unknown origin, and the development of a database system to store and query the assembled dark sequences. (3) The quantification, analysis and clustering of the identified dark sequences. The project is a combination of data science and bioinformatics, with substantial elements of computation, programming and statistics/machine learning. The student undertaking this PhD will be trained in a number of MRC priority quantitative skills area. The project is a combination of data science and bioinformatics/computational biology, with substantial elements of computation, programming and statistics/machine learning."
08F8CFC9-49BB-4F82-AA82-D9D6559FCEE9,"There have recently been significant leaps in deep reinforcement learning algorithms, with notable successes in games such as Atari arcade games and Go; however, there is still a need to adapt these techniques to be more widely applicable in other domains, such as the life science sector. Identifying regulatory relationships between genes is one of the primary research activities carried out by molecular biologists and geneticists, since learning the structure of gene regulatory networks is critical for many applications, for example understanding the origins of many diseases and how crops respond to their environments. Biologists sequentially conduct experiments that provide information about the gene network structure, but they must operate under strict cost and time limits. This project aims to formulate this experiment design procedure in a reinforcement-learning framework, to ascertain how biologists should prioritise experiments to maximise information about the gene networks, under constraints. The primary deliverable will be a Computer-aided Experimental Design (CoED) software tool to aid researchers in utilising their resources most effectively. This reinforcement-learning framework could also be used to identify the bottlenecks for biomedical research, such as the pricing model or the time-intensity of certain experiments, thereby identifying the most impactful areas for further development in experimental methodology. We will deliver impact by providing consultation services to laboratory supply and service providers, and through our collaboration with our industrial partner Google Brain Genomics. This project primarily aligns with the new approaches to data science and high productivity services through specialised artificial intelligence priority areas of this call."
B3B44649-897A-435B-A188-032BEB8403C8,"The processes of life are dynamic - it is change on a molecular level that enables us to grow and move, but also to become ill and treat disease. Just as the shape and posture of our body can determine our readiness to perform a task, the structure and conformation of a protein molecule can determine its function or activity. It is the ability for proteins to dynamically and rapidly reconfigure that underpins many critical activities in biology, disease and medicine.
However, we are currently limited to study proteins, including many important enzymes, at high resolution in space or time - but not both. Static structural models have contributed to major advances, such as in gene editing technology, based on the reprogramming of the enzyme 'CRISPR/Cas9'. This structural information is also crucial for drug discovery, accurately guiding design and optimisation efforts.
These are major new applications that rely on precisely controlling dynamic changes in protein structure. These aims - and our understanding of fundamental biology - will be greatly advanced by bridging high resolution information in both time and space.
My research will pioneer an integrated experimental and computational approach to determine with unprecedented spatio-temporal resolution how enzymes are dynamically regulated and how they catalyse chemical reactions. We now have a unique opportunity to make measurements of the structural perturbations in large enzymes both with high structural resolution (per amino acid building block) and high temporal resolution (per millisecond). The information that we gain will be used to build high resolution dynamic structural models in which individual features reconfigure according to their individual rates, determined experimentally with millisecond and amino acid precision. 
This work will focus on two areas of recent high profile success in developing tools for biotechnology and medicine which depend on the exquisite control of enzyme dynamic structural changes. (i) Gene editing: There is a growing effort to engineer CRISPR/Cas9 enzymes to improve their efficiency and to create entirely new tools for targeted mutation of the genome in situ. This has potentially broad application in research, but also to specifically treat genetic diseases. We will study gene editing enzymes to provide mechanistic insight to explain their behaviour and to guide the development of variants with improved activities. (ii) Allosteric drug discovery. There has been major recent investment by both big pharma and by venture capital/biotechnology partnerships to discover 'allosteric' drugs that control enzyme function by controlling the protein conformation. These drugs have potential benefits in selectivity and the ability to modify otherwise intractable targets in disease. We will ascertain whether the new millisecond time-resolved measurements that we will develop can differentiate signatures of allosteric regulation and thus form the basis of a direct screen for allosteric drugs.
This research programme brings together expertise in building novel experimental methods, cutting edge data science approaches, development of new software tools and a direct relevance to fundamental biology and applications in biotechnology and drug discovery."
F17AEE0A-513C-494E-BE3B-563E886BB6A7,"Staphylococcus aureus is a major cause of morbidity and mortality worldwide. The burden caused by this opportunistic pathogen to global human health is compounded by the prevalence of antibiotic resistant strains, which the World Health Organisation predict will contribute to greater than 300 million premature deaths worldwide by 2050. There is, therefore, an urgent need to identify novel therapeutic targets. Ribosomes are responsible for one of the key growth processes in both eukaryotic and prokaryotic cells - the synthesis of proteins. As these molecular machines are so complex, the assembly process is quite tightly regulated. As such, correct maturation of the ribosome requires assembly cofactors. One class of assembly cofactors are the GTPases, which have a range of functions associated with ribosomal development. As assembly cofactors are multiple in number, are crucial for ribosome maturation, and are broadly conserved throughout the bacterial kingdom, they represent novel targets for broad-spectrum antibacterial drug discovery.
Our recent work has utilised a genome-wide screen to identify binding targets for a small nucleotide, ppGpp, in S. aureus. This has led to the discovery of five GTPases with predicted functions as ribosomal assembly cofactors. We show that the activities of all five enzymes are inhibited by ppGpp and initial characterisation confirms that at least one of these enzymes plays a role in ribosomal biogenesis, with a deletion of this gene negatively impacting bacterial growth. In order to determine the contribution of all five GTPases to bacterial survival and initiate the development of an antimicrobial that could potentially target all five simultaneously and so Iimit the development of resistant strains, we will be undertaking a multi-disciplinary approach which includes bacterial genetics, antimicrobial susceptibility testing, enzymatic assays, coupled with protein purification and structural determination of the apo and ppGpp-bound forms of the proteins. 
Scientific objectives
1. Examination of the contribution of each GTPase to bacterial growth and ribosome assembly:
Gene deletion mutants, as well as GTPase-inactive protein variants will be created to allow the contribution of each enzyme to bacterial growth, cell morphology and ribosomal assembly in vivo to be examined.
2. Determination of the mechanism of ppGpp-mediated enzyme inhibition:
The GTPase enzymes will be purified and the structures analysed by X-ray crystallography in the presence and absence of ppGpp and GTP (supervised by secondary supervisor) in order to determine precisely how this molecule can inhibit GTPase activity. This will form the basis of future rational drug design based on the structure of ppGpp.
3. Screen to identify other GTPase inhibitors:
A library of 2,000 compounds, including FDA-approved drugs and a natural-products library, is readily available from the small molecule screening facility here at the University. This library will be screened in order to identify molecules that, like ppGpp, can inhibit the GTPase activity of these five proteins. Crystallography will also be performed on any positive interactions to determine the mode of inhibition.
Altogether this project will provide important mechanistic data on the importance of these GTPases for bacterial survival and will lay the foundation for future rational drug design."
9B3E1E26-280F-4420-99F0-5A227B868C61,"The aim of this project is to develop new methods for intelligent feature selection, that will allow advanced joint modelling of vast imaging and genomics data sets, for the purpose of determining new gene candidates for targeted neuroprotective therapy of vulnerable preterm infants. Imaging genetics is an emerging field that has huge potential to improve understanding of complex neurological conditions, through identifying concrete links between morphological or functional changes in the brain and genetic variants linked to disease. Unfortunately, the immense numbers of imaging and genetic features involved challenge current methods of analysis, limiting their capacity to find statistically significant relationships from the data. This project will therefore use advanced techniques from sparse predictive modelling and Deep Learning to intelligently compress and combine state-of-the-art multi-modality, developmental imaging and genomics data sets so as to propose sensitive genotype-phenotype candidates as targets for future clinical trials."
4197D20A-6254-4D76-985D-52AD77AD4C1A,"This MRC-funded doctoral training partnership (DTP) brings together cutting-edge molecular and analytical sciences with innovative computational approaches in data analysis to enable students to address hypothesis-led biomedical research questions. This is a 4-year programme whose first year involves a series of taught modules and two laboratory-based research projects that lead to an MSc in Interdisciplinary Biomedical Research. The first two terms consist of a selection of taught modules that allow students to gain a solid grounding in multidisciplinary science. Students also attend a series of masterclasses led by academic and industry experts in areas of molecular, cellular and tissue dynamics, microbiology and infection, applied biomedical technologies and artificial intelligence and data science. During the third and summer terms students conduct two eleven-week research projects in labs of their choice. 

Project:
In early embryos of many animals, maternally provided RNAs and proteins control the earliest developmental processes. This includes the distribution, stability and activity of RNAs involved in cell fate specification events. How RNA molecules are targeted to specific sub-cellular and embryonic regions and how their activity is regulated is not fully understood. For instance, how the germ plasm, a specialised complex of RNAs and proteins essential for germline and sexual development, is stabilised and distributed in early embryos is not understood. The sequence, structure and, more recently, modification of RNAs (such as m6A) has been shown to regulate their localisation and activity. A small set of proteins that recognise the modifications and modulate the RNAs have also been identified, but their mechanisms and functions are not fully understood.
 
Recent studies have reported a number of m6A-related diseases in humans, including cancer and metabolic disorders, such as obesity. Therefore, it is vital we understand precisely the roles of this modification in development and homeostasis. This project aims to study the role of RNA modifications and the proteins that recognise them during early embryonic development in zebrafish focussing on a known m6A reader, Igf2bp3. Zebrafish is an ideal model organism to study these processes as there are functionally equivalent early development factors in humans and zebrafish, and many fundamental mechanisms are conserved. Igf2bp3 has recently been shown to be important for early embryonic and germline development (Vong et al., 2021). 
 
Using RNA-sequencing the project aims to understand the molecular basis of defects in igf2bp3 mutants. The role of specific candidate RNAs will be addressed using genome editing using CRISPR/Cas9, transcriptome-wide gene expression changes and phenotype analysis. Through the project, the student will adopt an interdisciplinary approach that combines embryology, bioinformatics, genome engineering and in vivo imaging and gain skills training in quantitative and interdisciplinary skills, healthy ageing through the lifecourse and whole organism physiology."
97807058-826F-43B3-BFD7-513E9AA24799,"The project aims to understand the mechanisms influencing RNA polymerase II (pol II) -mediated transcription, their relationships with each other and how they affect transcriptional dynamics. The primary process of interest will be polymerase pausing, in which the elongation rate of pol II is greatly reduced at certain sites. The nature of pausing will be investigated by attacking the problem from multiple angles using a variety of data types. The recently developed time-variant PRO seq (TV-PRO seq) allows for genome-wide detection of pausing sites and measurement of pausing times. TV-PRO seq data will be linked with other data types, including ChIP seq data on distributions of histone modifications, NET seq data on pol II distributions, ATAC seq data on chromosome accessibility, single cell RNA seq data on mRNA levels and variability and SLAM seq data on mRNA degradation rates. Statistical analysis of integrated data sets to find correlations between pausing sites and other genomic features will provide mechanistic insights. Mathematical models of transcription will be constructed that account for various mechanisms and processes of interest, including pol II pausing, initiation, reinitation from the gene's 3' terminus and spontaneous disengaging. The models will be designed to provide read-outs that can be directly compared with the aforementioned data, such as polymerase and nascent mRNA distributions along the gene, as well as mature mRNA count distributions. This will allow theoretical exploration of the interplay between different mechanisms and how they contribute to the stochastic dynamics of gene expression. Simulation/analytical results will be fitted to the data, using Bayesian inference to, for example, optimise parameter values and model structures. Conclusions made regarding transcriptional mechanisms/dynamics will be confirmed with experimental verification. Insights regarding stochasticity in transcription may have applications in synthetic biology."
921F5C28-0C3F-488C-B763-47C666332698,"In our work in the current edition of the CMIH we have built up a strong pool of researchers and collaborations across the board from mathematics, statistics, to engineering, medical physics and clinicians. Our work has also confirmed that imaging data is a very important diagnostic biomarker, but also that non-imaging data in the form of health records, memory tests and genomics are precious predictive resources and that when combined in appropriate ways should be the source for AI-based healthcare of the future.

Following this philosophy, the new CMIH brings together researchers from mathematics, statistics, computer science and medicine, with clinicians and relevant industrial stakeholder to develop rigorous and clinically practical algorithms for analysing healthcare data in an integrated fashion for personalised diagnosis and treatment, as well as target identification and validation on a population level. We will focus on three medical streams: Cancer, Cardiovascular disease and Dementia, which remain the top 3 causes of death and disability in the UK.

Whilst applied mathematics and mathematical statistics are still commonly regarded as separate disciplines there is an increasing understanding that a combined approach, by removing historic disciplinary boundaries, is the only way forward. This is especially the case when addressing methodological challenges in data science using multi-modal data streams, such as the research we will undertake at the Hub. This holistic approach will support the Hub aims to bring AI for healthcare decision making to the clinical end users."
401406A4-00B2-479F-8144-5F667BFB2919,"This project will train a BioDesign engineer, who can develop novel therapeutics by applying repeated cycles of &quot;learn-design-build-test&quot; using mathematical modelling and synthesis of microbiomes. We will specifically bio-design a next-generation treatment for atopic dermatitis (AD, also known as eczema), a very common devastating chronic skin disease with high socioeconomic burdens. Controlling skin microbiome has been recently demonstrated as possible novel AD treatment. However, the mechanisms behind these potential interventions and the role of skin microbiome in the pathogenesis of AD remain to be elucidated, making systematic design of new treatment challenging.

The project will build directly on the engineering methodologies developed in the Tanaka group to design personalised AD treatment strategies using mechanistic modelling and machine learning, and the Ledesma-Amaro group's cutting-edge techniques of engineering microbiomes using synthetic biology. The project will give the student the opportunity to make a direct impact on a clinically important problem. We will apply a rigorous BioDesign engineering approach to elucidate mechanisms by which controlling skin microbiome could improve AD symptoms and to design microbial population that provides protection against AD development.

Our BioDesign engineering approach will allow us to think beyond the current limits of AD treatment and develop therapeutics of future by combining mathematical modelling, genome engineering and synthetic microbial communities."
71727EA3-F3B6-444E-9D12-54BD3D507912,"Brief description
Epilepsy is a group of neurological conditions that share the common characteristic of epileptic seizures. There are many types of epilepsy and many types of seizure. The diagnosis of epilepsy typically follows the occurrence of two or more seizures. While anyone can develop epilepsy at any point in life, it is most commonly diagnosed in children and people over 65 years of age. Currently, about 60 million people are suffering from epilepsy worldwide and over 500,000 in the UK alone. 
 
Anti-epileptic drugs (AED) are intended to reduce the frequency of seizures or even completely eliminate them. If AED treatment works, it allows people living with epilepsy to lead normal lives. However, in about one third of people none of the available drugs or combinations of drugs stop the seizures. These cases are considered treatment-resistant epilepsies and the underlying biology is still poorly understood. 

Aims and objectives
In this project, we will help to advance knowledge about drug-resistant epilepsy. Using a large database of neuroimaging data from people with epilepsy, the first aim is to establish the imaging signature of drug-resistant epilepsy compared to drug-responsive epilepsy. That is, which brain regions show different cortical thickness or structural and functional connectivity changes in resistant vs responsive epilepsy? The second phase of the project involves an imaging-genetics approach to elucidate the genetic origin of drug-resistant epilepsy, which may help to identify drug targets for currently drug-resistant epilepsy.

Novelty of the research methodology
In this research project we will combine high-dimensional imaging data with high-dimensional genetics data (e.g., whole genome genotyping) in thousands of subjects. To make the research feasible this will require to adapt and modify existing machine learning methods and, more importantly, work towards methodological solutions that will enable us to leverage existing knowledge about genome organisation and molecular biology.

Alignment with EPSRC's strategies and research areas
This project is aligned with 'Healthcare technologies' grand challenge. In particular with 'optimising treatments'. The methodological contribution will be on data analytic methods to identify disease phenotypes. 

Companies and collaborators involved
UCB Pharma (https://www.ucb.com/)
Prof. Sanjay Sisodiya at UCL (https://iris.ucl.ac.uk/iris/browse/profile?upi=SMSIS90)"
E14BD0ED-1729-434E-A68D-4BAA2CF37F1F,"What does the genetic make-up of RNA viruses look like? All genomes are composed of four bases, A, C, G and T (or U in the case of viral RNA genomes and mRNAs). If these were selected randomly, every genome would comprise 25% of each base; but this is not the case. Similarly, there are 16 possible combinations of nucleotide pairs, or dinucleotides. With random representation, each dinucleotide would occur 1/16 or 6.25% of the time, but again this is not so. In the genomes of all organisms, from bacteria to humans, TpA dinucleotides ('p' represents the phosphate bridge in the DNA backbone) are under-represented. We don't know why this is. Even more intriguingly, RNA viruses mimic this by suppressing UpA in their genomes.

When a virus infects a host cell, this triggers an interferon response that results in hundreds of antiviral genes being upregulated. One such gene is RNaseL. In 1981 it was reported that mRNA is cleaved at UpA motifs by RNaseL. This offers one possible explanation for why UpAs are suppressed in the genomes of viruses and their hosts. However, when UpAs are added into virus genomes, the virus is impaired, but depletion of RNaseL from the system does not remove the impairment, suggesting other factors are at play.

Alternatively, UpAs may be avoided to reduce the risk of introducing stop codons. Two of the three stop codons (UAA and UAG) include UpA motifs, and if UpAs are deselected the chances of aberrantly introducing stop codons in protein coding sequences are reduced. 
The purpose of this interdisciplinary project is to integrate computational (Lycett lab) and laboratory (Gaunt lab) based methods to characterise the distribution of UpAs in RNA virus genomes, and establish their importance in a virus system. Specifically you will:
1. Determine the distribution of UpA motifs in selected RNA viruses by assessing whether their frequencies are different in coding and non-coding regions, whether UpAs occur within or across codon boundaries, and whether they correlate with the occurrence of stop codons or are utilised / deselected under different pressures. 
2. Use this understanding to design and synthesise mutants of influenza A virus with increased UpA content, and characterise the impact of UpA introduction on virus replication. You will test whether removal of RNaseL (and other factors) from the system abrogates the anticipated defect in virus replication.
3. If RNaseL restricts virus replication, you will characterise the mechanism. If RNaseL is not restrictive, you will use a small screen based approach to identify cellular factor(s) that are important for UpA recognition by the host cell. 

From this project, you will learn data science skills, applied to biological data - including statistical, bayesian, machine learning and evolutionary modelling, (bio)informatics, phylogenetics and phylodynamics, as well as computing skills including how to code, script and use high performance computing; and laboratory skills including how to perform virus infections and virology assays, and molecular biology techniques including CRISPR."
A04E7990-12A8-4279-9C48-496FB9584DBA,"The broad aim of the PhD is to harness the genetic potential for arbuscular mycorrhizal (AM) symbiosis in rice. Recent establishment of the high coverage, 3000 Oryza sativa (rice) genome sequence dataset through international effort at the International Rice Research Institute (IRRI), Philippines, provides a unique opportunity to investigate genetic diversity in AM symbiosis. In addition, identification of a novel shoot metabolite marker of AM fungi-association- blumenols- allows for development of a high-throughput screening method to interrogate variation in AM outcome between accessions. This provides a strong basis for a Genome Wide Association Study (GWAS) aiming to identify candidate gene variants required for AM symbiosis in rice.

The project aim requires attention to the following objectives: 
1. To develop a precise, robust protocol to give consistent, blumenol-derived AM colonisation phenotypes on infection of genetically and physiologically variable rice accessions with Rhizophagus irregularis. 
2. To perform a GWAS at the International Rice Research Institute aiming to identify candidate gene variants required for AM fungal associations. 
3. To characterise and validate the functional and ecological relevance of the identified gene variants. 

The project will be co-supervised by Dr. Uta Paszkowski, Department of Plant Sciences, University of Cambridge and Dr. Amelia Henry, International Rice Research Institute (IRRI), Philippines. It will involve a first year at the University of Cambridge to establish a reliable protocol for characterisation of colonisation of diverse rice cultivars by R. irregularis. Variation can often be observed in progression and establishment of AM colonisation so this will ensure that the marker phenotype is consistent. In addition, the robustness of the 'blumenol detection' method for detecting variation in AM colonisation in rice plants will be confirmed through collaboration with Prof. Ian Baldwin at the Max Planck Institute for Chemical Ecology, Jena, Germany. The established protocol will then be taken to IRRI, Philippines to conduct the genetic screen during the second year. The final years will then be back at the University of Cambridge to characterise and validate gene variants identified.

The proposed studies will deliver donor materials, QTLs and associated marker systems for introgression of QTLs into upland breeding programs. Thus through use of marker-assisted-backcrossing approaches they will readily translate to products, which, once disseminated through IRRI's network with national partners, will have direct impact in upland farmers' fields, and will be evaluated for their utility in wider water-saving rice production systems."
909C5FA4-F16E-4B83-ABF2-B620E51CC945,"Why do stressful events have a long-term impact on the brain? With the tremendous rise in the number of people suffering from stress-related mental disorders finding an answer to this question is more important than ever. Stressful events can have a long-lasting impact which includes the formation of memories of such events. Usually, these memories help the individual to cope with the experience and be better prepared in case of a similar event. However, a mental health problem (e.g. post-traumatic stress disorder (PTSD), major depression, anxiety) can develop if a situation is extremely traumatic or exposure to stress becomes chronic. It is still not clear how the brain processes stressful challenges. It has been well established though that stress-induced glucocorticoid hormones play a key role through their actions on a part of the brain (the hippocampus) that is crucial for responding to stress including the formation of memories of the stressful event itself. Interestingly, the hippocampus is one of the main brain systems where new neurons are incorporated throughout life. Adult neurogenesis, plays a principal role in memory formation of events and places and is sensitive to stress. We recently found that glucocorticoid hormones, through binding to their receptors (the mineralocorticoid and glucocorticoid receptors (Mifsud &amp; Reul, Proc. Natl. Acad. Sci. USA 2016)), influence the expression of more than 60 neurogenesis associated genes in the hippocampus. This is a significant step forward in the investigation of the effects of stress on the hippocampus in terms of stress coping and memory formation. The aim of this project is to elucidate the role of glucocorticoids in the effects of stressful challenges on hippocampal progenitor pools and neuronal differentiation and maturation. This multidisciplinary research will be conducted both in stress/behavioural models (stress coping, memory formation in adolescence, adulthood, ageing) in vivo and in primary cell culture/progenitor cell lines in vitro. The successful PhD student will apply various state-of the-art technologies including epigenetic (chromatin immuno-precipitation (ChIP), bisulfite pyrosequencing (for DNA methylation analysis)), molecular (RNA, genome analysis, gene silencing), neuroanatomical (RNAscope, double/triple immuno-fluorescence), cell culture (primary/progenitor cell lines), experimental animal (behavioural models), and bioinformatics (R, Bioconductor, Ingenuity Pathway Analysis) technologies and methods. This project will be supervised by Professor Johannes Reul, Dr Oscar Cordero Llana and Dr Karen Mifsud at the University of Bristol and Professor Jonathan Mill at the University of Exeter."
CCAACDFD-24CE-4BD6-8087-3E300040E797,"My project is with the Complex Traits Genetics group, supervised by Dr Sara Knott, Dr Pau Navarro and Prof Chris Haley. The aim of the project is to utilize bioinformatics and statistical analyses alongside existing data on gene annotations and locations of mutations to characterize genetic variants that affect disease phenotypes. 

A major aim of precision medicine is to provide personalized treatment for disease, where much of this personalization is based on patient genotype. This relies on a good understanding of genotype-phenotype relations, specifically the causal connection behind certain mutations and their resulting diseases. In an unprecedented era of accurate and abundant genome sequencing, a major challenge is processing the vast amounts of data to provide useful results for clinical targets or drug development. Genome-wide association studies (GWAS) have been tremendously successful for particular diseases in identifying single-nucleotide polymorphisms (SNPs) - base substitutions at a single point in the sequence - that are causally linked to disease phenotypes. However, for most phenotypes we have not uncovered causal mutations, but associated ones, i.e., for most of the associations between SNP variants and phenotype, the specific variant causing the disease and the underlying molecular mechanisms remain unknown. We can supplement GWAS data with gene annotations from genome browsers such as Ensembl, using logistic regression to build multi-variate models that highlight the most influential annotations. Previous members of the group assessed the enrichment and depletion of genetic variants in 54 annotation classes, including genic regions, regulatory features, measures of conservation and patterns of histone modification (see Kindt et al, 2013). This research showed that SNPs associated with the enriched annotations were 8 times more likely to be trait-associated than variants annotated with none of them. 
In my PhD project, I aim to further develop these methods to build generalized models for uncovering disease mechanisms. I will find mechanisms that underlie variation across phenotypic categories, including several omics, and those that are different across categories of disease-related phenotypes (such as protein or lipid levels and DNA methylation) and disease (such as diabetes or different types of cancer). I will then conduct further analysis on the most promising findings at trait and region level, using colocalisation and causality analyses, to determine mechanism of causation and control of disease variation. 
Kindt et al. (2013) The genomic signature of trait-associated variants. BMC Genomics 14, 108 https://doi.org/10.1186/1471-2164-14-108"
44D7EA6C-768F-4540-BEA5-E1FFEDC787DF,"Crohn's disease and ulcerative colitis are the common forms of inflammatory bowel disease affecting up to 1 in 100 people in the UK. Incidence rates are increasing sharply in the previously undeveloped world, driven by urbanisation and adoption of a Western lifestyle. IBD typically manifests in adolescence / early adulthood with disturbed bowel function, a robust inflammatory response, systemic upset, psycho-social disturbance and substantial health-economic burden. Recent years have seen massive biotech / pharma investment in IBD with multiple different drug modalities now approved for use. However, remission rates are hitting a ceiling at 1 year of 30-40%, and no reliable biomarkers exist to aid with drug positioning. Management of IBD is further complicated by our inability to prognosticate on treatment response, disease flare or disease progression. 

The PREdiCCt study www.predicct.co.uk, led by Dr Charlie Lees, is presently recruiting 3100 people with IBD from across the UK. Patients are recruited in clinical remission, and followed-up during two years. Detailed baseline data is collected for all patients. Among others, this includes electronic health records held by NHS, whole-genome and metabolomic sequencing, diet/lifestyle data recorded through a mobile app as well as a full blood panel. Throughout the follow-up, the mobile app is also used to regularly collect patient self-reported disease outcomes. 

The overarching goal of this project is to develop and apply computational strategies which can improve the stratification and subsequent treatment of IBD patients. High-dimensional Bayesian hierarchical models will be used as a natural and powerful framework to combine information from multiple data sources, whist appropriately quantifying statistical uncertainty. In particular, we seek to address the following research questions: 

1. What aspects of disease phenotype, diet, lifestyle, genetics and the gut microbiota contribute to a) disease flare, b) disease progression &amp; c) treatment response in IBD? 
2. How can we stratify patients based on disease biology and risk of progression? 
3. Based on this, how can we intervene to improve patient outcomes?"
D5D69C09-A254-4E28-BD37-B8B58C89376A,"For much of the world's poor, rice (O. sativa) provides the majority of daily calories. Rice productivity has more than doubled in recent decades, resulting from continued breeding efforts. However, to meet the demands imposed by the projected increase in population, rice production has to continue growing rapidly, while meeting challenges imposed by a changing climate. With the recent sequencing of &gt;3000 different varieties, there is a huge genetic resource available for identifying genetic polymorphisms associated with desirable traits e.g. tolerance to biotic or abiotic stress, yield, nutritional content etc., which in due course could be bred into a major crop variety. However, there is a great knowledge gap at present between genetic variation and functional effects, in terms of how plants respond at the cellular level to different stresses.

Under normal field conditions, plants can be exposed to various biotic and abiotic environmental stresses. Plant stress tolerance and acclimation depends on significant changes in post-translational modifications (PTMs) of specific proteins to switch function rapidly. It is expected that environmental stresses, such as drought and heat will become more prevalent in the coming decades. Future successful solutions will undoubtedly involve applying next-generation technologies to improve the breeding of agro-economically important crops. This study aims to identify and quantify PTMs in rice, and in the model plant Arabidopsis thaliana, to improve our understanding of how plants respond rapidly to different types of stress. We are particularly interested to study lysine modifications that affect protein-protein interactions and turnover, such as SUMOylation and ubiquitination. We will study the evolutionary conservation of these sites, the extent to which they can be competition between different PTMs for the same site, and/or crosstalk with proximal sites. The acquired knowledge will be used to mine plant genomes for new alleles associated with desirable traits, with a long term objective of improving crop breeding efforts."
8C255068-A14C-4C0F-9DAF-D0F00271B254,"Our project aims to understand how the cell can read the information that is written in its genome. The project is very much a collaboration between biological and computational scientists, who will work closely together to understand basic mechanisms of how cells can tell when and where the genes written in their DNA should be active. In other words, we seek to understand 'the second genetic code'. 

The first genetic code that describes how DNA sequence is converted to protein sequence was decoded more than 50 years ago, and the first draft of human genome, which describes the sequence of the chemical letters A, C, G and T found in all human cells was published in 2001. However, just knowing the order of the letters is not enough to understand how they instruct cells to function and to grow. 

Advances in DNA-sequencing have also allowed sequencing of entire genomes of individual humans and we have learnt for instance that sequences of unrelated individuals are different by approximately 10 million DNA bases. These specific variants, and the mechanisms by which they act are largely unknown. This is because most of the changes do not affect protein structure. Instead, the variations are presumed to affect the amount of proteins made in particular cells, by affecting DNA binding of proteins called transcription factors. 

Our research project aims to understand how the transcription factors read the genomic code. This will also help us to understand how mutations or variations in DNA sequences change the activity of genes. The work is basic research utilizing novel high throughput methods and artificial intelligence based computational data analysis tools. The project will first generate vast amounts of data in a laboratory, and then utilize and understand it using tailor-made computer programs.

The work will have immediate benefits to the scientific community in terms of deeper understanding, novel methods and computational tools. The work will also lead to increased understanding of the function of cells during growth and development. In a wider context, the proposed project is part of a broader effort to use advanced genomic and computational tools to understand the basis of human and animal biology. Genetic variants that are located between genes are so common that most plants, animals and people have many of them. To understand their function will be of great benefit to the scientific community in terms of deeper understanding of biological principles, for development of novel experimental methods and computational tools, and also eventually for applications such as plant and animal breeding. In addition, understanding the effect of non-coding genetic variants will help to explain human variation, for example in lifespan and health."
EA121E6C-D768-413F-90A2-C9E258CAC339,"The human brain is arguably the most complex structure among living organisms. Its development from single cells into a highly elaborate and unique organ has intrigued scientists for generations, yet remains incompletely understood. Recent scientific breakthroughs in the reprogramming of induced pluripotent stem cells (iPSCs) combined with tissue modelling and genome engineering offer unprecedented opportunities to model aspects of human brain development in the laboratory. Human iPSCs can be coaxed down several developmental trajectories including into neurons, thus allowing the investigation of human developmental brain processes in vitro. Moreover, human iPSC-derived models of brain disorders promise to identify potential therapeutic targets that could significantly improve the likelihood of successfully translating preclinical discoveries to the clinic.
This project will focus on the development of cerebellar models from human iPSCs. Only a handful of studies, including from the Becker group, have reported the generation of one particular cerebellar neuron type, i.e., Purkinje cells, from human iPSCs. Major limitations of the current protocol are the cumbersome and long protocol, the heterogeneity of cell composition and maturity of the differentiated neurons, and the necessity to grow human iPSC-derived cells together with mouse cerebellar progenitors. The goal of this iCASE studentship will be the development of robust and reproducible methods to generate specific and mature subpopulations of human cerebellar neurons. Specifically, the student will test the hypothesis that the overexpression of lineage-specific transcription factors will yield highly enriched and differentiated cerebellar neurons including Purkinje cells but also, for the first time, cerebellar granule neurons.
This collaborative project will bring together the expertise of the Becker group in cerebellar biology with the knowhow of the industrial partner, Axol Biosciences, in human stem cell culture. The Becker group are one of the few laboratories worldwide and the only one in the UK culturing cerebellar neurons from iPSCs. The student will be mainly based in Oxford, but will also benefit from an extended placement at Axol Biosciences in Cambridge. Axol Biosciences are a UK-based leading stem cell company with an in-house R&amp;D team. The Axol Bioscience scientific team comprises scientists from a variety of different backgrounds and some with many years of laboratory experience. The core expertise in the lab is in human induced pluripotent stem cells and the directed differentiation to a variety of end-stage cell types. In addition, Axol Bioscience has molecular biology and electrophysiology expertise in their laboratories, allowing functional analysis of the iPS cells. Being part of a small and growing company will give the student an industrial perspective on stem cell biology, an opportunity to see which sectors are using Axol's products and what they are used for. There will also be the chance to learn about the other aspects of the business, such as marketing, sales and logistics."
DD18DE59-317C-47C4-9DBE-19616241FDE2,"Proteins are amongst the most important of all molecules in biological systems. They are crucial to organisms which use them to carry out a huge variety of essential functions: catalysis, transport, storage, motor functions, signalling, chaperoning folding, regulation, molecular recognition, structural roles, and DNA Repair. As proteins are so ubiquitous in biology, understanding their properties is essential if we want to know about biological processes. This project is focused on one of the most significant of all protein functions: enzyme catalysis. Enzymes catalyse, or facilitate, the chemical reactions that occur in living organisms. Understanding how they work is both interesting in itself and useful in areas as diverse as drug design, diagnostics, biofuels, food science and laundry. This project is about the relationship between the structure of a protein and the enzyme function it carries out. We aim to predict the catalytic functionality from a knowledge of the protein structure. In order to achieve this, we will use machine learning methods, and in particular a technique called Random Forest. The forest consists of several hundred 'decision trees', each of which is basically a flow diagram. We will train them to learn patterns in the known properties of existing enzyme structures and the chemistry of the steps comprising the reactions they catalyse. However, the way in which we will generate the trees involves computer-simulated dice-rolling. This will ensure that they are all different, though based on the same underlying information. The decision trees then each make a prediction of the unknown possible catalytic functions. These predictions are treated as votes as to the function of the protein. This voting process produces a consensus of many decision trees and maximises the use of the information contained in the underlying data, generating results which are much more accurate than those of any one decision tree. The prediction of enzyme function is immensely important for a number of reasons. Firstly, being able to predict enzyme function more accurately will improve the functional annotation of genomes and reduce the current risk of misannotations being propagated through bioinformatics databases. Rapid developments in structural genomics, high throughput structure determination of diverse proteins from a wide variety of organisms, mean that many structures are available for enzymes whose functions are not yet known. Secondly, this project will allow us to recognise chemical similarities between evolutionarily unrelated enzymes that catalyse similar steps, though not necessarily similar overall reactions. Thirdly, this work will help us to understand the key determinants of the complex relationship between protein structure, function and evolution, particularly in terms of catalysis of reaction steps. Fourthly, the project will facilitate the design of new enzymes with either novel functions or carefully modified versions of existing functions. This project sits at an interface between disciplines, combining chemistry, biology and computer science. A wide range of skills and expertise is necessary to increase our understanding of catalysis, which has long been an important academic goal. Commercially, this work lays a foundation which is directly useful to the pharmaceutical and biotechnology industries, where enzymes are used both as diagnostics and therapeutics; the agrochemical industry, whose products often target enzymes; in the development of biofuels, which need robust enzymes to improve productivity and reduce costs; in laundry, where enzymes are already used in everyday products; and in the nutrition and food industries. In particular this project will aid in the design of new and repurposed enzymes."
2F15F3EC-EC5C-4821-BE6E-18EC7662C21B,"Objectives:
This project aims to enhance our understanding of molecular pathogenesis of Dementia with Lewy bodies (DLB). Its objectives are to:,
1. Develop a polygenic risk score (PRS) for DLB and to evaluate its ability to differentiate DLB from older people without cognitive impairment and from people with other dementias.
2. Investigate post-mortem cortical transcriptomics of people with DLB, and to identify differentially expressed genes (DEGs) in DLB brains.
3. Identify dysfunctional molecular pathways and networks in DLB brains and to compare them with dysfunctional molecular networks in brains of people with Alzheimer's disease (AD).
4. Evaluate the relationship between DLB genomic and transcriptomic data
5. Integrate DLB genomic and transcriptomic data for gaining biological insights regarding its pathogenesis and potential therapeutic targets. 

Research plan:
I. Study I (0-6 months): PRS of DLB and its ability to differentiate DLB from older people without cognitive impairment and other dementias
1. DLB specific GWAS data and genome sequencing data will be used to generate a PRS on DLB samples from the Brains for Dementia Research (BDR) to identify the best single nucleotides polymorphism (SNP) model to discriminate DLB from older people without cognitive impairment.
2. This PRS will then be used to see if it can differentiate DLB from other types of Dementia (AD, vascular dementia, Frontotemporal dementia, and Parkinson's Disease Dementia).
3. We can then use the PRS SNP model for AD from the BDR, and compare it with the DLB model to identify general dementia SNPs and DLB specific SNPs.

II. Study II (7-18 months): Investigating post-mortem cortical transcriptomics of people with DLB
1. We will obtain BDR post-mortem cortical samples from people with DLB and older people without cognitive impairment (n=40 of each). Total RNA will be extracted, and next-generation RNA-sequencing (RNA-Seq) will be completed by following our previous reported methodology (https://pubmed.ncbi.nlm.nih.gov/31327631/). 
2. DEGs will be identified by an experimentally validated edgeR algorithm. This will allow us to match up of BDR transcriptomic and genomic data, which have already been generated.
3. Functional pathway analyses of identified DLB DEGs and to compare them with the post-mortem cortical transcriptomic data from people with AD. Comparing DLB and AD DEGs and their downstream dysfunctional molecular pathways and networks may identify potential gene expression biomarkers specific to DLB. 

III. Study III (19-24 months): Evaluate the relationship between DLB genomic and transcriptomic data
1. eQTL Exploration for general dementia and DLB specific factors using our genomic and transcriptomic data.
2. Our genomic and transcriptomic data will be linked to find eQTLs for general dementia genes/SNPs and specific DLB gene/SNPs and correlating phenotypes with PRS.

IV. Study IV (25-36 months): Integrate DLB genomic and transcriptomic data for gaining further biological insights
1. Genome scale metabolic modelling for understanding metabolic reprogramming in DLB brains
2. In-silico gene silencing analyses for identifying potential therapeutic targets
3. Exploring machine learning/ AI's ability to gain biological insights from our DLB genomic and transcriptomic data."
34148E47-B33C-4CC5-875F-95075D1887B1,"In the past several decades there has been a substantial global investment to try and map the regions of livestock genomes that control production, disease tolerance and welfare phenotypes. The ultimate aim of mapping these DNA regions is so that researchers can then use advanced genomics and breeding approaches to more rapidly improve the production and welfare of livestock. Although many important loci have been mapped, most often we do not know which precise genetic changes in these regions are linked to the observed differences in phenotypes, making it more difficult to apply advanced approaches such as gene editing to improve these traits. However, studies in cattle have estimated that variants that alter downstream phenotypes are over 18 times more likely to do so by leading to changes in transcription, i.e. the expression level of genes, than is expected by chance (Nat Genet 50, 362-367 (2018)). If we can map which variants directly impact expression levels, we can determine which genetic changes are most likely driving the observed changes in key traits. This will consequently substantially improve the rate at which we can improve important livestock phenotypes.

In this project we will apply a high-throughput approach that directly tests the impact on gene expression of millions of genetic changes at the same time. This will allow us to generate a catalogue of cattle functional variants directly linked to changes in transcription, and which may therefore underlie loci linked to important traits. However, we will also take this further, and test the impact of human genetic changes when in cattle cells as well as vice versa. Certain species are much better annotated with richer datasets than others, and we will use these data to determine which features are linked to genetic variants that impact gene regulation across species. Using these data and machine learning approaches we will develop statistical models that will allow researchers to predict which genetic changes will likely have an impact across species. This will allow researchers to exploit the data in better characterised species to improve less well annotated ones, further accelerating livestock improvement efforts but also potentially, for example, informing human disease studies that are based on animal models.

Consequently, this project is expected to substantially improve the understanding of both cattle and human phenotypes by mapping regulatory variants and developing statistical models for predicting variants that impact transcription across species."
704F628F-6696-4641-A74D-C4E07E275639,"Neurodevelopmental disability (NDD), which is an umbrella term for autism, attention deficit, and intellectual and learning disability, affects 13% of the population. It has major economic and quality-of-life impacts on NDD individuals and families, and substantial economic burden on the healthcare system. So far, treatment is aimed only at general symptoms, which often leads to low efficacy and frequent side effects. 
 
The advent of novel genetic testing methods has provided plenty of evidence of the major impact that genes and their regulation have on clinical presentation in NDD. Nonetheless, there is a large diversity among individuals with NDD, even with the same genetic mutation. This is not unique to NDD as it is seen widely in many other medical conditions. The complexity derived from the genetic heterogeneity and the clinical (neuro) diversity has proven challenging to traditional approaches for treatment. 
 
Recent research in the UK and Canada has led to the development of large databases recording detailed information about individuals with NDD. Artificial intelligence (AI) now provides us with the tools to quickly analyze the information in those datasets. In particular, we will use machine learning (ML) to manage complex information, leading to the acceleration and better prioritization of interventions. Also, our project takes a novel view on the understanding of genomic information in NDD. Instead of directing our focus only on exploring data from a single individual or small group of individuals carrying the same gene mutation, our team will apply ML to large databases to identify features (from genes and their biology) correlated with improved clinical outcomes. 
 
In addition, we will use ML to better understand the interdependence between different symptoms to develop treatments that have a globally positive impact. In other words, we would find solutions that improve cognitive skills without impacting sleep negatively or generating more anxiety, as has been seen in previous clinical trials. 
 
We will finish by providing the entire scientific community with an open access portal, including our research findings, which will be integrated with the current Open Targets platform, a partnership between academia and industry in the UK that allows researchers to access linked data on diseases, genes and drugs in a single site. Researchers will be able to provide further information, which will improve the ML model. 
 
To ensure that we accomplish our objectives, we have assembled a team of experts in clinical and genetics of NDD: Dr. Bolduc (Canada); in computer science of genomics, molecular and pharmacological data: Dr. Dunham (UK); bioinformatics: Dr. Droit; machine learning: Dr. Greiner; social sciences, patient engagement and health economic: Dr. Zwicker. Our team has also developed strong links with NDD patient and research organizations in Canada and the UK, which will provide insight throughout the project. We are supported by collaborators involved in family and government engagement, ethics and data management in the UK and Canada. The project will also be a unique opportunity for multidisciplinary international training. 
 
Our project will show how ML can disassemble the complexity and diversity seen in NDD to develop more successful interventions. It will allow us to develop new ML approaches that will be readily applicable to other disorders where personalized interventions have been lagging behind diagnosis. More importantly, it will bring together families, society and scientists into a shared space where more and better information is exchanged. Finally, our project will embrace responsible implementation of data privacy and confidentiality while recognizing the need for data sharing to develop better interventions."
A5A80F90-C483-40C0-9128-6CFA877016E4,"Blackleg disease of potato caused by P. atrosepticum (Pba) is the most damaging bacterial plant pathogen in the UK, costing &pound;50M p.a. in losses for the potato industry. Current knowledge assumes that disease is caused through Pba-infected seed tubers. However, our recent unpublished data have shown that under high soil moisture following irrigation, disease appears in plants grown from pathogen free seed (minitubers). The most likely explanation is that bacteria enter the plant and cause disease directly from the soil; something not previously considered. We have also shown that Pba is able to colonise roots of other plant species (including crops), possibly as natural rhizosphere-dwelling saprophytes in the soil. In pot trials with Pba alone, we showed there was no movement of Pba from soil into the plant. However, when free-living nematodes (FLN) were added to soil, a 100-fold increase in Pba in stems occurred.

Through these and other findings we now have the potential to make a step change in how we manage blackleg. We will address knowledge gaps firstly by using Light Sheet and Confocal Laser Scanning microscopy, transparent soils and mesocosm studies to assess the role of FLN as vectors of Pba and how infection occurs. We will also examine how changes in standard irrigation regimes can help to reduce levels of blackleg in ware crops (where irrigation is often over-applied to avoid common scab disease that occurs in dry conditions), and how it might change FLN communities around potato root systems. Similarly, we will identify cover crops that limit natural Pba colonisation on their roots as a possible way to reduce Pba numbers in soil prior to planting potato. Little is known about the microbiome on potato roots and how these might be influenced to favour or reduce colonisation by Pba. We will therefore characterise the potato microbiome prior to and following irrigation using shotgun metagenomics sequencing and the latest bioinformatics tools, with a focus on the Pectobacteriaceae and wider Gamma-proteobacteria. We will also use GC-MS to examine how changes in root architecture and the constituents of root exudates influence the composition of these bacterial groups, to assess whether the use irrigation and cover crops alter the balance between beneficial and harmful bacteria associated with potato. Finally, we will determine whether novel antimicrobials (bacteriocins) in closely related non-pathogenic bacteria in the microbiome could act as a management option against Pba.

Our recent modelling research using the Scottish Government's in-house potato inspections database (SPUDS), shows that blackleg incidence on a national scale does not occur randomly but in clusters. Reason(s) for this remain unclear but could be due to several things that, when identified, may assist growers in managing their crops, e.g. potato crop distribution, weather, soil type, soil moisture, leaf wetness, FLN distribution, crop type and rotation prior to planting. Using data generated from this project, an extensive array of data from other recent and historical investigations and the latest data from government and industry we will model, using innovative machine learning methods, at national scale these data to identify trends and drivers of Pba incidence in both space and time and, through this, produce predictive models to support development of a set of decision support tools for evaluation by stakeholders during the project and early adoption thereafter. Further, through scenario testing, we will quantify the predicted effects of climate change on future blackleg incidence in association with FLN presence thus providing the industry with robust and novel data to underpin sector resilience planning."
4BC9780E-1952-4090-BE70-D32152B5C1C6,"- parasites

Research Questions: 
The proposed project aims to use interdisciplinary techniques to investigate dense granule formation and protein targeting in the apicomplexan parasite Plasmodium falciparum, the most lethal of the human malaria parasites. Molecular biological approaches and imaging techniques will be used to identify genetic sequences which target proteins to the dense granules. Once these signals have been identified, bioinformatics approaches will be used to predict novel dense granule proteins. The use of such bioinformatics techniques meets the MRC LID key skills of data analytics, informatics and computational approaches. The presence of these proteins can then be confirmed using mass spectrometry, and their function determined by observing knock-out mutants generated using CRISPR/Cas9 genome editing technology. 

Rationale: 
Dense granules are essential for Plasmodium infection of the host erythrocyte. Since the debilitating symptoms of malaria are a product of parasite invasion and survival within the host erythrocytes, elucidating the mechanisms which underly this process and contributing to the understanding of Plasmodium systems biology will provide information of great importance to medical science. Additionally, this project could identify proteins suitable for inhibitor screening with a view to discovering compounds capable of inhibiting parasite growth.

Background: 
Malaria is a significant infectious disease caused by apicomplexan parasites of the genus Plasmodium with 216 million cases and an estimated 445,000 mortalities worldwide in 2016 , and 65% of cases occurring in those under the age of 15. However, advances against malaria are in decline, therefore the development of novel interventions is vital.
The symptoms of malaria are caused when the infective life stage of the parasite Plasmodium (the zoite), invades the host erythrocyte and forms a parasitophorous vacuole (PV) in which the parasite can reproduce. As in other apicomplexan parasites, Plasmodium spp. invasion of the host cell by the zoite requires the function of three specialised secretory organelles; micronemes, rhoptries, and dense granules (DG). These three organelles have been demonstrated to be essential to host cell invasion and PV formation, with rhoptries and micronemes holding essential roles in host cell invasion in Plasmodium. However, despite their vital role in parasite survival, the mechanisms of DG function in Plasmodium host cell infection remain largely unknown."
49F6B20C-F4A8-4BFA-AE24-8F506075944C,"The aim of this project is to develop multi-modal models across data from high-throughput technologies such as genomics, metabolomics, proteomics, and radiomics, to identify genetic variations linked with cellular biochemical pathways leading to changes in brain structures and neurodegeneration. While several disparate data sources and population-based studies have been available in this space, drawing conclusive inferences across these datasets has been challenging for biostatisticians due to the large-scale and heterogeneous nature of these data. To date, AI/ML approaches have been severely underutilised. Biostatistical identification of single genetic hits without simultaneous modelling of the large array of metabolomics data that are markers of the linked biochemical pathways, yields genetic variants that are commonly in non-functional regions of the genome, have weak associations with the disease and do not provide useful insights. Likewise, identification of single metabolomic hits in isolation of the upstream genetic and downstream brain imaging features do not provide meaningful insights into the pathogenesis of dementia. We propose to combine the large array of genomics and metabolomics data with data on the intensity, shape and textural features of different brain structures derived from structural and functional MRI associated with neurodegeneration and dementia."
E0CF9986-CD1C-4E1F-9A67-197D7DA93ECF,"Uncovering genetic variation of natural and domesticated populations, quantifying gene flow between them and understanding diversification mechanisms operating in both environments is vital for sustainability of agriculture and aquaculture in the face of climate change, as well as increased vulnerability to diseases. We will apply our expertise in animal and plant genomics to identify domestication and adaptation diversification hotspots and bottlenecks in key systems: crops and wild relatives in Poaceae and Brassicaceae and aquaculture fish species (both farmed and wild Tilapia populations). 

For each of these systems, we will scan genomes of domesticated and cultivated species, and those of their wild relatives, to assess genetic diversity in these populations and identify patterns of selection that are linked to environmental adaptation, speciation, and evolution under domestication. Using improved genome annotations, we will identify and characterise variants segregating at high frequency within protein coding sequences, their regulatory regions, and conserved noncoding elements in domesticated species in comparison to their wild relatives. We will compare the pattern of intraspecies diversity between wild and cultivated lines to assess the impact of artificial selection on the loss of heterozygosity and the fixation of weakly deleterious variants. We will assess the selective constraints acting on regulatory elements and gene regulation through evolutionary analyses to provide demographic and genetic data necessary to model interactions between farmed and wild species, and predict population character and abundance. This information will ultimately contribute to the improvement and expansion of breeding programs.

We will also utilise natural and synthetic hybrids to investigate the immediate and long-term effects of hybridisation and polyploidy on genome architecture and evolution. We will focus our investigations on Triticeae species (tetraploid: Triticum turgidum, T. dicoccum; diploid: T. urartu, T. monococcum) and their hybrids. We will apply sequence-based approaches to assay transcriptional activity (RNA-seq, smRNA-seq), and interrogate existing public data and data available through the Designing Future Wheat ISP WP4 (ATAC-Seq, ChIP-Seq, DNA methylation), to define the epigenome of natural and synthetic hybrids and the wild progenitors. 

The widespread use and misuse of antimicrobials in our general environment has allowed bacteria to be frequently exposed to sub-inhibitory concentrations, favouring the evolution and spread of resistance to the most commonly used antimicrobial molecules. The effects of these low antibacterial concentrations on pathogenic bacteria leading to the selection of variants associated with resistance are currently not fully understood despite their implications for the effectiveness of antimicrobial drugs in the future. Using machine learning approaches to mine currently available data, we will investigate the genetic changes responsible for adaptation of Salmonella to certain hosts and environments as well as changes in virulence or drug resistance. We aim to characterise the fitness effects of resistance mutations and how they can be maintained in a population with and without antimicrobial selection. Using experimental selection (performed by QI collaborators) and genome sequencing (performed by EI), we will assess whether the trajectory of mutations and allele frequency changes at different antimicrobial concentrations can be predicted and modelled."
23609EED-C790-4708-9CDD-4C0C142B1649,"Programme overview:
This MRC-funded doctoral training partnership (DTP) brings together cutting-edge molecular and analytical sciences with innovative computational approaches in data analysis to enable students to address hypothesis-led biomedical research questions. This is a 4-year programme whose first year involves a series of taught modules and two laboratory-based research projects that lead to an MSc in Interdisciplinary Biomedical Research. The first two terms consist of a selection of taught modules that allow students to gain a solid grounding in multidisciplinary science. Students also attend a series of masterclasses led by academic and industry experts in areas of molecular, cellular and tissue dynamics, microbiology and infection, applied biomedical technologies and artificial intelligence and data science. During the third and summer terms students conduct two eleven-week research projects in labs of their choice. 

Project overview: 
Staphylococcus aureus is a bacterium responsible for infections ranging from minor abscesses to severe endocarditis. It is a leading cause of hospital-acquired infections. The rise in drug resistant strains of S. aureus, such as methicillin resistant S. aureus (MRSA), has made effective management of staphylococcal infections challenging. A major type of infection caused by S. aureus is the bone and joint infections, particularly those associated with prosthetic joints. Prosthetic joint infections (PJI) are often very serious, with high rates of chronic infections, which are extremely hard to eradicate. In addition to treatment, accurate clinical diagnosis of chronic PJI is also hard, due to a lack of reliable diagnostic tools. 

S. aureus is able to effectively invade bone cells, where it is protected from antibiotics and our immune responses. Intracellular bacteria survive and multiply within our cells and have been strongly linked to chronic infections. The cell pathways that are modulated by the bacterium during intracellular infection remain unclear, and identification of these could aid early diagnosis and provide new drug targets.

The aim of this project is to identify bacterial and host proteins that are key to bone cell infection. Additionally, it will explore novel antibiotic delivery systems against intracellular S. aureus. During this project, we will use immunofluorescence confocal microscopy to characterise the intracellular bone cell infection profiles of S. aureus and functional genomics methods (RNA-seq) to identify genes that are regulated during infection. We will also synthesise novel antibiotic delivery systems against intracellular S. aureus using antimicrobial polymers. During this project the student will receive training in polymer chemistry methods and in quantitative skills such as live microscopy and bioinformatic analysis."
30B778F5-02D2-46BC-A977-8FDEA543E4D0,"Our evolutionary history is written in our genomes. By comparing DNA sequences from different species we can work out how the species are related. By comparing the DNA sequences of multiple individuals from the same species, we can estimate the population size and infer demographic changes (such as population bottleneck) of the species. Such studies fall into the domains of phylogenetics and population genetics. Genomic sequence data from multiple individuals of several closely related species allow powerful inference at the interface of phylogenetics and population genetics. One can use such data to estimate species divergence times and ancestral population sizes, accounting for lineage sorting, and to detect gene flow at the time speciation or to test different models of speciation Such data also allow delimitation of species (for example, to decide whether the sampled individuals belong to one or two species).

To achieve those goals, powerful statistical methods and computational algorithms are necessary. In this project we will implement such methods within two well-established statistical frameworks: maximum likelihood and Bayesian inference. 

We will develop maximum likelihood methods for estimating migration rates between populations, and design likelihood ratio tests to test whether there is gene flow at the time of speciation (that is, whether speciation is clean). We will implement models that allow the migration rate to decrease over time since species divergence. Those methods will be useful for testing different speciation models such as allopatric and parapatric speciation. Computational difficulties will limit our likelihood methods to 2 or 3 sequences at each sampled locus. However the methods can accommodate a huge number of loci (indeed the whole genome), and with population data at some loci and species data at other loci, powerful inference is feasible. We will use computer simulations to examine the statistical properties of the new methods, and apply the methods to genomic datasets from the hominoids.

We will introduce significant improvements and extensions to a Bayesian model-comparison approach to delimiting species using genomic sequence data. Published a year ago (Yang and Rannala 2010 Proc Natl Acad Sci USA 107:9264-9269), this method has attracted much attention among evolutionary biologists. This uses an algorithm called reversible-jump Markov chain Monto Carlo (rjMCMC) to sample different species-delimitation models, such as the one-species model (which assumes that all sampled individuals are from one single species) and the two species model (which assumes that the sampled individuals are from two distinct species). However, our current implementation in the computer program BPP has serious limitations and is inefficient in intermediate or large datasets. A major objective of this project is to improve the rjMCMC algorithm so that the program becomes feasible for analysis of large genomic-scale datasets. We will also parallelize the programs to improve the computational efficiency."
E46F440C-55F3-4C75-B6DA-39E3663011EF,"Mental health is the leading area of unmet medical need in the developed world, projected to rapidly acquire the same status in the developing world. With ~1 billion affected by a mental disorder worldwide, poor mental health was estimated to cost the world economy approximately $2.5 trillion per year in poor health and reduced productivity in 2010, a cost projected to rise to $6 trillion by 2030. Despite undeniable advances in psychiatric genomics and neuroscience, translation into real-world actionable results has been limited. The favorable conjuncture of large, prospective, deeply-phenotyped cohorts becoming available and machine learning (ML) techniques being fast developed for extracting knowledge from data can unlock great potential for precision psychiatry.
As adolescence is notoriously a period of vulnerability to mental illness, with nearly half patients suffering from mental illness having an onset by the age of 18, the Adolescent Brain and Cognitive Development (ABCD) offers a unique and unprecedented opportunity for ML approaches to mental health. ABCD is a longitudinal, observational study of over 10,000 youth, aged 9 to 10, recruited at 21 sites throughout the United States and followed up for approximately ten years into young adulthood. Comprehensive biennial assessments and more limited interim assessments measure health, mental health, neurocognition, family, cultural and environmental variables, substance use, genetic and other biomarkers, and structural and functional brain development.
This project sits at the intersection between neuroscience, psychiatry, and ML and aims to investigate the following questions and propose ML solutions. 1) The current psychiatric nosography rests almost entirely on patient-reported and clinically observable symptoms and behaviors and it is not informed by a biological understanding of the pathophysiological mechanisms driving mental illness. As a result, traditional psychiatric disease categories encompass much heterogeneity of phenotype and fall short of representing 'ground truth labels'. This is a major hurdle to overcome in the pursuit of precision medicine. Unsupervised learning approaches capitalizing on a wealth of biological and behavioral data can retrieve disease groups and dimensions which can then be interpreted and tested against their clinical usefulness. 2) Previous studies have pursued supervised learning approaches to predict clinically meaningful outcomes. However, well-established and consistent pre-processing/modelling workflows consistently implementable across samples have hardly been suggested. Common challenges and limitations include small sample sizes, especially in comparison to the dimensionality of the feature space when biological measures (e.g. neuroimaging, genomics) are used as predictors, poor standardization of predictors and outcomes across different studies, lack of independent samples for testing generalization performance, lack of benchmark data sets, poor practice around code sharing. Reviews of the literature show that, notably, most studies so far have relied on a single data modality (e.g. genomics, neuorimaging, wearables). This is due to the so-far limited availability of cohorts phenotyped on multiple modalities but also to the lack of well-established approaches and pipelines for harnessing multiple modalities. 3) Most ML approaches to making predictions used up to now are purely associative, failing to disentangle correlation from causation which can result in sub-optimal (or even dangerous) predictions and limited insights into causal mechanisms. This is in contrast to how a doctor makes a diagnosis, which amounts to explaining a patient's symptoms by determining the pathophysiological abnormalities causing them. Causal ML is thus the way forward for explicitly testing assumptions about the data-generating process, deriving causal insights and applications in high-risk environments such as health care."
04C5DAB4-C26E-4591-B6E9-32B33A5269FE,"Recent studies show that 70% percent of all deaths among type 2 diabetes (T2DM)
patients are due to cardiovascular disease (CVD) involving coronary heart disease,
stroke, heart failure and peripheral arterial disease. CVD treatment in subjects without
T2DM is guided by the Qrisk3 prognostic rule, however while multiple CVD prognostic
rules are available, it is unclear which rule is most appropriate for T2DM patients.
Furthermore, it is unclear whether it is possible to develop more advanced rules, jointly
predicting individual CVD elements (e.g., CHD and stroke), while allowing for competing
risk and disease trajectories.
As a first step in introducing risk-stratified CVD management in T2DM care I will validate
existing CVD prognostic algorithms on a British sample of 200,000+ T2DM CPRD
subjects. The scope of the project includes exploring average out-of-sample
performance, as well as presenting stratified results for geographical location, diagnosis
setting, disease duration, year of diagnosis and patient type.
The next phase of the project focuses on developing novel CVD prediction rules in
diabetes patients using advanced competing-risk and multi-stage methodologies.
Moreover, we want to leverage genomics data to improve prognostic performance. The
scope of the project also includes exploring the utility of EHR data and real-time analytics
to update CVD rules in diabetes population, designing methods for predicting repeated
episodes and predicting disease trajectory."
0F8B780A-BC91-49C3-B316-F59B3EA9996B,"Genome-wide association studies (GWAS) have been successful in identifying chromosomal regions (loci) that contain genetic variants that contribute to many complex human traits and common diseases, including those that have major public health burden, such as cancers, diabetes and arthritis. Association signals for many complex traits predominantly localise to regions that influence disease by modulating gene expression (i.e. the process by which DNA is converted into a functional gene product), which may vary across tissues and cell types (referred to as the transcriptome). However, studies of the relationships between gene expression and complex traits have been restricted to investigations in small samples because of cost and availability of relevant tissues. Consequently, there has been limited progress in identifying the causal genes in GWAS regions and in understanding of the biological processes through which genetic variants impact on disease pathophysiology, thereby hindering the translation of these findings into the clinic through targeted drug development.

One increasingly utilised approach to understand molecular pathways underlying human disease is through integrated analysis of genetic variation and transcriptomic data resources from large-scale tissue-based molecular profiling initiatives. For example, the Genotype-Tissue Expression Project has generated high-density genome-wide genotyping and gene expression across a wide range of tissues, and has made these data publicly available. One primary finding of these investigations has been the identification of expression quantitative trait loci (eQTL) that link genetic variation to the regulation of gene expression in diverse tissues. Methods have thus been developed that aim to detect association of complex traits with gene expression by: (i) building tissue-specific multi-eQTL models in these molecular profiling resources; and (ii) using these models to predict (or &quot;impute&quot;) the transcriptome into GWAS data (based on individual-level genotypes or association summary statistics). However, existing transcriptome imputation methods typically: (i) consider each cell type separately, and do not take advantage of the observed correlations in gene expression between cell types driven by cross-tissue eQTLs; and/or (ii) do not account for eQTL model uncertainty (i.e. many different genetic variants may regulate gene expression), resulting in potential for false positive findings.

The aim of this proposal is to develop novel statistical methods for transcriptomic imputation into GWAS to address these limitations by: (i) harnessing multi-tissue expression to build eQTL models that better predict gene expression than those that consider each cell type separately; and (ii) use computationally efficient Bayesian statistical methods that appropriately allow for uncertainty in the eQTL model, reducing the potential for &quot;over-fitting&quot;. The methodology will be implemented in user friendly software that will be made freely available to the wider research community. The methodology and software will be utilised to create a repository of imputed multi-tissue gene expression into 500,000 participants from the UK Biobank for whom GWAS data are already available. These imputed transcriptomic profiles will be tested for association with rheumatoid arthritis and other musculoskeletal diseases, cardiovascular disease, cancer and diabetes, revealing novel causal genes and improving understanding of molecular mechanisms and relevant cell types underlying disease biology. The repository will also be returned to UK Biobank for archiving and distribution to approved researchers to identify causal genes for any trait of interest available in the resource. These analyses will have enhanced potential for translation of GWAS findings by identifying drug targets for up- or down-regulation of causal genes for which expression is associated with risk of disease."
989CC241-2C05-4665-AD19-DF5C5C261BFA,"Keywords: Analytical science, biological informatics.
Summary; 
Next generation sequencing of exomes has revolutionized the genetic diagnosis of a broad spectrum of diseases, allowing the possibility to detect mutations within most genes of the human genome. However, this strategy does not address the possibility of pathogenic mutations that lie in non-coding regions of the genome. For example, in some patients with primary immune immunodeficiency we can observe clinical phenotypes that are compatible with mutations of known disease-associated genes, in the absence of any mutation within the relevant coding regions. Where accompanied by alterations at transcriptional level, these similar phenotypes suggest the possible dysregulation of the same disease genes by mutations in non-coding regulatory regions that influence their expression.
Whole genome sequencing (WGS) allows the exploration and potential discovery of such non-coding genomic variants. However, non-coding regions are highly polymorphic and, therefore, it is still a challenge to identify potential disease-associated mutations with confidence. Furthermore, annotation of the noncoding space has until recently been held back by the complexity and cell-type specificity of enhancer activity and chromatin accessibility. In this project, we will take advantage of the recent explosion of expression quantitative trait loci (eQTL) data and epigenomic information to refine our ability to identify potential deleterious variants within cell type-specific regulatory regions.
There has been a recent expansion in the development of computational tools and methodologies that utilise statistical models to enable the interrogation of non-coding variants, each with their own advantages and disadvantages. Machine learning for example is already being tested as a means to predicting non-coding passenger mutations in cancer genomes (Yang et al., 2016). The main challenges are to integrate all the current sources of information in a common framework and develop new creative strategies for the prediction of damaging variants.
In this project, the student will develop new methodologies to predict non-coding variants that drive the dysregulation of clinically relevant disease genes to improve their diagnosis and future therapy. The main focus will be in exploiting cell type-specific data that are relevant for each disease. The analytical protocols will be tested in WGS data from patients with primary immunodeficiencies and further validated with WGS data from other diseases with different cell types affected, such as neurological diseases. Where available, transcriptional data will be used to test the validity of variant predictions integrated into the analysis. In the era of genomic medicine, such protocols have potentially broad significance."
0553C337-BE25-4B18-B141-349FE71DDD1A,"Low-grade inflammation, particularly that related to the pro-inflammatory cytokine interleukin 6 (IL-6) pathway, could be causally linked to psychosis, and offers innovative treatment targets. Elevated circulating IL-6 and related protein levels are present prior to psychosis onset and may be seen more often in patients with specific types of symptoms - cognitive difficulties such as working memory and difficulty processing information and negative symptoms such as poor motivation, diminished pleasure, reduced facial expression, reduced speech and social isolation. There is also evidence that inflammation may be related to mood symptoms such as depression, which are common in psychosis. However, recent drug trials of anti-inflammatory agents in psychosis have yielded mixed results, potentially because these were given to groups of patients with psychosis regardless of whether there was evidence of current inflammation. It is unlikely anti-inflammatory treatment could be helpful for patients who do not have increased inflammation.

The PIMS project will focus on the IL-6 pathway, and immune markers up (interleukin 1 beta (IL-1B) and tumour necrosis factor (TNF-a) and downstream (C-reactive protein) of IL-6, as potential new therapeutic target for schizophrenia using a number of approaches. 

First, we will use Mendelian randomization analysis of existing large genomic data to test whether IL-6 and related immune markers are causally linked with psychosis. We will then use existing data from large clinical and epidemiological samples and machine learning approaches to identify illness stage and symptom dimension most closely linked with inflammation, and the relevance of peripheral blood levels of markers of inflammation to brain structure: identifying the biotype of immune-related psychosis. 

This work will inform a randomised double blind experimental medicine study, giving psychosis patients with evidence of inflammation one dose of Tocilizumab. Tocilizumab is an anti-inflammatory medication used in Rheumatoid arthritis that blocks IL-6 signalling. We will see if this has any effect on psychotic symptoms especially cognition. We will test whether IL-6 blockade has effect and on circulating inflammatory markers and brain measures of oxidative stress using magnetic resonance spectroscopy implicated in psychosis. 

We will carry out experiments on immune cells collected from patients before and after tocilizumab; this could identify cellular source of low-grade inflammation seen in psychosis. We will create modelled brain cells from specific blood cells (monocytes) to test whether they act differently from healthy people in different test conditions.

Finally, we will use results to refine established animal models of schizophrenia to understand the biology of the immune target and inflammation-related psychosis. 

The PIMS study group comprises experts in psychosis, immuno-psychiatry, epidemiology, neuroscience, bioinformatics, genomics, and pharmacology with established track record in their fields and experience of collaborating and/or leading large projects. We will work with our Industry Advisory Board to take findings forward with the ultimate aim of developing new stratified medicine treatments for psychosis patients with active inflammation."
A69D3AFC-9F3D-4C20-8393-738BD83899CC,"In biomedicine the amount of published material has been growing exponentially in recent years, particularly in very productive areas, such as genomics. The management of the information derived from this material poses a problem for researchers, who cannot cope with this magnitude of data and find it increasingly difficult to find information that is necessary for their research. Automatic processing of these documents would provide the means to efficiently access the information they contain by building tools to search for documents and identify facts within them. However, this is made difficult by the fact that texts in the biomedical domain, like those on other topics, contain a range of ambiguities. This research project aims to develop tools and algorithms to resolve lexical ambiguity in the biomedical domain. We will apply novel unsupervised word sense disambiguation methods to three distinct forms of lexical ambiguity. The problem of obtaining adequate amounts of training data for these approaches will be addressed by adapting techniques for automatically generating disambiguated sentences using information from a domain ontology and unannotated corpora. Finally, the resulting disambiguation systems will be integrated into Termino, a publicly available terminology recognition tool, to improve its functionality. The three forms of biomedical lexical ambiguity that we will focus on in this project are the following: (i) Terms which refer to multiple concepts. The phenomenon of polysemy, where a word may have several possible meanings, occurs in all texts. A special consideration which must be taken into account when resolving this form of ambiguity is the fact that words may be used with meanings that are unlikely to occur in text from other domains. For example, cold'' has six possible meanings in the Unified Medical Language System (UMLS) Metathesaurus including well known meanings like common cold'' and cold sensation'' but there are also domain-specific usages, for example, Chronic Obstructive Airway Disease (COLD)''. (ii) Abbreviations with more than one possible expansion. Abbreviations are used frequently in biomedical text but a single abbreviation may have several expanded forms. It has been reported that abbreviations in MedLine consisting of six characters or less have an average of 4.61 possible meanings, making it difficult to interpret these texts automatically. (iii) Systematic relation between possible meanings for a set of terms. This form of ambiguity, which is particularly common in genomics literature, occurs when the same term can refer to a gene, protein or mRNA. This is a form of regular polysemy since the meanings are related (the gene produces mRNA and a protein). Since the same term can refer to a variety of compounds, it can be difficult to determine which one is meant in a particular usage. Resolving these various forms of lexical ambiguity is critical for the automatic processing of biomedical texts."
44FB0572-E0BA-445A-B242-1892591E0EDA,"Since a Canadian research project in the 1970s first showed how the regional killer whale population could be tracked over time using photographs to identify and follow the associations and movement of individual whales, it has become increasingly apparent that this species offers great potential for advancing our understanding of key evolutionary and ecological processes. Despite their tremendous potential for long-distance dispersion, with social groups travelling 1000s of km in a season, identified populations of associating individuals (divided into social units of 20-50 individuals) are genetically differentiated at neutral markers over small geographic scales. The apparent mechanism is dependence on local or seasonal habitat resources, and in particular, prey resources. In this way picivorous populations can be separated by the direction of migration in their anadromous salmonid prey (migrating north or south of an estuary), and picivorous populations can be isolated from marine-mammal-eating populations even in sympatry. There is a pattern of differentiation associated with geographic distance (as seen for many species), but only within an ecotype. Differentiation among ecotypes is based on biological factors (especially behaviour associated with foraging and social structure). Although the effective size of regional populations is likely small, there are sometimes physical differences that may be associated with resource exploitation (as seen in various other delphinid species, especially associated with buccal morphology), suggesting local adaptation. In this study we will identify genes that are apparently under selection, and associate them where possible with ecological characteristics, especially known aspect of the life history of the different ecotype populations. A key deliverable will be an extensive set of SNP markers, with some identified as likely under selection, to be applied in a follow-on study to an extensive program of population screening. A preliminary assessment based on these SNP markers will be undertaken in the current study as part of the SNP discovery process. This is made possible by the chosen methodology. The initial step will be the sequencing of the full genome for one sample to a quality level sufficient to use as a reference scaffold (to be done through the commercial provider, Eurofins MWG/ Operon). This will then be used to facilitate the RAD-Tag sequencing work and the associated bio-informatics (to be undertaken under the supervision of partner Neil Hall at CGR Liverpool). The RAD-Tag data will then be analysed by the PI in Durham in collaboration with Prof. Hall and with the assistance of the RA. The RAD-Tag sequences will permit the identification of SNP markers, and the reference genome would permit identification of their location and linkage within the killer whale genome. Analysis of an initial 150 whales from 5 populations will provide the preliminary data on signals for selection and a high-resolution assessment of patterns of differentiation. Bayesian and multiple regression methods will be applied to allow interpretation of genetic variation in the context of environmental variables, and to assess which variables explain the largest proportion of the genetic variance. Taken together these analyses will advance our understanding of the evolutionary processes that generate biodiversity within and among species, facilitate more effective programs of biodiversity conservation, and provide the raw material for future studies that will advance these objectives further."
5C6EB9CE-FBB9-4681-B0D1-602080331C46,"The Masters in Research (MRes) in Computational Biology programme trains graduates to meet the computational research demands of modern interdisciplinary bioscience (e.g. postgenomic, systems and synthetic biology) in universities, research institutes and industry. Delivered by staff from across the Departments of Biology, Chemistry and Computer Science, the course provides interdisciplinary research-led training in data analysis, informatics and the organisation and dynamics of complex biosystems. The programme builds on over 30 years of experience in training mathematically, statistically and computationally literate bioscientists. From the long running MSc in Biological Computation to the Masters of Research programmes in Bioinformatics, Maths in the Living Environment and Computational Biology we have continued to develop and evolve programmes to meet the current, and future, research demands of interdisciplinary bioscience. Our focus on core training in the essentials of data analysis, statistics, computational methods and modelling and the provision of opportunities to practise such methods in a research context equip graduates to meet new challenges emerging in biological research. The programme is principally aimed at graduates of the biological and molecular sciences but also accepts graduates of computer science, mathematics and statistics who can demonstrate an interest in the biosciences. SPECIFIC AIMS OF THE PROGRAMME: * to provide knowledge of the concepts and methods underpinning research in bioinformatics and computational biology; * to provide training in bioinformatics research skills, principally in the areas of: - sequence to structure to function, and evolutionary relationships in biomolecules - analysis of large biological data sets - modelling and simulation of biological systems; * to provide training in skills that are widely transferable, such as mathematical and programming skills, personal effectiveness, team working, communication and technology transfer; * to apply and develop these skills through three research projects including an external placement in academia, research institutes or industry worldwide. PROGRAMME STRUCTURE (51 WEEKS) Also see attached 'CBoutline2010.doc' * Autumn term 11 weeks ( -1 to 10) The focus is on providing teaching in the more fundamental areas with the following modules: Sequence, Structure &amp; Genomics; Data Analysis I - Concepts and Skills; Introduction to Programming (Python); and Transferable skills. * Spring term 15 weeks (1 to 15) Taught modules advance the knowledge and skills acquired during the Autumn term and comprise: Data Analysis II - Applied Biological Data Analysis; Complex Dynamical Biosystems; Biocomputing and Web Applications; and Introduction to Machine Learning. There is a greater emphasis on research work during this term with a 12-13 week individual project. * Summer term 18 weeks (1 to 18) This term is devoted almost entirely to a 17-18 week research project normally carried out on placement in industry, a research institute or academic institute."
897A551A-E092-4F7C-952F-B4CA14C09B41,"The COVID-19 pandemic has highlighted the importance of a number of different scientific fields in helping to tackle the spread of an infectious disease. One of these fields is pathogen genomics, which has, through the analysis of sequenced SARS-CoV-2 genomes, enabled the detection and tracking of different variants of the virus. The UK is particularly strong in this area, with the COVID-19 Genomics UK Consortium (COG-UK) providing important inputs into the government response to the pandemic.

Rapid sequencing of pathogen genomes is now possible. One possible use of this data is in real-time tracking of pathogen evolution and transmission through reconstruction of the ancestral history of sequenced genomes (phylogenetic inference). The pandemic has shown the value of having such information available (see, for example, the work of Nextstrain, https://nextstrain.org/).

The state-of-the-art in phylogenetic inference is to use Markov chain Monte Carlo (MCMC) algorithms for the Bayesian inference of the ancestral history, preferred due to its philosophy of rigorously describing the uncertainty associated with inferences drawn from the data. This approach is implemented in the BEAST (https://beast.community/) and BEAST2 (beast2.org) packages but in their current form these are unsuitable for &quot;real-time&quot; inference, since they perform inference on a batch of genome sequences. If a new sequence becomes available after starting the a run of the MCMC in the software, the algorithm must be restarted to take account of the new data. These MCMC algorithms are often run for tens of millions of iterations, so this process of restarting the algorithm is computationally wasteful and hinders the goal of real-time inference. This project proposes an alternative approach, with the aim of making real-time Bayesian inference feasible for large numbers of sequences, preparing the ground for a deployable system that could be used during a pandemic."
4486DCB1-2640-45CF-B3BF-4BAD63CFA220,"Background
--
Science is discovering the exciting world of genes, how they interact, how they differ from person to person and the process by which they ultimately form the templates for proteins, the building block of life. But genes are more complicated than we thought. It seems that genes can be transformed: somewhere between the DNA code for a gene and the final protein, genes can be 'spliced' to make different types of proteins and to form other molecules that interact with the gene system. 

In a healthy cell, this splicing is useful! It allows us to store the code for different proteins in a single gene. But splicing has been implicated in disease, in particular, Motor Neurone Disease (MND), a debilitating and poorly understood disease. Recently, researchers have found a small part of the genetic code (which we call C9ORF72) which may be a tiny clue in understanding MND, and it seems to have a huge effect on splicing. 

New technology is allowing us to uncover the world of genes. Technology developed to sequence the human genome allows us to measure the genes in a cell, right at the point where splicing happens: we call this RNA-Seq. But this sequencing generates LOTS of data, and the amount is increasing. In fact, it's increasing faster than computers are improving. If we want to analyse the data to uncover the world of splicing and the effect it has in MND, we need to create new computational tools which allow us to deal with the data using limited computing resources. 

The Problem
--
RNA-Seq presents us with millions of short sequences which represent the genes after splicing has occured. It's a bit like being presented with a huge bag of jigsaw pieces from thousands of different puzzles: how do the pieces fit together? How many types of picture are there? Which pictures occur most often? There is a lot of uncertainty in the problem, and so we use probabilities to express how the pieces might fit together, and thus how genes have been spliced. 

In recent work, I've examined how to make probabilistic algorithms like this one more efficient, now I will look at how to make use of this type of method in RNA-Seq data. My research will create such tools usings methods based on approximate Bayesian inference. I'll devise algorithms which can deal with these increasing quantities of data, and allow scientists to make statistical inferences from RNA-Seq data about splicing in disease. 

Transferring knowledge
--
To develop such tools, I'll draw inspiration from the related field of natural language processing. With the explosion of the web, data scientists have created methods for organising and categorising our data. One particular statistical method, called a &quot;topic model&quot;, closely resembles the analysis of RNA-Seq. With so much focus on the web, there have been lots of developments in topic models that we can borrow to make our algorithms for RNA-Seq faster and better. I'll investigate how we can transfer these ideas to RNA-Seq analysis. 

There are lots of statistical models that we might want to adapt to study disease through RNA-Seq. For example, we might want to build a time-series model of gene progression, or we might want to find groups of genes which follow the same pattern or trend. To get the maximum efficiency from the data, I'll build these models right in to the reverse-jigsaw problem described above. 

Investigating disease
--
My colleagues are in the process of collecting RNA-Seq data on MND. But the nature of the data will present unforeseen statistical challenges. For example, we might have unknown groupings in patients from whom we have data. I'll use the investigations into MND to inspire statistical models built around the RNA-Seq algorithms that I develop. These methods will be inspired by problems in MND research, but will lead to algorithms that can be used by the wider scientific community in experiments which involve RNA-Seq."
42D138CE-73B2-4AA4-B2BE-1D3C63B277A3,"DTP overview:
This MRC-funded doctoral training partnership (DTP) brings together cutting-edge molecular and analytical sciences with innovative computational approaches in data analysis to enable students to address hypothesis-led biomedical research questions. This is a 4-year programme whose first year involves a series of taught modules and two laboratory-based research projects that lead to an MSc in Interdisciplinary Biomedical Research. The first two terms consist of a selection of taught modules that allow students to gain a solid grounding in multidisciplinary science. Students also attend a series of masterclasses led by academic and industry experts in areas of molecular, cellular and tissue dynamics, microbiology and infection, applied biomedical technologies and artificial intelligence and data science. During the third and summer terms students conduct two eleven-week research projects in labs of their choice. 

Project overview:
Coronaviruses (CoVs) infect a wide variety of animals and birds and can also cause severe disease in humans. The emergence of the novel SARS-CoV-2 virus at the end of 2019 has resulted in the ongoing Covid-19 pandemic that has infected millions of people and caused worldwide social and economic disruption.

In spite of the devastating impact of coronaviruses, many questions regarding the exact molecular details of how they replicate remain unanswered. For example, it is unknown how different parts of the viral genome interact with each other, the precise roles of many of the viral proteins that are involved in viral replication, or even the exact sites of viral replication in host cells. The need for fundamental research into coronaviruses, which can guide the development of novel treatments, is therefore vital.

To date, our knowledge of CoV replication has relied on data obtained using ensemble methods that report on the mean properties of billions of molecules, averaging the measured parameters over the entire molecular population. Single-molecule techniques allow real-time studies of viral replication with the advantage that they can provide direct observations of just one molecule at a time.

The aim of this project is to use single-molecule imaging to study coronavirus replication, using avian IBV and human SARS-CoV-2 as model viruses, and identify important stages of the life cycle that can be targeted with antiviral inhibitors.

The student will gain interdisciplinary skills at the interface of biology, virology and physics, using a wide range of techniques (protein expression and purification, protein labelling, biochemical and biophysical characterisation of protein/RNA interactions, single-molecule FRET, super resolution microscopy, quantitative image analysis, cell culture, virus infectivity assays etc.)."
47EEB650-3DAD-45FA-8109-649C8EF4A790,"Biodiversity underpins long term sustainability of agriculture as well as ecosystems. Current commercial
crops have a extremely narrow genetic base, which is a vulnerability. Seed banks and Herbaria represent
a concentrated resource, collected over many decades and include many heritage varieties with potential
value in the face of climate change and other pressures. The challenge is to extract this information in a
systematic manner that useful to researchers, breeders and agriculture.
We hypothesize that these physical archival materials can be mined for variation in useful traits using
non- or minimally destructive approaches, that include image-based phenotyping, and this variation
related to the underlying genetics.
To test this, well documented grass and cereal collections are available in the AberInnovation Seed
Biobank and in the IBERS' Crop Herbarium. The specific objectives are to:
Obj1. Machine learning tools
To develop robust deep learning protocols and test, a set of manually labelled images from selected test
grasses will be used to train neural networks to recognise and measure features. We have recently
applied deep learning to identify and count organ from both vouchers and uCT scanning (Masters project,
Fig). These deep learning networks will be extended to quantify a wider variety of traits at different
levels of image resolution. For example, higher resolution imaging and deep learning will be applied to
microscopic features such as stomata and vessels that support water transport and gaseous exchange
processes and other minimally destructive modalities will be evaluated (X-Ray Fluorescence imaging for
elemental analyses, metabolomics for nutritive content, etc).
Obj2. De novo test-case experiments
To formally address whether variation in these traits can be linked to underlying genetic variation (and
therefore be useful to breeders), the DR will use vouchers made from genetically unstructured
populations that have been previously created by crossing selected pairs of oats and of ryegrass. These
morphologically diverse and genetically characterised populations provide a rigorous test-case for 
validation of the approach. The student will build quantitative models to account for the genotypic
contribution to variation in features contributing to yield and quality, and compare to models produced
using conventional data.
Obj3. Phenotyping the grass and oat herbaria
A very extensive collection of grass species is populated by original wild samples (with geographic
coordinates) as well as duplicates grown locally under defined agronomy. These will be imaged and,
where appropriate, uCT scanned for seed and stem traits. The samples are crossed referenced to
breeding ledgers and in many cases their pedigree can be traced through to current commercial varieties
while seed can be recovered and regrown as necessary. This physical collection of &gt;10000 samples
provides an unexploited resource to examine genetic and environmental effects across time. The student
will focus on the ryegrass and oats within the collection aiming to exploit advanced genetic analytical
techniques such as GWAS.
Justification and Likely Outcomes: This crop-focused project brings together the Phenomics Centre and
Seed Bank at Aberystwyth with Computer Sciences in Surrey who have previously worked with Kew
Gardens on biodiversity. This combination of expertise combined with large datasets from genetically
defined species will allow design of optimised approaches to extract and interpret the information
content of more extensive collections, available in Botanical Gardens from across the world, and
ultimately extending beyond the grasses to other crops and into wider questions associated with
biodiversity."
87618896-2A53-4DB1-8CF4-EFF044CC6016,"Data science and artificial intelligence will transform the way in which we live and work, creating new opportunities and challenges to which we must respond. Some of the greatest opportunities lie in the field of human health, where data science can help us to predict and diagnose disease, determine the effectiveness of existing treatments, and improve the quality and affordability of care. 

The Oxford EPSRC CDT in Health Data Science will provide training in:
- core data science principles and techniques, drawing upon expertise in computer science, statistics, and engineering 
- the interpretation and analysis of different kinds of health data, drawing upon expertise in genomics, imaging, and sensors
- the methodology and practice of health data research, drawing upon expertise in population health, epidemiology, and research ethics 

The training will be provided by academics from five university departments, working together to provide a coordinated programme of collaborative learning, practical experience, and research supervision.

The CDT will be based in the Oxford Big Data Institute (BDI), a hub for multi-disciplinary research at the heart of the University's medical campus. A large area on the lower ground floor of the BDI building will be allocated to the CDT. This area will be refurbished to provide study space for the students, and dedicated teaching space for classes, workshops, group exercises, and presentations. 

Oxford University Hospitals NHS Foundation Trust (OUH), one of the largest teaching hospitals in the UK, will provide access to real-world clinical and laboratory data for training and research purposes. OUH will provide also access to expertise in clinical informatics and data governance, from a practical NHS perspective. This will help students to develop a deep understanding of health data and the mechanisms of healthcare delivery. 

Industrial partners - healthcare technology and pharmaceutical companies - will contribute to the training in other ways: helping to develop research proposals; participating in data challenges and workshops; and offering placements and internships. This will help students to develop a deep understanding of how scientific research can be translated into business innovation and value. 

The Ethox Centre, also based within the BDI building, will provide training in research ethics at every stage of the programme, and the EPSRC ORBIT team will provide training in responsible research and innovation. Ethics and research responsibility are central to health data science, and the CDT will aim to play a leading role in developing and demonstrating ethical, responsible research practices. 
 
The CDT will work closely with national initiatives in data science and health data research, including the ATI and HDR UK. Through these initiatives, students will be able to interact with researchers from a wide network of collaborating organisations, including students from other CDTs. There will also be opportunities for student exchanges with international partners, including the Berlin Big Data Centre. 

Students graduating from the CDT will be able to understand and explore complex health datasets, helping others to ask questions of the data, and to interpret the results. They will be able to develop the new algorithms, methods, and tools that are required. They will be able to create explanatory and predictive models for disease, helping to inform treatment decisions and health policy.

The emphasis upon 'team science' and multi-disciplinary working will help to ensure that our students have a lasting, positive impact beyond their own work, delivering value for the organisations that they join and for the whole health data science community."
148F076E-B206-4D49-8650-73B7BF5CD021,"State-of-the-art technologies are generating unprecedented amounts of complex data, from genomes, to proteomes and transcriptomes, thus spanning mechanistic and functional diversity. Handling, interpreting and integrating these large scale data into descriptive models that interpret the molecular functions at a system level requires continued development of algorithms, robust computational models, and interoperable analytical frameworks. Supported by our core capability, In this work package, we will contribute to the newest developments in the data sciences and facilitate the extrapolation of meaningful signals from often noisy data. 

We will continue to develop efficient, reproducible and robust assembly and scaffolding algorithms, and robust statistical models to handle diverse complex genomic and metagenomics datasets. We will improve and further develop software to facilitate orthology assignment across complex and highly divergent species. We will also incorporate machine learning approaches to integrate the conservation of functional signals across species to infer functionality and improve annotation. We are also developing new statistical and network analytical approaches will be applied to track temporal and spatial changes across and within species to further inform phenotypic complexity. 

Our algorithm optimisation expertise will enable us to drive computational advances in accuracy and efficiency across our research into assembly and variant calling, annotation and, network analysis. These efforts will put the platforms in place to consistently collect and rapidly feed datasets into downstream integrative analyses, enabling the extensive and complex data interrogation processes required for bringing together multiple heterogeneous datasets. We will also apply these strategies to investigate and implement low power consumption computing technologies for data acquisition and analysis that will be deployed in environmental situations at a previously unavailable scale.

We will carry out fundamental research into software engineering methods to manage, share, visualise and integrate the large and complex datasets. We will develop research data management and dissemination layers, underpinned by community standards, that provide the granularity and searchability of EIs large-scale and diverse data outputs that we are generating, and integrate the statistical, machine-learning, and network-based models developed under this programme. We will also build semantic knowledge graphs annotated with ontology-based descriptions in order to represent the body of information gathered through harmonised data and network integration. These will comprise metadata that describe reusable interconnected research datasets, and we will feed these methods into appropriate information systems to enable national and international collaborative research through open multi-omics platforms.

This will lay the foundations for an interconnected network of hardware and software to deliver real-time monitoring of crop development and pathogen detection and screening. Subsequent federation of these activities with national and international services will be facilitated through the EI NCG in e-Infrastructure (NC3), and interactions with the ELIXIR-UK community for pan-European life science infrastructures. This will also underpin the computational biology needs of the QIB Microbes in the Food Chain ISP in standardised and interoperable analysis systems."
DD90B269-3EFB-45A0-B2DE-550F20D682EA,"Microbiota present a promising and underexploited potential source of novel neuroactive compounds for the treatment of neurological and psychiatric disease in humans. However, due to their diverse and complex interactions with the host nervous system, identifying causal strains and the molecules they produce remains challenging. Here, I address this challenge in the nematode worm, Caenorhabditis elegans, as it is a simple bacterivore with a small nervous system, yet displays a variety of bacteria-influenced behaviours that are observable in the laboratory and governed by conserved neural signalling pathways. I perform phenotypic screening and animal tracking to investigate the behavioural response to various bacteria, in order to highlight behaviour-modifying strains for follow-up analyses to investigate the kinds of neuroactive molecules they produce, and their genetic targets in the worm. Preliminary results find multiple bacterial strains that elicit significant effects on C. elegans behaviour. Follow-up research on these bacteria could lead to the discovery of novel compounds for the molecular control of neural states to treat disease."
323024EB-B13C-4E92-A2A8-7DC248783E0B,"Organ formation is controlled by the action of gene regulatory networks (GRNs) deployed in cells that are interacting with their neighbours through cell contacts and cell signalling networks. This proposal is designed to develop novel nonparametric Bayesian methods to extract the quantitative input/output relationships among gene products in the functioning GRNs that coordinate the patterning, growth and morphogenesis driving organogenesis. The Fraser Laboratory is refining and deploying technologies which will enable the reliable creation of gene expression reporters through multiplex imaging and genome profiling of discrete cell populations, creating &quot;test points&quot; that can be used to watch aspects of a GRN as it functions. Tagging multiple components of the GRN with distinct labels makes it feasible to read out the quantitative state of a GRN in a cell-specific and time-resolved fashion. To read out these &quot;test points&quot;, Fraser's group is refining the equipment needed for quantitative imaging of multiple gene products over the contiguous space of a developing embryo. The novel Bayesian-based computational tools to be developed in this project will be used to reverse engineer and analyse GRNs at various scales of granularity, based on the quantitative imaging of these &quot;test points&quot;. Ultimately, this research will permit elaboration of a more complete GRN and its linkage to key morphogenetic events by combining real-time, multiple-gene reporters, multiplex imaging and Bayesian modelling approaches. Once validated, the kit of imaging and computational tools will be broadly applicable for defining the GRN in less well-studied and accessible systems."
922DB6E8-03E2-4690-990F-6E79F094463F,"Abstract: 

Rheumatoid arthritis is a chronic inflammatory disease characterized by immune-mediated pathology. In the order of 400,000 people in the UK suffer from the disease to varying degrees. The underlying pathology is still not sufficiently understood. However, it is clear that different patients display different responses to treatment with either conventional disease-modifying antirheumatic drugs (cDMARDs) e.g. methotrexate or biologic bDMARDs such as anti-TNF monoclonal antibodies and JAK inhibitors (tsDMARDs). The Scottish Early RA Cohort (SERA n=1173), together with a series of clinical trials that have been led by the University of Glasgow in people with early RA e.g. &quot;ORBIT&quot; and &quot;TASER&quot;, have generated a unique biobank within which a range of transcriptomic and metabolomics datasets have been derived but as yet not integrated in terms of data analyses. Specifically, we have RNAseq data available from SERA (early untreated RA and undifferentiated arthritis), RNAseq and mass spec metabolomic data available from TASER (early untreated RA) and RNAseq and shortly metabolomics datasets available from ORBIT (RA failing first cDMARD and randomised to receive rituximab or TNF inhibitor(see McInnes et al. 2017). 

Biomarker approaches using pharmacogenomic approaches or using RNAseq alone have been unhelpful so far in RA in offering reliable drug response prediction. Combined metabolomics and trancriptomics data are likely to provide more inference about the factors that distinguish between responders and non-responders, but combination of these data types remains an open problem. This project therefore seeks to address this problem in order to identify new biomarkers arising from combinatorial scoring systems, that can be used to predict likely response and enable choice of the right treatment for each patient.

Aims:

1. Analyse and compare transcriptomic datasets from several RA patient cohorts
2. Analyse and compare metabolomics datasets form several RA patient cohorts
3. Integrate metabolomic and transcriptomic data to seek additional inference on pathways predictive of therapeutic response
4. Generate a panel of metabolite/transcript biomarkers to enable robust prospective prediction of therapeutic outcomes in RA treatment

Training outcomes:

The student will receive directed Bioinformatics training to analyse transcriptomic (Supervisor: Watson) and metabolomics (Supervisor: Barrett) datasets using existing and novel software. They will also receive training in machine learning, Bayesian statistics and computer programming (Supervisor: Rogers) to develop novel algorithms that enable new ways to probe combined metabolomics and transcriptomics datasets. This computational work will feed into clinical understanding of RA (Supervisor: McInnes).

References:

McInnes, I.B., Schett, G. (2017) Pathogenetic insights from the treatment of rheumatoid arthritis. Lancet. 389, 2328-2337. PMID: 28612747

Creek, D.J., Jankevics, A., Burgess, K.E., Breitling, R., Barrett, M.P. (2012) IDEOM: an Excel interface for analysis of LC-MS-based metabolomics data. Bioinformatics. 28, 1048-9. PMID: 22308147

Robert C, Watson M. Errors in RNA-Seq quantification affect genes of relevance to human disease (2015) Genome Biol. 16:177 PMID: 26335491

van der Hooft, J.J., Wandy, J., Barrett, M.P., Burgess, K.E., Rogers, S (2016) Topic modeling for untargeted substructure exploration in metabolomics.. Proc Natl Acad Sci U S A. 113, 13738-13743. PMID: 27856765"
80C10567-0CBA-4DFD-BFA0-6B710930A69E,"We propose to use novel approaches for AI vaccination using recombinant herpesvirus of turkey (HVT) and avian infectious bronchitis virus (IBV) as vaccine vectors that express protective haemagglutinin (HA) and neuraminidase (NA) antigens of avian influenza virus. Since these vaccine constructs will express only selected AI antigen, vaccinated birds can be unambiguously differentiated from those infected with the field virus. These virus vectors have several distinct advantages: (1) they are extensively used as live virus vaccines. (2) they induce immunity following in ovo vaccine application. (3) it is relatively easy to generate new vaccines from the specific field isolates. Recombinant HVT and IBV vectors will be generated by cloning HA and NA genes (the multiple basic amino acids at the HA1 &amp; HA2 cleavage sites will be deleted) from the HPAI viruses, [A/os/Italy 984/00 (H7N1) and A/ty/Turkey/1/05 (H5N1)], into the HVT and IBV genomes using in house derived reverse genetics systems. We plan to generate a panel of recombinant viruses (1) HVT/H7/N1 (2) HVT/H5/N1 (3) IBV/H7 (4) IBV/H5 (5) IBV/N1 for use as potential vaccine candidates. The recombinant viruses will be evaluated for expression of the AI-derived HA and NA genes in cell culture and in ovo. Selected viruses will be used in homologous virus challenge studies in chickens for comparison with commercially available inactivated vaccines. The protection parameters of the vaccines candidates will be assessed by comparing the immune responses, mortality rates, morbidity and shedding of AI virus from the challenged birds. The data obtained from these experiments will enable us to select the most effective vaccine candidate providing protection against challenge with HPAI AI virus and decrease in excretion of the AI virus. Ultimately, we anticipate that these novel AI vaccines will be used in the eradication of AI by the control of disease and reduction of viral load in the environment."
E4AEBABC-3D8D-4612-8081-D678708398E7,"Understanding the role of environmental adaptation is crucial to develop strategies to mitigate the effects of climate change. Identifying genomic regions involved in local environmental adaptation in species of agricultural interest is among the first steps towards generating a plan to conserve the adaptive potential in those species to guarantee the resilience of agricultural systems in the future. However, identifying those regions has only become possible in the last decades with the development of sophisticated genomic and statistical methods. 
This project will sample water buffalos in Sabah (Malaysian Borneo) and the UK, and genotype them with the Axiom 90K Genotyping Array. This genomic data will be used to characterise the domestication and demographic history of the water buffalo. Additionally, it will be correlated to environmental variables from the samples' collection sites to identify genetic markers involved in local adaptation to Sabah's contrasting environments using state of the art landscape genomic methods. For the UK, correlative analyses between the genetic markers and production traits of interest will be carried out to identify genes of agricultural relevance. The combined results of these efforts will contribute to the generation of recommendations to inform husbandry practices while providing a collection of markers to monitor environmental adaptation. 
The PhD student will be based 75% at Cardiff University, spending 50% of the time at the main supervisor's lab that specializes in identifying signatures of selection using genomics in livestock, while 25% of the time will be spent in Sabah based at Cardiff University's Danau Girang Field Centre collecting buffalo samples in collaboration with the Sabah Wildlife Department (Collaborator). 20% of the time will be spent with the Bristol University's supervisor, a world leader in the development of statistical approaches to study demographic history using genetic data. 5% of the time will be spent with the UK collaborator learning about the water buffalo industry in the UK and contributing to knowledge dissemination in the industry. 
The PhD student will be trained in sampling and bioinformatics for SNP chip analysis (e.g. data quality filtering, demographic analyses, and identifying signatures of selection). This experimental design will enable the PhD student to characterise the domestication process of the swamp water buffalo and identify markers associated to local adaptation and production traits, while controlling for confounding factors such as the demographic history (to be simulated with approximate Bayesian computation)."
3E479EB3-10B3-4672-9C64-A412B79CF503,"Experiments conducted over the last 40 years suggest a role for cyclic nucleotides (CNs) in plant cell
signalling. However, the precise nature of the plant signalling system responsible for modulating CN
levels and responding to changes in CN concentration is not clear. We do know that CN signalling in
plants is different to the canonical system encountered in mammals because no higher plant genome
has been shown to contain either the cAMP activated protein kinase A or PKG that is modulated by
cGMP. However plants do contain a large family on CN-modulated ion channels. Another major issue
has been the lack of a CN modulated phosphodiesterase (cnPDE). In a recent breakthrough
(unpublished) we have used advanced bioinformatics to identify an Arabidopsis gene that encodes a
protein with cGMP PDE activity (AtPDE1). Our analyses reveal that this gene originated in bacteria
and has been retained as a single copy gene in plant genomes but has been lost from animal lineages.
This suggests that there are significant differences between animal and plant CN signalling.
The objective of this studentship, co-supervised by Prof Nick Smirnoff (Exeter) and Prof Kerry Franklin
(Bristol) is to fully characterise the role of this gene in guard cell signalling and to determine its role in
crop water use efficiency. Our unpublished data suggest that it is involved in light and ABA mediated
stomatal responses. The work in the studentship will involve investigating whether cGMP levels are
modulated in guard cells in response to light ABA and CO2 using a novel single cell cGMP sensor
(FlincG). The student will also fully characterise the role of the PDE1 gene in Arabidopsis by using gas
exchange, bioassay techniques and atomic force microscopy (with Prof Merv Miles FRS, Physics) to
monitor stomatal responses in the mutant. We will investigate what other genes are involved in the
cGMP gene regulatory network using transcriptomics and use CRISPR-Cas9 (with Prof K Edwards and
Gary Barker, Biology) to manipulate the expression of PDE1 in wheat and subsequently characterise
its effect on water use efficiency. The student will gain a thorough training in imaging, plant cell and
molecular physiology, gene manipulation and techniques used to investigate stomatal behaviour."
630B8B86-D6E0-44D9-A261-28E9EFD793BB,"This research aims to understand the enigma of how highly virulent viruses that cause lethal outbreaks in humans can persist in bat populations, without causing obvious death and disease in these animals. While some of the reasons likely relate to immune systems targeting the specific viruses, other reasons will relate to the ecology and lifestyles of the bats that host these viruses. When these viruses, which include Ebola and Marburg, transmit into the human population, they cause significant death and disease and occasional major epidemics, as in the recent West African Ebola crisis. If we understood how the viruses persist in their wildlife reservoir, we could identify mechanisms for spillover and develop better means of reducing the likelihood of outbreaks occurring in humans. 

The programme will characterise the actual Ebola- and Marburg-like viruses (termed filoviruses) that infect bats in Ghana, West Africa, where preliminary testing has provided evidence of infection with both viruses. Using data from the characterisation, we will then develop specific tests for the viruses in Ghana, rather than using tests based on viruses found in other parts of Africa. This phase of the work will also characterise variability in Ebola and Marburg, and potentially other filoviruses, in their bat hosts, thereby providing important information for strategies to control them, such as how these viruses are transmitted and the effectiveness of medical interventions. The specific assays developed will include tests to detect viral genomes, which will be able to pick-up low levels of specific viruses as well as blood tests for immune responses to detect prior infection; an important feature is that the tests will be developed against the range of filoviruses actually infecting bats in Ghana. 
Using these tests and working with our long-standing veterinary collaborator in the Ghana wildlife services, we will screen infected bat roosts in Ghana over the 2 year time period of this grant to obtain a picture of how viruses transmit amongst and between different species of bats in Ghana. This will allow us to distinguish whether, for example, Ebola persists at a low level, persistently infecting roosts, or whether the virus depends on spreading waves of infection involving many different interconnected bat roosts. This basic knowledge does not currently exist for filoviruses in bats. 

We will also use our new tests to investigate the presence of past infection of people in Ghana, in particular in those with livelihoods that bring them in close contact with bats (e.g. hunting). 

The work will be delivered through careful collaboration between UK-based and Ghanaian scientists, with a strong capacity building focus. Cambridge University has a major capacity building Cambridge-Africa programme that includes the University of Ghana as a specific partner. Dr Osbourne Quaye, the Ghanaian virologist leading the programme there, has benefitted from a visiting fellowship as part of that programme. This proposed programme will fully resource his laboratory with molecular and serological equipment and also allow for specific training in the specialist assays that will be developed with Dr Wright in Westminster. The field studies in Ghana will be led by Dr Richard Suu-Ire, who recently completed his PhD on bat virus infections in the University of Ghana, co-supervised by Professors Wood and Cunningham. 

We will also establish South-South collaborative links between our Ghanaian collaborators and the University of Makeni Infectious Disease Laboratory (UniMak IDRL), Sierra Leone. This laboratory was established during and following the Ebola epidemic in West Africa with funding from Wellcome and the support of the Cambridge-Africa program to provide capacity in the area of genomics. The equipment within the UniMak IDRL was used during the Ebola epidemic in West Africa to provide real-time sequencing capability."
5CD69D7E-3F35-4651-A142-34F14CC1F9B1,"Blackleg disease of potato caused by P. atrosepticum (Pba) is the most damaging bacterial plant pathogen in the UK, costing &pound;50M p.a. in losses for the potato industry. Current knowledge assumes that disease is caused through Pba-infected seed tubers. However, our recent unpublished data have shown that under high soil moisture following irrigation, disease appears in plants grown from pathogen free seed (minitubers). The most likely explanation is that bacteria enter the plant and cause disease directly from the soil; something not previously considered. We have also shown that Pba is able to colonise roots of other plant species (including crops), possibly as natural rhizosphere-dwelling saprophytes in the soil. In pot trials with Pba alone, we showed there was no movement of Pba from soil into the plant. However, when free-living nematodes (FLN) were added to soil, a 100-fold increase in Pba in stems occurred.

Through these and other findings we now have the potential to make a step change in how we manage blackleg. We will address knowledge gaps firstly by using Light Sheet and Confocal Laser Scanning microscopy, transparent soils and mesocosm studies to assess the role of FLN as vectors of Pba and how infection occurs. We will also examine how changes in standard irrigation regimes can help to reduce levels of blackleg in ware crops (where irrigation is often over-applied to avoid common scab disease that occurs in dry conditions), and how it might change FLN communities around potato root systems. Similarly, we will identify cover crops that limit natural Pba colonisation on their roots as a possible way to reduce Pba numbers in soil prior to planting potato. Little is known about the microbiome on potato roots and how these might be influenced to favour or reduce colonisation by Pba. We will therefore characterise the potato microbiome prior to and following irrigation using shotgun metagenomics sequencing and the latest bioinformatics tools, with a focus on the Pectobacteriaceae and wider Gamma-proteobacteria. We will also use GC-MS to examine how changes in root architecture and the constituents of root exudates influence the composition of these bacterial groups, to assess whether the use irrigation and cover crops alter the balance between beneficial and harmful bacteria associated with potato. Finally, we will determine whether novel antimicrobials (bacteriocins) in closely related non-pathogenic bacteria in the microbiome could act as a management option against Pba.

Our recent modelling research using the Scottish Government's in-house potato inspections database (SPUDS), shows that blackleg incidence on a national scale does not occur randomly but in clusters. Reason(s) for this remain unclear but could be due to several things that, when identified, may assist growers in managing their crops, e.g. potato crop distribution, weather, soil type, soil moisture, leaf wetness, FLN distribution, crop type and rotation prior to planting. Using data generated from this project, an extensive array of data from other recent and historical investigations and the latest data from government and industry we will model, using innovative machine learning methods, at national scale these data to identify trends and drivers of Pba incidence in both space and time and, through this, produce predictive models to support development of a set of decision support tools for evaluation by stakeholders during the project and early adoption thereafter. Further, through scenario testing, we will quantify the predicted effects of climate change on future blackleg incidence in association with FLN presence thus providing the industry with robust and novel data to underpin sector resilience planning."
86515EE3-DF65-4B74-8D8F-877115867172,"Around 80% of all animal species are arthropods: the group that includes insects, crabs and spiders. From their rapid radiation over 550 million years ago, they evolved to fill almost every habitat and exploit most imaginable lifestyles. Today, arthropods underpin virtually all ecological communities and food webs. They are of immense economic and medical importance to humans: as sources of food, crop pests and vectors of disease. 

In order to understand the biodiversity of arthropods, to investigate the mechanisms by which they evolved, and to plan for their conservation, it is vitally important that we have a clear picture of their evolutionary relationships. There are many thousands of published evolutionary trees for particular arthropod groups at a shallow level (e.g., species within families) as well as many that attempt to resolve the more ancient branching events. These published trees represent an enormously rich resource, but one that largely remains locked within the pages of journals. This project will digitise 5,000 or more trees from across the arthropods, and make them available to all researchers electronically online. 

Unfortunately, there are serious difficulties when researchers try to compare published trees: partly because they are derived from many different types of data (anatomy, molecules, genomes and fossils) and partly because they are analysed in an even greater variety of ways. More problematically, they often imply contradictory patterns of evolution. How, then, can we bring all of this information together to yield the giant, all-inclusive trees that evolutionary biologists and conservationists need, and do so without cherry-picking the data? Supertree methods are presently the most tractable approach, resolving conflict and finding overlap between the source trees using objective and repeatable rules. Such approaches have yielded the largest trees ever published. 

Unfortunately, again, the construction of supertrees is presently very time-consuming and labour-intensive. Moreover, once constructed, it is extremely difficult or impossible to add new trees, to sub-sample the data (e.g., molecules or morphology), or to generate supertrees using different methods. Another core objective of this project is therefore to develop a set of software tools that will largely automate the process, providing inexperienced users with the ability to construct a supertree for any arthropod group at any taxonomic level (e.g., species, genera, families, etc.), and using multiple filtering criteria (e.g., only the most robust or recent source trees). We will then embed these tools in the website containing our data. 

Existing, fast supertree methods are not without their problems, and another key objective of the project will therefore be to realise and program novel approaches (new Quartet Joining, Maximum Likelihood, Conservative and Bayesian methods are all under development by members of the team and our collaborators). The properties of these new methods need characterisation, and our arthropod dataset will offer the perfect test case against which to benchmark their performance. 

We will then use our supertrees to ask a range of important questions in the study of arthropod biodiversity. Which evolutionary relationships are well-understood, and which are most uncertain and in need of further research? Which arthropod groups have an evolutionary branching sequence that matches the order in which they appear as fossils (such groups are useful for calibrating 'molecular clocks')? Is there a relationship between the age of arthropod groups and their present day diversity? We will also explore the utility of supertrees for addressing conservation priorities. Species that are alone on isolated branches of the supertree have greater than average 'evolutionary distinctiveness'. Where these are also imminently endangered, a powerful case can be mounted to prioritise their preservation."
D9F00EA5-A21E-4A60-B337-361984B54FE6,"Enterohemorrhagic Escherichia coli (EHEC) O157 are bacteria that have their main reservoir in food production animals, predominately cattle, and can be responsible for serious and life-threatening infections in humans. There are specific factors that define EHEC O157, including a micro-injection (type 3 secretion) system and production of specific Shiga toxins. However, we have known for nearly twenty years that not all subtypes represent the same threat to human health and significant effort has gone into understanding why this is the case. On key reason is that there are different Shiga toxin types, some potentially more toxic than others, and their production levels differ between isolates. This variability comes from the fact that Shiga toxins are introduced into the bacteria by infection with bacterial viruses, known as bacteriophages. These integrate their DNA into the bacterial genome in a 'prophage' state. When the bacterial cell is threatened this can activate the prophage to produce copies of itself and new bacteriophages. From whole genome sequencing of E. coli we are now aware that multiple prophages are present in E. coli genomes, some in different states of decay, but they can impact on each other and recombine to produce new variants. Much of the differences between E. coli O157 isolates are down to their prophage content yet sequence identification methods generally use only 'core' genes for epidemiological studies. 
We have recently applied machine-learning approaches to examine whole genome sequences of E. coli O157 from cattle and humans. We use these as training sets and then ask it to predict which group other E. coli O157 isolates should be assigned to. Surprisingly it only assigns a small proportion (&lt;10%) of isolates from cattle to the human grouping, indicating that only this small subset may be more of a threat to human health. This grant is to investigate the biological basis of this selection process. We know that the machine-learning assignment is based on discriminatory protein variants predicted to be expressed from mainly prophage genes, so this fits with our understanding of the variation present in these isolates. The proposed work will be a combination of bioinformatics research and 'wet' infection biology research. For the bioinformatics we can use subjective and objective approaches to swap gene variants, including whole prophage, between isolate sequences and re-calculate their host prediction scores. This will allow us to define the most important combinations of genes being used for the prediction of zoonotic potential. It may also highlight specific genes to simplify the identification process. In the laboratory we will initially compare isolates that are very similar at the core genome level but differ markedly in their prediction scores. We will examine their gene expression profiles, metabolic profiles and key phenotypes such as Shiga toxin production, cellular interactions and pathology in a mouse model. Then we will swap or mutate genes identified by the bioinformatics and test these strain variants in the same laboratory assays. 
The research should help validate this exciting new approach to understanding bacterial virulence and identify genes involved in the zoonotic threat of this dangerous pathogen. We should then be able to develop simpler approaches to identifying these specific variants on farms and intervene with, for example a vaccine, to reduce the threat to human health. The approach may also work to predict differences in virulence between human isolates and this could have repercussions for how specific outbreaks are managed. This research is timely as it builds on our recent and unique application of machine learning to predict zoonotic potential and access to fully annotated PacBio sequences of UK cattle and human E. coli O157 isolates generated in partnership with Dr James Bono (USDA, Nebraska)."
8789F0F4-8825-48A8-85ED-35D689CB6E5F,"At every genomic position, two individuals are connected through genealogical relationships that lead to a common ancestor. The chronological distance from the individuals to this ancestor is termed time to the most recent common ancestor (TMRCA). This can be generalized to a set of individuals by representing their genealogical relationships by a tree. Moving along the genome, the topology of the trees can change as the genome is broken up by recombination during meiosis. Hence, the evolutionary history of a set of samples can be compactly represented by a graph, called the ancestral recombination graph (ARG), comprised by the individual trees spanning different chunks of the genome. 

There are multiple computationally intensive methods to reconstruct the ARG from high-quality sequencing data of modern DNA samples. Ancient samples are of degraded quality due to environmental conditions and contamination; usually they can only be sequenced at very low coverage making the task of incorporating them into the ARG of a set of modern samples challenging. 

Reconstructing an accurate joint ARG between modern and ancient DNA samples has multiple potential applications that we aim to explore. It can be used for ancestry inference, by recovering the ancestry proportion a modern sample inherits from various ancient ancestral groups, enabling us to reconstruct historical events such as population migrations. We can further exploit ARG topology to detect natural selection, by locating regions of the genome that are unusually shared from certain individuals or ancient groups . Finding regions under positive or negative selection, particularly with known biological functionality, can be especially useful in healthcare-related applications and such regions have, for example, been leveraged to determine drug targets in pharmaceutical settings. Finally, the phenotypic impact of variants can be evaluated by testing whether ancestry from certain groups is more closely related to certain phenotypes.

The project's first goal is to build a relatedness inference algorithm that can infer tree topology and TMRCAs between modern and ancient samples and use it to reconstruct a joint ARG with data from the UK BioBank and other sources. Long-range chromosomal regions that are shared across pairs of samples are informative for this analysis but hard to detect in low coverage ancient DNA, so our algorithm will need to to implicitly or explicitly model haplotype sharing despite the lack of phasing information, or in the presence of noisy computational phasing. 

For this algorithm, we leverage Deep Learning (DL), which has transformed many scientific fields in the past decade. Population genetics has traditionally focused on developing complex parametric models and has not yet significantly benefited from DL advances. Sequencing data has a spatial structure, so sequences from multiple samples can be stacked to form an image and analysed using computer vision approaches (e.g. Convolutional Neural Networks),adjusting for the fact that sample order is irrelevant (i.e. require exchangeable networks). As we already have access to an ARG for modern samples, our aim is to explore the use of attention- and graph-based methods to extract ARG information that will help infer ancestry between modern and ancient samples.

Overall, we expect to make two main contributions. The first is algorithmic development that will allow the use of DL for reconstructing joint genealogical trees for modern and ancient DNA samples, tackling quality issues for the latter. The second is joint ARG inference using real UK Biobank and ancient data. We then aim to analyse this ARG to answer questions relating to natural selection and phenotypic impact of having ancestry from certain ancient groups."
587F6C7E-27B7-4CB5-8D47-A1D87C4CD07F,"GenomeKey is developing a next-generation point-of-care diagnostic device for bacterial blood infections in cases of sepsis. Our diagnostic will result in earlier and more accurate detection and diagnosis of bacterial sepsis, and faster antimicrobial susceptibility results, leading to better treatment, patient outcomes and considerable treatment cost savings. In addition, our device will allow clinicians to better manage use of antibiotics and provide broad surveillance of antimicrobial resistance and pathogen strain in hospitals and communities, thereby enabling better antibiotic stewardship and limiting the spread of resistance.

What sets GenomeKey's approach apart, from other contemporary approaches to infection diagnosis, is our innovative technology. The current gold standard takes upwards of 3 days for a condition that can kill in hours. To overcome this we have developed a rapid diagnostic which classifies species ID and antimicrobial susceptibility directly from the genome of the invading pathogen and arrives at the desired clinical information much faster, reducing the time to result from days to only hours. With GenomeKey's proprietary machine learning approach we are able to determine the antibiotic resistance to a greater accuracy than existing tests which are based on a target panel of biomarkers.

The medical diagnostic device GenomeKey is developing will be a significant step forward for the clinical diagnosis and treatment of sepsis. Rapid genomic sequencing enables us to bypass the need for culturing which is the fundamental limiting step in today's practice. GenomeKey's diagnostic is a replacement for blood culture and will detect the infectious agent within hours, rather than days. This device will be designed for use within hospital microbiology labs and for Point-Of-Care, allowing clinicians to go from sample to result at the patient bedside. To achieve the objectives of this grant we have brought together a team of expert scientists and engineers, supported by strong project and business management and commercial experience. Moreover, our external support network is expansive, including NHS clinicians and microbiologists, and the Academic Health Science Networks (AHSN). Through this grant, we will protect our key intellectual property, set out our regulatory pathway, develop a proof-of-concept prototype device and validate this with _in vivo_ models, preparing us for the next phase of product development and clinical testing."
C5FFEED0-B532-4034-8175-2207F54A6466,"This project sets out to understand the critical factors affecting the adoption of PGt/x in NHS cardiovascular practices. Cardiovascular diseases (CVDs) are the most common causes of mortality in the UK and a number of important cardiovascular drugs have PGt/x indications that may be employed to personalise therapies making them more effective by optimising dosages, reducing adverse drug reactions and overall providing better care for patients with significant returns for the NHS. Can we learn from oncology where PGt/x knowledge is already at a relatively advanced stage of implementation in clinical practice? We shall unpack institutional and organisational arrangements to identify innovation management practices that favour the application of PGt/x and personalised approaches in cardiovascular medicine.
The focus of the study is the contextualisation of PGt/x knowledge in the NHS. Studies have shown that while there has been tremendous investment in early-stage research from basic science to human studies in the UK, less effort and investments have been given to the translation and implementation of new knowledge in clinical and health decision making. Thus, our contribution aims at understanding the institutional, organisational and innovation management issues driving and/or hindering translation of advanced PGt/x and clinical knowledge in a personalised approach to heart and circulatory diseases. To this end, this research will deep-dive into how the behaviour of NHS professionals become institutionalised. This means understanding the socio-technical dimensions of how new routines emerge, how organisations innovate and how this change process (medical innovation) is managed to introduce PGt/x knowledge on the cardiovascular wards of the NHS. 
We use the ongoing progress in oncology and personalised cancer therapy to reflect upon the supporting/inhibiting factors affecting the implementation of PGt/x knowledge in the CVD domain. The project capitalises on a strong multidisciplinary team incorporating complexity and medical innovation scholars, pioneers in pharmacogenetic research and its applications in medical practice, oncology and cardiovascular clinicians.
The research plan comprises 4 phases to be carried out over 36 months. Phase 1) consists in mapping the knowledge available on PGt/x - drug associations and conduct a review of the literature. These will be used to draw a typology of factors underlying the implementation of PGt/x knowledge in practice. Phase 2) and Phase 3) will develop cases studies in oncology and cardiovascular medicines respectively. The rationale behind this choice is due to the diverse penetration of PGt/x within the two medical fields. Phase 4) shall comprise the systematic comparative analysis, the preliminary report, validation and engagement with the wider academic communities in medical and social science disciplines, patient advocacy groups and policy makers.
The study will be conducted within a number of active clinical units in the NHS identified as early adopters of PGt/x in clinical practice. The methodology developed will contribute to advancing our understanding of the general principles to implementing PGt/x in cardiology with a socio-technical focus on the necessary technologies, institutional and behavioural changes within the organisation. These can be broadly seen as innovation management steps beginning with the identification of stakeholders who are key to implementation, testing/care with practical repercussions on the implementation of PGt/x guidelines in cardiovascular medicine.
The project will benefit from oversight and guidance of an advisory board comprising academics, a clinician and a patient representative. Em.Prof Stan Metcalfe (UoM), Prof Alex Faulkner (Sussex), Prof Ellen Moors (Utrecht), Prof William Newman (NW - Genomic Medicine Service Alliance), Ann Bamford (GM - Integrated Stroke Delivery Network)."
A9E72193-CAF9-43E6-A7DA-EABA5459BB64,"Why do trees die? How do the rates and drivers of tree mortality vary from the tropical rainforest to the boreal? How do these mortality rates affect forest structure? These questions are crucial in order to understand large-scale forest dynamics. They are also of fundamental importance for our understanding of how climate change will evolve because forest ecosystems are huge stores and sinks of carbon.

Hot droughts are expected to become more prevalent under climate change (Seneviratne et al., 2012), resulting in a lot of focus in recent years on how trees die under drought (Allen et al., 2015; Hember et al., 2016; Rowland et al., 2015). Yet little is known about the extent to which drought usually plays a role in tree mortality in the different ecosystems around the world. For instance, is drought a more prevalent driver of tree mortality in areas that are commonly hot and dry, or in those where such conditions are a relatively rare occurrence? Which types of tree are most vulnerable and how is this affected by their status in the ecosystem?

This project will apply the latest machine learning techniques developed for genomics problems (Basu et al., 2018) to identify patterns and relationships between drought and tree mortality in of a range of forest inventory and remote sensing datasets, spanning global forest biomes. This new process-knowledge will then be integrated within a state-of-the-art global ecosystem model (Smith et al., 2014), to understand the implications of drought-induced tree mortality for current and future forest structure and carbon cycling, thus achieving a complete flow from observations, to understanding, to implications.
This project has the potential to substantially advance understanding of how drought interacts with forest at a biogeographical level - the scale that is most relevant for understanding feedbacks of tree mortality on future climate change.
The studentship collaborates with Operation Wallacea, a major source of inventory data from the tropical forests, which will be analysed for the first time for tree mortality within this project. The student will be part of a larger team working on tree mortality through the TreeMort project (more.bham.ac.uk/treemort)."
AE87E81E-FD5A-411F-939C-8A805E2FDC46,"Under the threat of climate change, an expanding worldwide population, and increasing movement of goods and people worldwide, the challenges for agriculture have never been more pressing. Barley (Hordeum vulgare subsp. vulgare) was one of the earliest domesticated crops which occurred 10,000 years before present. Barley has and continues to be impacted by several plant disease including rust, mildew, blast, scald, smut, and others. The wild progenitor of barley is H. vulgare subsp. spontaneum, a species with a wide range from North Africa to southwest China. Wild barley is in the primary gene pool of domesticated barley; therefore, it can be directly accessed through breeding to improve barley. This project sets out to understand immune receptor diversity in wild barley and to identify genes that can be used to improve domesticated barley. Skills that will be gained during the project include bioinformatics (high-throughput genomics, big data), genetics (biparental and association), modern plant breeding, and molecular biology. 
This PhD project will be supervised by Dr. Matthew Moscou at The Sainsbury Laboratory and is an industrial collaboration with KWS, a leader in barley breeding in the UK. The Moscou group focuses on understanding immunity in the grasses, with the goal of engineering durable disease resistance in the major cereal crops (barley, wheat, rice, and maize)."
32A0F0E4-53D7-4EFE-8A4B-B72F9ED439D6,"There is a growing need for specialised expertise in data science to support the work of researchers and healthcare professionals including clinical scientists, specialist registrars or consultants in medical microbiology in the UK, as the nature of their work changes and needs to incorporate big data, sequencing and genomics. 
While curricula in the UK teach some genomics and data analysis and interpretation to these audiences, most training is left to advanced professional courses through postgraduate programmes and other independent training providers. 

This proposal is motivated by the great demand in training for data science skills for genomics related to infectious pathogens, and a growing need for skilled trainers. Our goal is to enhance training capacity across the UK, able to provide education in Data Science for Pathogen Genomics and Surveillance for healthcare professionals working in the field of clinical microbiology.

We plan to achieve this by 1) implementing a series of Train-the-trainer (Tt) courses 2) offering mentorship and encouraging networking and 3) building and publishing freely available training resources. While regular training courses provide individual participants with skills on how to analyse and interpret their own data, TtT approaches apply the concept of forward teaching and equip professionals who are already knowledgeable in pathogen genomics data science with the skills needed to train others.

A key focus will be training participants in teaching and facilitation skills. We will also develop a project-based learning approach, where participants will be mentored to build their own training materials. This will be followed by in-person sessions, where they will demonstrate how they will deliver training to others and will receive feedback on their teaching methods. Participants will be supported to deliver training in their research or work environments, through mentorship and networking. 
By the end of the project, we will publish freely available, ready-to-use training resources for use by trainers in data science for pathogen genomics in the UK. 
This proposal brings together the expertise of the Centre for Genomic Pathogen Surveillance (CGPS) and the Wellcome Genome Campus Advanced Courses and Scientific Conferences (ACSC), who have previously collaborated in running several courses, including &quot;Train-the-trainer Capacity Building for Genomic Surveillance of AMR in LMICs&quot; (2019, Wellcome Genome Campus). 
 
CGPS works to translate the analysis of pathogen spread and AMR research into public health benefit, by the generation of open-access tools for the interpretation of local sequence data in a global context. CGPS has experience in all aspects required to build capacity in genomic AMR surveillance, drawn from running an NIHR Global Health Research Unit, in collaboration with laboratories from Colombia, India, Nigeria and The Philippines. 


ACSC have over 30 years experience in delivery of training courses for researchers and healthcare professionals. Key courses include Genomics of Clinical Microbiology and Genomics for Clinical Virology, which are primarily targeted at genomics researchers and healthcare professionals including clinical scientists, specialist registrars or consultants in medical microbiology in the UK. Online Future Learn MOOC courses developed by ACSC (https://www.futurelearn.com/search?q=bacterial+genomes) attract tens of thousands of participants every year. To date, ~13% of the online participants are from the UK (10,7k from the UK out of 79k total). 
 
In summary, this project will develop a framework for new training resources tailored to professionals in clinical microbiology fields, enabling use of data science tools to enhance healthcare in the UK. Emphasising on mentorship and network building, the programme will provide a sustainable, standardised and scalable training model both for TtT and for direct training."
DFA8DCB6-2DD5-409D-9958-646CE215EE6A,"Epigenetics is the study of heritable changes in gene and genome function that occur without changes in the DNA sequence itself. It is mediated by chemical coding recorded on top of the DNA sequence which is found throughout nature and affects many biological processes in health and disease. These mitotically heritable, yet reversible chemical modifications act upon the chromatin structure and specific DNA bases to regulate gene expression in a cell-specific manner. DNA Methylation is one such modification where individual cytosine bases undergo methylation producing 5-methylcytosine. In mammals including humans, it occurs predominantly in the context of cytosine guanine dinucleotides (CpG sites).
Due to its central role in normal human development and numerous diseases, genome-wide DNA methylation (methylome) analysis is of broad interest in medical research. However, generating DNA methylomes on a large scale is quite expensive; considerably more so than whole-genome sequencing. This is because of technical issues inherent to bisulfite sequencing (e.g. DNA fragmentation, incomplete bisulfite conversion, reduced mapping efficiency), requiring a higher sequencing coverage in order to confidentially call the methylation status at a cytosine residue. One potential way to reduce this cost is to explore in silico methodologies, such as imputation, to improve the coverage and quality of the data produced in these experiments.
Imputation is a statistical technique where missing values are substituted with a computed value1. The process requires reference data from which the missing information can be extracted and imputed to boost quality, power, fine-map associations and facilitate integrative analysis using meta data. Imputation of genotypes as well as haplotypes has become routine and has already proved invaluable for the discovery of many replicated associations for many complex human diseases2. In comparison, imputation of epi-genotypes such as DNA methylation states is still in its infancy. Current methylation imputation/recovery techniques include ChromImpute3, COMETvintage4 and DeepCpG5 which impute/recover missing data in Whole-Genome Bisulfite Sequencing (WGBS). ChromImpute utilises regression tree ensemble predictors to impute multiple epigenomic signals (including DNA methylation). COMETvintage uses segmentation to calculate blocks of co-methylation (COMETs) to recover differentially methylated signal missing from methylomes not sequenced deep enough. DeepCpG utilises deep learning techniques to determine associations between DNA sequence patterns and methylation states as well as between neighbouring methylation sites. Neither of these tools has yet been used to reduce the cost of methylome analysis by reducing sequencing depth while increasing data quality and accuracy."
D334F311-B75B-44C8-9561-94B9C4BDE09D,"Around 80% of all animal species are arthropods: the group that includes insects, crabs and spiders. From their rapid radiation over 550 million years ago, they evolved to fill almost every habitat and exploit most imaginable lifestyles. Today, arthropods underpin virtually all ecological communities and food webs. They are of immense economic and medical importance to humans: as sources of food, crop pests and vectors of disease. 

In order to understand the biodiversity of arthropods, to investigate the mechanisms by which they evolved, and to plan for their conservation, it is vitally important that we have a clear picture of their evolutionary relationships. There are many thousands of published evolutionary trees for particular arthropod groups at a shallow level (e.g., species within families) as well as many that attempt to resolve the more ancient branching events. These published trees represent an enormously rich resource, but one that largely remains locked within the pages of journals. This project will digitise 5,000 or more trees from across the arthropods, and make them available to all researchers electronically online. 

Unfortunately, there are serious difficulties when researchers try to compare published trees: partly because they are derived from many different types of data (anatomy, molecules, genomes and fossils) and partly because they are analysed in an even greater variety of ways. More problematically, they often imply contradictory patterns of evolution. How, then, can we bring all of this information together to yield the giant, all-inclusive trees that evolutionary biologists and conservationists need, and do so without cherry-picking the data? Supertree methods are presently the most tractable approach, resolving conflict and finding overlap between the source trees using objective and repeatable rules. Such approaches have yielded the largest trees ever published. 

Unfortunately, again, the construction of supertrees is presently very time-consuming and labour-intensive. Moreover, once constructed, it is extremely difficult or impossible to add new trees, to sub-sample the data (e.g., molecules or morphology), or to generate supertrees using different methods. Another core objective of this project is therefore to develop a set of software tools that will largely automate the process, providing inexperienced users with the ability to construct a supertree for any arthropod group at any taxonomic level (e.g., species, genera, families, etc.), and using multiple filtering criteria (e.g., only the most robust or recent source trees). We will then embed these tools in the website containing our data. 

Existing, fast supertree methods are not without their problems, and another key objective of the project will therefore be to realise and program novel approaches (new Quartet Joining, Maximum Likelihood, Conservative and Bayesian methods are all under development by members of the team and our collaborators). The properties of these new methods need characterisation, and our arthropod dataset will offer the perfect test case against which to benchmark their performance. 

We will then use our supertrees to ask a range of important questions in the study of arthropod biodiversity. Which evolutionary relationships are well-understood, and which are most uncertain and in need of further research? Which arthropod groups have an evolutionary branching sequence that matches the order in which they appear as fossils (such groups are useful for calibrating 'molecular clocks')? Is there a relationship between the age of arthropod groups and their present day diversity? We will also explore the utility of supertrees for addressing conservation priorities. Species that are alone on isolated branches of the supertree have greater than average 'evolutionary distinctiveness'. Where these are also imminently endangered, a powerful case can be mounted to prioritise their preservation."
54B15D44-817C-4787-882A-4723599550D6,"Drugs against diseases caused by viruses, bacteria and parasites have transformed human health and saved millions of lives. Nevertheless, their widespread use and misuse has led to the emergence of antimicrobial resistance (AMR) that poses a potentially catastrophic threat to public health. The increasing power of genomic sequencing is offering new ways to rapidly detect and respond to the development of antimicrobial resistance. The availability of this wealth of data, along with the latest developments in artificial intelligence / machine learning (AI/ML) techniques, allows the development of sophisticated approaches that can fully leverage this data to pre-empt the effects of potential resistance mutations.
 
The aim of this project is to develop new computational tools for automatically analysing the molecular consequences of single nucleotide polymorphisms (SNPs) linked with therapeutic resistance from genome wide association studies (GWAS) and to use this wide-ranging iterative analysis to build a predictive model to identify future SNPs that could lead to therapeutic failure. It will focus on analysing point mutations, singularly and as observed haplotype combinations, that represent one of the major routes to resistance. It will leverage the wealth of in-house and publicly GWAS linking SNPs to drug resistance. By exploiting the latest state-of-the art tools for predicting various measures of the effect of a mutation, this offers an exciting opportunity to measure the biophysical functional, geometrical and genomic effects these mutations are having on proteins on a large scale across different organisms and resistance types.

Such insights will be used to develop a novel computational tool utilising the latest developments in machine leaning to anticipate mutations leading to resistance before they become fixed in a given pathogen population. The ability to effectively predict the effects of such mutations has several applications including in the development of the next generation of drugs. The tool can be used to make an informed decision as to the effects of mutations on a potential drug binding region, as well as connected distal regions, that might lead to the drug becoming less effective. If areas that are tolerant of mutations can be avoided, drugs with a longer clinical life can be developed. This is important in pathogen drug management, and especially for neglected tropical diseases, where new therapeutics are difficult to develop and market incentives for developing new drugs are weak.

These new tools will be validated building on our preliminary research in tuberculosis by independently predicting likely resistance mutations in target proteins from studies currently being undertaken by us. As well as helping validate our method it will also provide new insights into routes of resistance. Moreover, the new tools will be applied by us and collaborators within our existing drug discovery programs against a range of infectious disease agents e.g. schistosomiasis. The results of the application to real situations along with validation will be used to iteratively feedback and improve the machine learning tool.

This research project takes a novel approach to addressing the critical threat of AMR as highlighted in the 2014 UK Review on Antimicrobial Resistance. The new approaches can be used to inform the development of novel therapeutics and in turn promises to answer specific questions around the modes of resistance in individual infectious disease organisms. It has the future potential to be applied in identifying early emergence of resistance and in clinical diagnostics. By contributing new tools and methods it will help ease the burden of AMR, before it becomes a much larger drain on our healthcare system."
17026E82-68FC-4FBB-B2A0-D20C2C479864,"Programme overview:
This MRC-funded doctoral training partnership (DTP) brings together cutting-edge molecular and analytical sciences with innovative computational approaches in data analysis to enable students to address hypothesis-led biomedical research questions. This is a 4-year programme whose first year involves a series of taught modules and two laboratory-based research projects that lead to an MSc in Interdisciplinary Biomedical Research. The first two terms consist of a selection of taught modules that allow students to gain a solid grounding in multidisciplinary science. Students also attend a series of masterclasses led by academic and industry experts in areas of molecular, cellular and tissue dynamics, microbiology and infection, applied biomedical technologies and artificial intelligence and data science. During the third and summer terms students conduct two eleven-week research projects in labs of their choice. 

Project:
How chromosomes are organised within the cells, how this organisation affects gene expression, provides protection for the underlying genetic information and allows correct segregation of chromosomes at mitosis is a fundamental question in cell biology. Although significant progress has been made at the nucleosome and chromatin fibre level, much less is known about how chromatin fibres fold into larger, mega-base domain structures, and how these structures behave in the cellular setting. This project is aimed at probing such chromosome structures using a unique labelling strategy to follow the movements of chromatin domains in living cells. Furthermore, the project will utilise quantitative image analysis combined with mathematical modelling to develop predictive models of the kinetics of chromatin domain movement and reestablishment of domain structure after mitosis. 
The project will deliver training in a number of current and emerging techniques to probe the architecture of chromatin in the nucleus. These will include molecular cloning, cell culture, live-cell imagine, quantitative image analysis and mathematical modelling. 
The multiplicity of techniques as well as the areas of science these span make the project a perfect fit for the framework of the MRC strategic skill priorities, as these encompass quantitative and interdisciplinary skills, which the MRC deems crucial for the establishment of future research leaders that are able to address issues in areas of unmet national need by employing varied and advanced research skills."
2DD92D33-6760-4686-B8DD-806FA2FCABD5,"The yeast synthetic genome project, the largest Synthetic Biology project to date, provides yeast, Saccharomyces cerevisiae 2.0 (Sc2.0), with chromosomal loxP sites, enabling Synthetic Chromosome Recombination and Modification by LoxP-mediated Evolution (SCRaMbLE, Science 2017, 355, 1040-1045). In this project, we will exploit Sc2.0 as a platform for producing valuable natural products (NP), including essential antibiotics (e.g. Nature Catalysis 2018, 1, 977-984), anticancer agents, immunosuppressants and statins (blockbuster drugs). Unlike the wild-type S. cerevisiae, Sc2.0 has synthetic chromosomes (re-designed DNA sequences chemically synthesized), enabling the genome to be scrambled, generating mutants where genes have been rearranged, deleted or duplicated. We have shown that, by introducing heterologous biosynthetic gene clusters into Sc2.0, it is possible to generate scrambled mutants with enhanced capacity for producing target compounds (Nature Commun. 2018, 9, 1936). However, screening large numbers (billions) of Sc2.0 mutants generated by genome scrambling is challenging. To this end, we will develop biosensors, based on modular riboswitch components (e.g. J. Am. Chem. Soc. 2015, 137, 9015-9021 &amp; J. Am. Chem. Soc. 2014, 136, 10615-10624), that can bind to the target NP and trigger a fluorescent response. By introducing biosensors into Sc2.0, along with the genes required for the biosynthesis of the target NP, we will be able to rapidly select the scrambled mutant cells that produce the highest levels of the target compound; these cells will be fluorescent and can be easily separated using a fluorescence activated cell sorter. Strains producing highest yields of desired compounds, will be subjected to further rounds of scrambling with biosensor screening, and their genomes will be sequenced. The project will provide a paradigm shift in pathway (metabolic) engineering, that could lead to more cost-effective and sustainable production of antibiotics required to combat antimicrobial resistance (AMR), as well as other essential medicines. This ambitious project provides cutting-edge training in synthetic biology, spanning NP biosynthesis, RNA-based biosensors and genetics. The project will be supervised by Profs Jason Micklefield and Patrick Cai, and will be based in the Manchester Institute of Biotechnology (MIB) and SYNBIOCHEM centre at the UoM, with world-class facilities and training opportunities."
1BC74CA2-BF14-42EB-B0D1-F94B1A88CFAC,"Dr Anyela Camargo, will add her expertise in computer vision, systems biology, statistics and bionformatics to the project. She has been interested in the topic of plant disease monitoring since his time at Corpoica where she developed a tool for monitoring cotton crops. At Liverpool University she developed a system for the early detection of plant disorders. Later she was involved in the modelling of the gene network describing stress responses in Arabidopsis. Now, she is using the Brachypodium distachon plant model to identify genes associated to the resistance to blast rice.

Prof. John Doonan is the director of the National Plant Phenomics Centre, he will add his expertise in genetics and molecular biology to help characterise, from the molecular point of view, the resistance to wheat to tan spot project.

Dr Narcis Fernandez-Fuentes has over 10 years of experience in different aspects of Bioinformatics and has developed a number of databases and web-servers widely used by the scientific community. Dr Fernandez-Fuentes is currently leading the Bioinformatics research within IBERS' C3G ISPG grant program, part of which relates to the discovery of genes linked to a range of traits of interest by combining a range of 'omics datasets and developing integrative approaches.

Professor John Draper has worked extensively at the interface between plant biology, analytical spectroscopy and computer science. Internationally he has been a pioneer in the use of metabolomics and machine learning to investigate the early stages of pathogen invasion in non-symptomatic host tissue. He has a long publication record in metabolomics, Brachypodium biology and plant defence. 

IBERS, at Aberystwyth University, is a major centre for public sector plant breeding for ryegrasses, forage and oats. IBERS has an in-house high performance computer (HPC) facility, Next Generation Sequencing labs and the UK's unique National Plant Phenomics Centre. The NPPC is based around automated non-destructive image analysis system running in a purpose-built glasshouse complex. The system is designed to cope with a range of plants, including small and large plants such as oats, wheat, barley, maize and Miscanthus. The NPPC provides a focus for trans-disciplinary research to facilitate the discovery of the genetic and environmental basis for variation in complex traits that underpin the major global. Also within IBERS, the Genome Diversity and Plant Breeding group addresses the major challenge of the sustainable intensification of agriculture: enhancing production whilst reducing environmental impacts, particularly with respect to grassland dominated systems.

Dr Fl&aacute;vio Santana is a plant pathologist at Embrapa Trigo since 2006. Since then he is working in characterization of tan spot disease isolates from Brazil. He also is responsible as coordinator of a fungicide control of Wheat Blast and Fusarium Head Blight in several States in Brazil. In this Project he will be committed with the phenotyping of a population of resistant and susceptible wheat cultivars to tan spot disease.

Dr Ricardo Lima de Castro has experience in agronomy with emphasis on plant breeding, working mainly in wheat breeding, biometrics and quantitative genetics. In Embrapa Wheat he has been working in wheat breeding. Dr. Lima will identify wheat cultivars resistant and susceptible to the fungus attack deliverable (preparation of a list of cultivars and their genetic background), carry out of the trials to test resistance and help in phenotyping of resistance.

Embrapa Wheat is a branch of the Nacional Agricultural Research Center (Embrapa) where several researchers are directly involved in all area of agricultural science related to wheat, as plant pathology, entomology, weed control, plant physiology, soil nutrition, of which the main focus is wheat breeding. The facilities are well equipped with greenhouses, fields for trials and research labs."
3EE95488-CC78-4D3E-A8A7-47B77E3E0076,"Big data' on health is a growing resource and complex interdisciplinary challenge. The availability of large heterogeneous datasets which link data across diverse domains - such as mental health indicators and microbiological genomics - has the potential to unravel complex interplay between myriad elements in the individual life course and society in general2,3. To maximise this potential, there is pressing need for advanced methods for analysing these complex data. However, the analysis of such complex linked data, presents challenges, and traditionally applied statistical analyses often struggle with the data itself. Data can be noisy, and the noise non-random. Questionnaires are often answered in a
systematically biased way, and self-reporting of certain aspects are subject to poor recall, desirability, bias or inaccurate self-estimation. Data also often comes in categorical, rather than numerical forms, which can be problematic for some forms of statistical modelling. Finally, missing data, in terms of missing item responses and longitudinal attrition is common. Thus, we need more flexible and advanced techniques to tackle these issues. 
In this PhD and MRes we will develop an innovative interdisciplinary solution by applying a network-based approach, typically using in analysing biological systems, to analyse integrated social science and biomedical data. 
Bayesian networks have potential to address many technical modelling issues that social science data faces but have yet to be widely applied in social sciences. This is because it is necessary to develop both practical methodology and specific theoretical advances before they are a truly usable approach. Here, we will develop these advances (further details below).
This project will apply BN approaches to a pressing and complex global health challenge: antibacterial resistance (ABR) in three countries in East Africa. The potential harm that increasing levels of ABR will have on human health is vast. One of the world regions most vulnerable to the increase in antibiotic resistance is Africa where, in comparison to other regions of the world, the burden of infectious diseases is highest. A 'one health', interdisciplinary approach to understanding the problem, which stresses the interconnectedness of social and biological domains and spans the human, animal and environmental spheres has been proposed.However such a complex system is difficult to analyse without advanced tools. There may be multiple drivers are varying scales: individual behavioural, household, community and healthcare system levels. The relative importance and inter-relationships between these drivers in predicting levels of AMR at individual and community level, however, not well understood, and moreover are likely to be highly context specific
Research Questions 
The research questions for this PhD are twofold, methodological and substantive:
1. Methodological: To develop BN structure learning to enable integrating of interdisciplinary big data across social sciences and health, specifically addressing:
a. Missing data
b. Categorical variables
c. Biased noise
2. Substantive focussed on a case study of communicable disease: using data from HATUA, to investigate the drivers of antibacterial resistance in urinary tract infections in East Africa."
4041ED95-0961-47BD-B47E-5F662B1ABE9B,"Major improvements in crop performance are needed to keep pace with population growth, which is driving up global food demand, and climate change, which is increasing the vulnerability of cropping systems to extreme weather events in the UK and internationally. Whilst plant breeding efforts have greatly benefited from advances in genomics, profiling the crop phenome (i.e. the structure and function of plants) associated with their genetic structure and environment remains a major bottleneck. 

Solutions will be multidisciplinary, requiring engineering and computer science as well as plant biology. Sensors are required that can measure of a diverse range of properties of complex, deformable, living and growing objects - plants - often in quite hostile environments. Structural and functional plant traits capturing key properties of roots, shoots, flowers, seeds, etc. must be recovered from those measures effectively and efficiently. Most data capture is image-based, requiring advanced computer vision techniques. Trait data are then used to provide understanding of e.g. plants' growth rates, flowering times, seed production and yield, using advanced data analysis and machine learning methods.

PhenomUK's vision is of an integrated, mutually-informed community of computer scientists, engineers and biologists, working together across discipline boundaries to shape the technologies needed to address one of the global challenges of the 21st century - the provision of a secure food supply to a growing population against a background of resource depletion and climate change. Through series of Annual Conferences, workshops, networking visits, online training events and pump-priming research projects, this multidisciplinary network project will:

1. ensure that UK scientists have access to the innovative technological capabilities needed to drive world-leading basic discovery research in the plant, crop and agricultural sciences
2. provide the deeper understanding of national plant phenotyping capabilities, needs and opportunities required to allow the UK to participate fully in and gain maximum benefit from international initiatives such as the pan-European infrastructure being created by the ESFRI EMPHASIS project (https://emphasis.plant-phenotyping.eu)."
2A4FE759-23FF-4CEF-8A93-A2F7EDBC82F8,"Preamble: This is an interdisciplinary KTN CASE BBSRC PhD project supervised jointly by two academic supervisors from the Department of Genetics (Marco R Oggioni) and Mathematics (Andrew Morozov) of the University of Leicester UK and by two industrial supervisors at Chr. Hansen A/S in Horsholm Denmark (Ana Rute Neves and Jonas Jacobsen). The student will be based at Leicester, but during the four years the student will be hosted for six months at the Chr. Hansen headquarters and research facility at Horsholm in Denmark.
Background: Phase variable type I restriction modification (R-M) systems have been identified and we have shown that they provide a novel bacterial epigenetic control mechanism that affects both gene expression and important bacterial phenotypes; i.e. in pathogens, these systems were linked to the capacity for generating disease (Manso et al., Nature Communications 2014). The phase variable genetic modules are based on repeated inverted copies of the specificity gene (hsdS) of the R-M system that allows for high frequency recombination conferring the R-M system with multiple different methylation target specificities. These double-hsdS modules are widespread among firmicutes, including bacterial species of industrial relevance for the production of starter cultures or for use as probiotic functional foods. Extensive genomic data is now available, both for bacterial strains already utilised by industry and for strains being screened for their commercial potential. The proposed project will combine the academic partner's expertise gained by studying the phase variable double-hsdS modules in the lactic acid bacterium Streptococcus pneumoniae (Manso et al., Nature Communications 2014) with the vast expertise in bacterial strain phenotyping at Chr. Hansen (Derkx et al., Microb Cell Fact. 2014) and the large number of sequenced genomes available through the industrial partner. 
Aims and objectives: The primary aim of the project is to characterise phase variable double-hsdS modules in firmicutes of commercial interest, especially lactobacilli, and to evaluate their impact on strain fitness and metabolic potential. The long term goal of the whole project would be to produce high level scientific data to allow optimisation of quality control and product efficacy of industrially relevant bacteria harbouring these phase variable epigenetic control systems"
C0E99095-B246-4A5D-9514-9C87412CA84B,"Programme overview: 
This MRC-funded doctoral training partnership (DTP) brings together cutting-edge molecular and analytical sciences with innovative computational approaches in data analysis to enable students to address hypothesis-led biomedical research questions. This is a 4-year programme whose first year involves a series of taught modules and two laboratory-based research projects that lead to an MSc in Interdisciplinary Biomedical Research. The first two terms consist of a selection of taught modules that allow students to gain a solid grounding in multidisciplinary science. Students also attend a series of masterclasses led by academic and industry experts in areas of molecular, cellular and tissue dynamics, microbiology and infection, applied biomedical technologies and artificial intelligence and data science. During the third and summer terms students conduct two eleven-week research projects in labs of their choice. 

Project overview:
Tuberculosis (TB), caused by Mycobacterium tuberculosis, claims the lives of millions of people each year globally, but the current treatment is long and not always effecEve. Resistance levels are increasing and there is a growing need for new treatments. Therefore, we urgently need to understand the basic biology of this global pathogen to aid its eradicaEon. Mtb is unusual as it survives in humans for decades but it is not known which nutrients are criEcal or indeed how they are transported into the bacteria. From interrogaEon of the genome Mtb is predicted to have five putaEve carbohydrate transporters, and the precise funcEon and physiology role of these import systems needs to be determined. This interdisciplinary proposal will aim to study all five of these transport systems and combine experimental techniques with computaEonal modelling to provide new insights into these Mtb transporters, which would be unavailable any other way.

ComparaEve modelling will be used to characterise carbohydrate transport in Mtb based on available crystal structures, and ligand docking will help guide potenEal substrate candidates that are transported by these processes. Using the crystal structures and homology models, molecular dynamic (MD) simulaEons will be performed. There will be mulEple aims for MD simulaEons: increase our understanding of the mechanism of transport, idenEfy key residues, ascertain key contacts between the ligand and protein and study effects of mutants on transport. This informaEon will then be used to inform the design of potenEal inhibitors and test these compounds experimentally. QuanEtaEve Skills in soXware for docking, MD simulaEons and homology modelling will be obtained, along with programming in python for analysis of this. Alongside experimental techniques will be developed to validate the results such as protein-ligand binding studies and X-ray crystallography."
BCE15D9A-0F1D-480B-8624-4B03C53CA770,"Blackleg disease of potato caused by P. atrosepticum (Pba) is the most damaging bacterial plant pathogen in the UK, costing &pound;50M p.a. in losses for the potato industry. Current knowledge assumes that disease is caused through Pba-infected seed tubers. However, our recent unpublished data have shown that under high soil moisture following irrigation, disease appears in plants grown from pathogen free seed (minitubers). The most likely explanation is that bacteria enter the plant and cause disease directly from the soil; something not previously considered. We have also shown that Pba is able to colonise roots of other plant species (including crops), possibly as natural rhizosphere-dwelling saprophytes in the soil. In pot trials with Pba alone, we showed there was no movement of Pba from soil into the plant. However, when free-living nematodes (FLN) were added to soil, a 100-fold increase in Pba in stems occurred.

Through these and other findings we now have the potential to make a step change in how we manage blackleg. We will address knowledge gaps firstly by using Light Sheet and Confocal Laser Scanning microscopy, transparent soils and mesocosm studies to assess the role of FLN as vectors of Pba and how infection occurs. We will also examine how changes in standard irrigation regimes can help to reduce levels of blackleg in ware crops (where irrigation is often over-applied to avoid common scab disease that occurs in dry conditions), and how it might change FLN communities around potato root systems. Similarly, we will identify cover crops that limit natural Pba colonisation on their roots as a possible way to reduce Pba numbers in soil prior to planting potato. Little is known about the microbiome on potato roots and how these might be influenced to favour or reduce colonisation by Pba. We will therefore characterise the potato microbiome prior to and following irrigation using shotgun metagenomics sequencing and the latest bioinformatics tools, with a focus on the Pectobacteriaceae and wider Gamma-proteobacteria. We will also use GC-MS to examine how changes in root architecture and the constituents of root exudates influence the composition of these bacterial groups, to assess whether the use irrigation and cover crops alter the balance between beneficial and harmful bacteria associated with potato. Finally, we will determine whether novel antimicrobials (bacteriocins) in closely related non-pathogenic bacteria in the microbiome could act as a management option against Pba.

Our recent modelling research using the Scottish Government's in-house potato inspections database (SPUDS), shows that blackleg incidence on a national scale does not occur randomly but in clusters. Reason(s) for this remain unclear but could be due to several things that, when identified, may assist growers in managing their crops, e.g. potato crop distribution, weather, soil type, soil moisture, leaf wetness, FLN distribution, crop type and rotation prior to planting. Using data generated from this project, an extensive array of data from other recent and historical investigations and the latest data from government and industry we will model, using innovative machine learning methods, at national scale these data to identify trends and drivers of Pba incidence in both space and time and, through this, produce predictive models to support development of a set of decision support tools for evaluation by stakeholders during the project and early adoption thereafter. Further, through scenario testing, we will quantify the predicted effects of climate change on future blackleg incidence in association with FLN presence thus providing the industry with robust and novel data to underpin sector resilience planning."
F3AF084F-FF0C-494B-B6D3-C63B952BCE9B,"This proposal is to request support for visits to the Centre of Excellence in Genomic Sciences (CEGS) at the University of Southern California, and Caltech (Mayo Laboratory), to exchange ideas, develop new lines of research and explore collaborative ventures. The underlying scientific theme which links these visits is the development of advanced tools for Bayesian statistical modelling, and their application to two challenging problems in systems and synthetic biology - the understanding of genetic variation and the design of novel protein molecules. This proposal surmounts traditional academic disciplinary boundaries and lies at the interface of biophysics, genomics and computational statistics.

A key feature that distinguishes the modern approach to systems biology is the aim of linking mathematical and statistical modelling with the huge volume and diversity of contemporary cellular and molecular data, such as that coming from high-throughput, genome-wide and imaging technologies. One of the most important challenges facing modern biology and medicine is to understand how the genetic variation between individuals (the genotype) translates into the type of variation we can see or measure, such as blood pressure (the phenotype), and how environment influences this relationship. Although considerable progress has been made in recent years in identifying regulatory genes and modules in various organisms, there is still limited knowledge about downstream gene regulatory networks, and about how variation in these networks results in phenotypic differences, and is, in turn, affected by the environment. 

The Centre of Excellence in Genomic Sciences (CEGS) at the University of Southern California, directed by Professor Simon Tavare FRS, is one of only 11 CEGS funded by the National Institutes of Health, with a focus on the use of the heterogeneous data produced by modern genomics technologies to understand genetic variation. Professor Tavare is internationally recognised for his work at the interface of statistics, probability and the biological and medical sciences. He has made important contributions to the study of combinatorial stochastic processes, population genetics and statistical bioinformatics. The visit to CEGS will provide an unparalleled opportunity to interact with a wide range of researchers, including molecular biologists, population geneticists, genetic epidemiologists, statisticians, computer scientists, and mathematicians, who are focused these problems. 

Whilst systems biology attempts to understand the design principles underpinning biological processes, synthetic biology attempts to apply this understanding to the design and construction of novel biological functions and systems not found in nature. One facet of synthetic biology is protein design, in which our increasing understanding of the principles underlying protein structure and function is being applied in the redesign of existing proteins, or the design of novel proteins. 

Professor Steve Mayo is one of the pioneers of the field of protein design and a member of the US National Academy of Sciences; the focus of his laboratory at Caltech is the use of theoretical, computational, and experimental approaches to study structural biology, and in particular to develop quantitative methods for protein design. Caltech was rated the world's number one university in the 2011--2012 Times Higher Education global ranking of the top 200 universities. The visit to Professor Mayo's laboratory will provide a unique opportunity to interact with a wide range of researchers applying theoretical, computational, and experimental approaches to the study of protein design, protein sequence evolution and protein-protein recognition, in a world-class environment."
7F7C1D05-6B48-46E3-8FEF-FA8454676838,"Understanding how species adapt to the environment they live in is a major goal in evolutionary biology. This is of particular value in light of climate change, where extant species will have to adapt to warmer and potentially harsher conditions relatively fast. However, identifying the genomic regions involved in local adaptation has been a challenging problem because the tools to survey species' genomes have only become available in the last two decades, e.g. SNP arrays and whole genome sequencing. The aim of this project is to analyse British sheep occurring in contrasting environments (mountain vs. lowland) using the OvineSNP50 arrays (~51,000 SNPs) to identify genetic variation linked to local adaptation in the UK's heterogeneous agricultural landscape. Additionally, the SNP arrays data will be analysed in combination with whole genome data for a population of Iranian wild mouflon (the sheep's ancestor) and other sheep breeds in order to identify genomic signatures of selection specific to the domestication event. 

The PhD student will be based 80% at Cardiff University, where the research group specialises in identifying signatures of selection using next generation sequencing in livestock and wildlife, and 20% at Bristol University, a world leader in the development of statistical approaches to study demographic history using genetic data. For this project the PhD student will be trained in sample preparation for SNP chip analysis and bioinformatics analyses (e.g. data quality filtering, demographic analyses, and identifying signatures of selection). This experimental design will allow the PhD student to compare populations of British mountain vs. lowland sheep, in the equivalent of a replicated experiment, to identify specific signatures of local adaptation to the environment where these populations live in, while controlling for confounding factors such as the demographic history (to be simulated with approximate Bayesian computation) and the selection signature left by the domestication process (to be accounted for by comparing domestic sheep against Iranian wild mouflon)."
8F609325-F675-4837-9340-C75E9B57224C,"Our evolutionary history is written in our genomes. By comparing DNA sequences from different species or multiple individuals of the same species we can work out how the species are related, when they diverged from each other, whether there was introgression between the species, and whether the population size of a species went through a bottleneck or other demographic changes. DNA sequences can also be used to identify species and delineate species boundaries. To address such exciting questions, powerful statistical methods and computational algorithms are necessary. In this project we will develop new statistical models and computer algorithms for efficient analysis of genomic sequence data within two well-established statistical frameworks: maximum likelihood and Bayesian inference. We will develop a maximum likelihood method for estimating the species tree that accommodates the random process of biological reproduction and genetic sequence evolution, as well as introgression or hybridisation that may be common between closely related species, especially during radiative speciations. We will introduce significant improvements and extensions to our Bayesian model-comparison approach to delimiting species using genomic sequence data. We will implement sophisticated models to describe the evolutionary process of DNA sequences and to allow changes in the evolutionary rate among lineages so that the program can be applied to estimate species phylogenies for distantly related species, such as different orders of mammals. We will parallelize the program to improve the computational efficiency."
